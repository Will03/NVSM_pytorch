Use dmy dates|date=July 2014
Refimprove|date=June 2008
Translation sidebar
<!----PLEASE DO NOT CONVERT REFERENCES WITHOUT DISCUSSING ON TALK PAGE. SEE http://bugzilla.wikimedia.org/show_bug.cgi?id=5885---->

Machine translation, sometimes referred to by the abbreviation MT (not to be confused with Computer-assisted translation|computer-aided translation, machine-aided human translation (MAHT) or Interactive machine translation|interactive translation) is a sub-field of computational linguistics that investigates the use of software to translation|translate text or speech from one language to another.

On a basic level, MT performs simple substitution of words in one  language for words in another, but that alone usually cannot produce a good translation of a text because recognition of whole phrases and their closest counterparts in the target language is needed. Solving this problem with corpus linguistics|corpus statistical, and Machine translation#Neural MT|neural techniques is a rapidly growing field that is leading to better translations, handling differences in linguistic typology, translation of idioms, and the isolation of anomalies.<ref>Albat, Thomas Fritz. "Systems and Methods for Automatically Estimating a Translation Time." US Patent 0185235, 19 July 2012.</ref>failed verification|reason=odd source with no mention of neural techniques|date=December 2017

Current machine translation software often allows for customization by domain or profession (such as meteorology|weather reports), improving output by limiting the scope of allowable substitutions. This technique is particularly effective in domains where formal or formulaic language is used. It follows that machine translation of government and legal documents more readily produces usable output than conversation or less standardised text.

Improved output quality can also be achieved by human intervention: for example, some systems are able to translate more accurately if the user has word sense disambiguation|unambiguously identified which words in the text are proper names. With the assistance of these techniques, MT has proven useful as a tool to assist human translators and, in a very limited number of cases, can even produce output that can be used as is (e.g., weather reports).

The progress and potential of machine translation have been debated much through its history. Since the 1950s, a number of scholars have questioned the possibility of achieving fully automatic machine translation of high quality, first and most notably by Yehoshua Bar-Hillel.<ref>cite book|title=Language and Information:  Selected Essays on Their Theory and Application|author=Yehoshua Bar-Hillel|first=|publisher=Addison-Wesley|year=1964|isbn=|location=Reading, MA|pages=174–179</ref> Some critics claim that there are in-principle obstacles to automating the translation process.<ref>cite web|url=https://docs.google.com/fileview?id=0B7-4xydn3MXJZjFkZTllZjItN2Q5Ny00YmUxLWEzODItNTYyMjhlNTY5NWIz |title=Madsen, Mathias: The Limits of Machine Translation (2010) |publisher=Docs.google.com |accessdate=2012-06-12</ref>

History
Main|History of machine translation
The idea of machine translation may be traced back to the 17th century. In 1629, René Descartes proposed a universal language, with equivalent ideas in different tongues sharing one symbol.<ref>cite book|first =稔 |last =浜口 |title =英仏普遍言語計画 |publisher =工作舎 |isbn=978-4-87502-214-5| pages =70–71 | quote =''普遍的文字''の構築という初期の試みに言及するときは1629年11月にデカルトがメルセンヌに宛てた手紙から始まる、というのが通り相場となっている。しかし、この問題への関心を最初に誘発した多くの要因を吟味してみると、ある種の共通の書字という構想は明らかに、ずっと以前から比較的なじみ深いものになっていたようである。…フランシス・ベイコンは、1605年出版の''学問の進歩について''のなかで、そのような真正の文字の体系は便利であると述べていた |date =30 April 1993translated from<br>cite book| first =James |last =Knowlson |title =UNIVERSAL LANGUAGE SCHEMES IN ENGLAND AND FRANCE 1600-1800
</ref> The field of "machine translation" appeared in Warren Weaver<ref>cite book|last1=Delavenay|first1=Émile|title=LA MACHINE A TRADUIRE (Collection QUE SAIS-JE? No.834)|publisher=Presses Universitaires de France|quote=英国人A.D.ブースとロックフェラー財団のワレン・ウィーバーとが同時に翻訳問題に手をつけたのは1946年のことであった。(translation (assisted by Google translate):It was in 1946 when the English Andrew Donald Booth|A. D. Booth and Warren Weaver at Rockefeller Foundation begun to study the issue on translation at the same time.)| translator = 別所照彦</ref>'s Warren Weaver#The .22Translation.22 memorandum|Memorandum on Translation (1949). The first researcher in the field, Yehosha Bar-Hillel, began his research at MIT (1951). A Georgetown University MT research team followed (1951) with a public demonstration of its Georgetown-IBM experiment system in 1954. MT research programs popped up in Japan<ref>cite book|last1=上野|first1=俊夫|title=パーソナルコンピュータによる機械翻訳プログラムの制作|date=1986-08-13|publisher=(株)ラッセル社|location=Tokyo|isbn=494762700X|page=16|language=Japanese|quote=わが国では1956年、当時の電気試験所が英和翻訳専用機「ヤマト」を実験している。この機械は1962年頃には中学1年の教科書で90点以上の能力に達したと報告されている。(translation (assisted by Google translate): In 1959 Japan, the w:jp:電気試験所|National Institute of Advanced Industrial Science and Technology(AIST) tested the proper English-Japanese translation machine ''Yamato'', which reported in 1964 as that reached the power level over the score of 90-point on the textbook of 1st grade of junior hi-school.)</ref><ref>http://museum.ipsj.or.jp/computer/dawn/0027.html</ref> and Russia (1955), and the first MT conference was held in London (1956).<ref name="Nye">cite journal|last1=Nye|first1=Mary Jo|title=Speaking in Tongues: Science's centuries-long hunt for a common language|journal=Distillations|date=2016|volume=2|issue=1|pages=40–43|url=https://www.sciencehistory.org/distillations/magazine/speaking-in-tongues|accessdate=20 March 2018</ref><ref name="Babel">cite book|last1=Gordin|first1=Michael D.|title=Scientific Babel: How Science Was Done Before and After Global English|date=2015|publisher=University of Chicago Press|location=Chicago, Illinois|isbn=9780226000299</ref>  Researchers continued to join the field as the Association for Machine Translation and Computational Linguistics was formed in the U.S. (1962) and the National Academy of Sciences formed the Automatic Language Processing Advisory Committee (ALPAC) to study MT (1964). Real progress was much slower, however, and after the ALPAC|ALPAC report (1966), which found that the ten-year-long research had failed to fulfill expectations, funding was greatly reduced.<ref name = "ueno">cite book|last1=上野|first1=俊夫|title=パーソナルコンピュータによる機械翻訳プログラムの制作|date=1986-08-13|publisher=(株)ラッセル社|isbn=494762700X|page=16|location=Tokyo|language=Japanese</ref> According to a 1972 report by the Director of Defense Research and Engineering (DDR&E), the feasibility of large-scale MT was reestablished by the success of the Logos MT system in translating military manuals into Vietnamese during that conflict.

The French Textile Institute also used MT to translate abstracts from and into French, English, German and Spanish (1970); Brigham Young University started a project to translate Mormon texts by automated translation (1971); and Xerox used SYSTRAN to translate technical manuals (1978). Beginning in the late 1980s, as computational power increased and became less expensive, more interest was shown in statistical machine translation|statistical models for machine translation. Various MT companies were launched, including Trados (1984), which was the first to develop and market translation memory technology (1989). The first commercial MT system for Russian / English / German-Ukrainian was developed at Kharkov State University (1991).

MT on the web started with SYSTRAN Offering free translation of small texts (1996), followed by AltaVista Babelfish, which racked up 500,000 requests a day (1997). Franz-Josef Och (the future head of Translation Development AT Google) won DARPA's speed MT competition (2003). More innovations during this time included MOSES, the open-source statistical MT engine (2007), a text/SMS translation service for mobiles in Japan (2008), and a mobile phone with built-in speech-to-speech translation functionality for English, Japanese and Chinese (2009). Recently, Google announced that Google Translate translates roughly enough text to fill 1 million books in one day (2012).

The idea of using digital computers for translation of natural languages was proposed as early as 1946 by Andrew Donald Booth|A. D. Booth and possibly others. Warren Weaver wrote an important memorandum "Warren Weaver#The .22Translation.22 memorandum|Translation" in 1949. The Georgetown experiment was by no means the first such application, and a demonstration was made in 1954 on the APEXC machine at Birkbeck, University of London|Birkbeck College (University of London) of a rudimentary translation of English into French. Several papers on the topic were published at the time, and even articles in popular journals (see for example ''Wireless World'', Sept. 1955, Cleave and Zacharov).  A similar application, also pioneered at Birkbeck College at the time, was reading and composing Braille texts by computer.

Translation process
Main|Translation process
The human translation process may be described as:
# Code|Decoding the meaning (linguistic)|meaning of the source text; and
# Re-encoding this meaning (linguistic)|meaning in the target language.

Behind this ostensibly simple procedure lies a complex cognitive operation.  To decode the meaning of the source text in its entirety, the translator must interpret and analyse all the features of the text, a process that requires in-depth knowledge of the grammar, semantics, syntax, idioms, etc., of the source language, as well as the culture of its speakers. The translator needs the same in-depth knowledge to re-encode the meaning in the target language.

Therein lies the challenge in machine translation: how to program a computer that will "understand" a text as a person does, and that will "create" a new text in the target language that Turing test|sounds as if it has been written by a person.

In its most general application, this is beyond current technology. Though it works much faster, no automated translation program or procedure, with no human participation, can produce output even close to the quality a human translator can produce. What it can do, however, is provide a general, though imperfect, approximation of the original text, getting the "gist" of it (a process called "gisting"). This is sufficient for many purposes, including making best use of the finite and expensive time of a human translator, reserved for those cases in which total accuracy is indispensable.

This problem may be approached in a number of ways, through the evolution of which accuracy has improved.

Approaches
File:Direct translation and transfer translation pyramid.svg|thumb|right|300px|Bernard Vauquois' pyramid showing comparative depths of intermediary representation, interlingual machine translation at the peak, followed by transfer-based, then direct translation.
Machine translation can use a method based on Expert System|linguistic rules, which means that words will be translated in a linguistic way – the most suitable (orally speaking) words of the target language will replace the ones in the source language.citation needed|date=December 2018

It is often argued that the success of machine translation requires the problem of natural language understanding to be solved first.<ref name="Lehrberger1988">cite book|author=John Lehrberger|title=Machine Translation: Linguistic Characteristics of MT Systems and General Methodology of Evaluation|url=https://books.google.com/books?id=YUNLlurHNAEC&printsec=frontcover&dq=%22natural+language+understanding%22+%22machine+translation%22&hl=en&sa=X&ved=0ahUKEwj1raiS96rfAhXq7oMKHd0fChIQ6AEIVTAH#v=snippet&q=%22natural%20language%20understanding%22&f=false|year=1988|publisher=John Benjamins Publishing|isbn=90-272-3124-9</ref>

Generally, rule-based methods parse a text, usually creating an intermediary, symbolic representation, from which the text in the target language is generated. According to the nature of the intermediary representation, an approach is described as interlingual machine translation or transfer-based machine translation. These methods require extensive lexicons with morphology (linguistics)|morphological, syntax|syntactic, and semantics|semantic information, and large sets of rules.

Given enough data, machine translation programs often work well enough for a native speaker of one language to get the approximate meaning of what is written by the other native speaker. The difficulty is getting enough data of the right kind to support the particular method. For example, the large multilingual Text corpus|corpus of data needed for statistical methods to work is not necessary for the grammar-based methods. But then, the grammar methods need a skilled linguist to carefully design the grammar that they use.

To translate between closely related languages, the technique referred to as rule-based machine translation may be used.

=Rule-based=
Main|Rule-based machine translation

The rule-based machine translation paradigm includes transfer-based machine translation, interlingual machine translation and dictionary-based machine translation paradigms. This type of translation is used mostly in the creation of dictionaries and grammar programs. Unlike other methods, RBMT involves more information about the linguistics of the source and target languages, using the morphological and syntactic rules and semantic analysis of both languages. The basic approach involves linking the structure of the input sentence with the structure of the output sentence using a parser and an analyzer for the source language, a generator for the target language, and a transfer lexicon for the actual translation. RBMT's biggest downfall is that everything must be made explicit: orthographical variation and erroneous input must be made part of the source language analyser in order to cope with it, and lexical selection rules must be written for all instances of ambiguity. Adapting to new domains in itself is not that hard, as the core grammar is the same across domains, and the domain-specific adjustment is limited to lexical selection adjustment.

Transfer-based machine translation
Main|Transfer-based machine translation

Transfer-based machine translation is similar to interlingual machine translation in that it creates a translation from an intermediate representation that simulates the meaning of the original sentence. Unlike interlingual MT, it depends partially on the language pair involved in the translation.

Interlingual
Main|Interlingual machine translation

Interlingual machine translation is one instance of rule-based machine-translation approaches.  In this approach, the source language, i.e. the text to be translated, is transformed into an interlingual language, i.e. a "language neutral" representation that is independent of any language. The target language is then generated out of the interlinguistics|interlingua. One of the major advantages of this system is that the interlingua becomes more valuable as the number of target languages it can be turned into increases. However, the only interlingual machine translation system that has been made operational at the commercial level is the KANT system (Nyberg and Mitamura, 1992), which is designed to translate Caterpillar Technical English (CTE) into other languages.

Dictionary-based
Main|Dictionary-based machine translation

Machine translation can use a method based on dictionary entries, which means that the words will be translated as they are by a dictionary.

=Statistical=
Main|Statistical machine translation

Statistical machine translation tries to generate translations using statistical methods based on bilingual text corpora, such as the Hansard#Translation|Canadian Hansard corpus, the English-French record of the Canadian parliament and Europarl corpus|EUROPARL, the record of the European Parliament. Where such corpora are available, good results can be achieved translating similar texts, but such corpora are still rare for many language pairs. The first statistical machine translation software was CANDIDE from IBM. Google used SYSTRAN for several years, but switched to a statistical translation method in October 2007.<ref>cite web|last=Chitu |first=Alex |url=http://googlesystem.blogspot.com/2007/10/google-translate-switches-to-googles.html |title=Google Switches to Its Own Translation System |publisher=Googlesystem.blogspot.com |date=22 October 2007 |accessdate=2012-08-13</ref> In 2005, Google improved its internal translation capabilities by using approximately 200 billion words from United Nations materials to train their system; translation accuracy improved.<ref>cite web|url=http://blog.outer-court.com/archive/2005-05-22-n83.html |title=Google Translator: The Universal Language |publisher=Blog.outer-court.com |date=25 January 2007 |accessdate=2012-06-12</ref> Google Translate and similar statistical translation programs work by detecting patterns in hundreds of millions of documents that have previously been translated by humans and making intelligent guesses based on the findings. Generally, the more human-translated documents available in a given language, the more likely it is that the translation will be of good quality.<ref>cite web|url=https://translate.google.com/about/intl/en_ALL/|title=Inside Google Translate – Google Translate|publisher=</ref> Newer approaches into Statistical Machine translation such as METIS II and PRESEMT use minimal corpus size and instead focus on derivation of syntactic structure through pattern recognition. With further development, this may allow statistical machine translation to operate off of a monolingual text corpus.<ref>http://www.mt-archive.info/10/HyTra-2013-Tambouratzis.pdf</ref> SMT's biggest downfall includes it being dependent upon huge amounts of parallel texts, its problems with morphology-rich languages (especially with translating ''into'' such languages), and its inability to correct singleton errors.

=Example-based=
Main|Example-based machine translation

Example-based machine translation (EBMT) approach was proposed by Makoto Nagao in 1984.<ref>Nagao, M. 1981. [https://pdfs.semanticscholar.org/bc43/f6bccb18a5a4892daa8e66756e0a684e7f5c.pdf A Framework of a Mechanical Translation between Japanese and English by Analogy Principle], in Artificial and Human Intelligence, A. Elithorn and R. Banerji (eds.) North- Holland, pp. 173–180, 1984.</ref><ref>cite web | url = http://www.aclweb.org/index.php?option=com_content&task=view&id=36&Itemid=30 | title = the Association for Computational Linguistics – 2003 ACL Lifetime Achievement Award | publisher = Association for Computational Linguistics | accessdate = 2010-03-10</ref> Example-based machine translation is based on the idea of analogy. In this approach, the corpus that is used is one that contains texts that have already been translated. Given a sentence that is to be translated, sentences from this corpus are selected that contain similar sub-sentential components.<ref>http://kitt.cl.uzh.ch/clab/satzaehnlichkeit/tutorial/Unterlagen/Somers1999.pdf</ref> The similar sentences are then used to translate the sub-sentential components of the original sentence into the target language, and these phrases are put together to form a complete translation.

=Hybrid MT=
Main|Hybrid machine translation

Hybrid machine translation (HMT) leverages the strengths of statistical and rule-based translation methodologies.<ref name="speechtechmag.com">cite web|author=Adam Boretz |url=http://www.speechtechmag.com/Articles/News/News-Feature/AppTek-Launches-Hybrid-Machine-Translation-Software-52871.aspx |title=Boretz, Adam, "AppTek Launches Hybrid Machine Translation Software" SpeechTechMag.com (posted 2 MAR 2009) |publisher=Speechtechmag.com |accessdate=2012-06-12</ref> Several MT organizations (such as Omniscien Technologies (formerly Asia Online), LinguaSys, Systran, and Polytechnic University of Valencia) claim a hybrid approach that uses both rules and statistics. The approaches differ in a number of ways:
* Rules post-processed by statistics: Translations are performed using a rules based engine. Statistics are then used in an attempt to adjust/correct the output from the rules engine.
* Statistics guided by rules: Rules are used to pre-process data in an attempt to better guide the statistical engine. Rules are also used to post-process the statistical output to perform functions such as normalization. This approach has a lot more power, flexibility and control when translating. It also provides extensive control over the way in which the content is processed during both pre-translation (e.g. markup of content and non-translatable terms) and post-translation (e.g. post translation corrections and adjustments).
More recently, with the advent of Neural MT, a new version of hybrid machine translation is emerging that combines the benefits of rules, statistical and neural machine translation. The approach allows benefitting from pre- and post-processing in a rule guided workflow as well as benefitting from NMT and SMT. The downside is the inherent complexity which makes the approach suitable only for specific use cases. One of the proponents of this approach for complex use cases is Omniscien Technologies.

=Neural MT=
Main|Neural machine translation

A deep learning based approach to MT, neural machine translation has made rapid progress in recent years, and Google has announced its translation services are now using this technology in preference to its previous statistical methods<ref>Cite news|url=https://www.theregister.co.uk/2016/11/17/googles_neural_net_translates_languages_not_trained_on/|title=Google's neural network learns to translate languages it hasn't been trained on</ref>. Other providers including Pangeanic<ref>Cite news|url=https://slator.com/deal-wins/eu-spends-eur-1-9m-to-customize-mt-for-state-and-regional-authorities/|title=EU Spends EUR 1.9m to Customize MT for State and Regional Authorities ! Slator|date=2017-07-09|work=Slator|access-date=2017-07-09|language=en-US</ref>, KantanMT<ref>Cite news|url=https://slator.com/press-releases/kantanmt-users-can-now-customise-and-deploy-neural-machine-translation-engines/|title=KantanMT Users Can Now Customise and Deploy Neural Machine Translation Engines ! Slator|date=2017-03-13|work=Slator|access-date=2017-06-23|language=en-US</ref>, Omniscien Technologies<ref>Cite news|url=https://slator.com/press-releases/omniscien-technologies-announces-release-language-studio-next-generation-nmt-technology/|title=Omniscien Technologies Announces Release of Language Studio™ with Next-Generation NMT Technology ! Slator|date=2017-04-21|work=Slator|access-date=2017-06-23|language=en-US</ref> and SDL Trados|SDL<ref>Cite news|url=http://www.destinationcrm.com/Articles/CRM-News/CRM-Featured-Articles/SDL-Adds-Neural-Machine-Translation-to-Its-Enterprise-Translation-Server-118775.aspx|title=SDL Adds Neural Machine Translation to Its Enterprise Translation Server|last=Rowe|first=Sam Del|date=2017-06-12|work=CRM Magazine|access-date=2017-06-23</ref> have announced the deployment of neural machine translation technology in 2017 as well.

Major issues
File:Stir_Fried_Wikipedia.jpg|thumb|right|250px|Machine translation could produce some non-understandable phrases.
File:Machine translation in Bali.jpg|thumb|right|250px|Broken Chinese "沒有進入" from machine translation in Bali, Indonesia. The broken Chinese sentence sounds like "there does not exist an entry" or "have not entered yet"
=Disambiguation=
Main|Word sense disambiguation|Syntactic disambiguation
Word-sense disambiguation concerns finding a suitable translation when a word can have more than one meaning. The problem was first raised in the 1950s by Yehoshua Bar-Hillel.<ref>[http://ourworld.compuserve.com/homepages/WJHutchins/Miles-6.htm Milestones in machine translation – No.6: Bar-Hillel and the nonfeasibility of FAHQT] webarchive|url=https://web.archive.org/web/20070312062051/http://ourworld.compuserve.com/homepages/WJHutchins/Miles-6.htm |date=12 March 2007  by John Hutchins</ref> He pointed out that without a "universal encyclopedia", a machine would never be able to distinguish between the two meanings of a word.<ref>Bar-Hillel (1960), "Automatic Translation of Languages". Available online at http://www.mt-archive.info/Bar-Hillel-1960.pdf</ref> Today there are numerous approaches designed to overcome this problem. They can be approximately divided into "shallow" approaches and "deep" approaches.

Shallow approaches assume no knowledge of the text. They simply apply statistical methods to the words surrounding the ambiguous word. Deep approaches presume a comprehensive knowledge of the word. So far, shallow approaches have been more successful.<ref>Cite book|url=https://www.worldcat.org/oclc/953581497|title=Hybrid approaches to machine translation|others=Costa-jussà, Marta R.,, Rapp, Reinhard,, Lambert, Patrik,, Eberle, Kurt,, Banchs, Rafael E.,, Babych, Bogdan,|isbn=9783319213101|location=Switzerland|oclc=953581497</ref>

Claude Piron, a long-time translator for the United Nations and the World Health Organization, wrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolve ambiguity|ambiguities in the source text, which the grammatical and Lexical (semiotics)|lexical exigencies of the Translation|target language require to be resolved:

: Why does a translator need a whole workday to translate five pages, and not an hour or two? ..... About 90% of an average text corresponds to these simple conditions.  But unfortunately, there's the other 10%.  It's that part that requires six [more] hours of work.  There are ambiguities one has to resolve.  For instance, the author of the source text, an Australian physician, cited the example of an epidemic which was declared during World War II in a "Japanese prisoner of war camp".  Was he talking about an American camp with Japanese prisoners or a Japanese camp with American prisoners?  The English has two senses.  It's necessary therefore to do research, maybe to the extent of a phone call to Australia.<ref name="piron">Claude Piron, ''Le défi des langues'' (The Language Challenge), Paris, L'Harmattan, 1994. <!-- GFDL translation by Jim Henry --></ref>

The ideal deep approach would require the translation software to do all the research necessary for this kind of disambiguation on its own; but this would require a higher degree of AI than has yet been attained.  A shallow approach which simply guessed at the sense of the ambiguous English phrase that Piron mentions (based, perhaps, on which kind of prisoner-of-war camp is more often mentioned in a given corpus) would have a reasonable chance of guessing wrong fairly often.  A shallow approach that involves "ask the user about each ambiguity" would, by Piron's estimate, only automate about 25% of a professional translator's job, leaving the harder 75% still to be done by a human.

=Non-standard speech=
One of the major pitfalls of MT is its inability to translate non-standard language with the same accuracy as standard language. Heuristic or statistical based MT takes input from various sources in standard form of a language. Rule-based translation, by nature, does not include common non-standard usages. This causes errors in translation from a vernacular source or into colloquial language. Limitations on translation from casual speech present issues in the use of machine translation in mobile devices.

=Named entities=

:Related to named entity recognition in information extraction.

Name entities, in narrow sense, refer to concrete or abstract entities in the real world including people, organizations, companies, places etc. It also refers to expressing of time, space, quantity such as 1 July 2011, $79.99 and so on.<ref>[张政.计算机语言学与机器翻译导论.外语教学与研究出版社，2010]</ref>

Named entities occur in the text being analyzed in statistical machine translation. The initial difficulty that arises in dealing with named entities is simply identifying them in the text. Consider the list of names common in a particular language to illustrate this – the most common names are different for each language and also are constantly changing. If named entities cannot be recognized by the machine translator, they may be erroneously translated as common nouns, which would most likely not affect the Bilingual evaluation understudy|BLEU rating of the translation but would change the text's human readability.<ref>http://www.cl.cam.ac.uk/~ar283/eacl03/workshops03/W03-w1_eacl03babych.local.pdf</ref> It is also possible that, when not identified, named entities will be omitted from the output translation, which would also have implications for the text's readability and message.

Another way to deal with named entities is to use transliteration instead of translation, meaning that you find the letters in the target language that most closely correspond to the name in the source language.  There have been attempts to incorporate this into machine translation by adding a transliteration step into the translation procedure.  However, these attempts still have their problems and have even been cited as worsening the quality of translation.<ref>Hermajakob, U., Knight, K., & Hal, D. (2008).  [http://www.aclweb.org/old_anthology/P/P08/P08-1.pdf#page=433 Name Translation in Statistical Machine Translation Learning When to Transliterate].  Association for Computational Linguistics.  389–397.</ref> Named entities were still identified incorrectly, with words not being transliterated when they should or being transliterated when they shouldn't.  For example, for "Southern California" the first word should be translated directly, while the second word should be transliterated.  However, machines would often transliterate both because they treated them as one entity.  Words like these are hard for machine translators, even those with a transliteration component, to process.

The lack of attention to the issue of named entity translation has been recognized as potentially stemming from a lack of resources to devote to the task in addition to the complexity of creating a good system for named entity translation. One approach to named entity translation has been to transliterate, and not translate, those words. A second is to create a "do-not-translate" list, which has the same end goal – transliteration as opposed to translation.<ref name="singla">http://nlp.stanford.edu/courses/cs224n/2010/reports/singla-nirajuec.pdf</ref>  Both of these approaches still rely on the correct identification of named entities, however.

A third approach to successful named entity translation is a class-based model. In this method, named entities are replaced with a token to represent the class they belong to. For example, "Ted"  and "Erica" would both be replaced with "person" class token. In this way the statistical distribution and use of person names in general can be analyzed instead of looking at the distributions of "Ted" and "Erica" individually. A problem that the class based model solves is that the probability of a given name in a specific language will not affect the assigned probability of a translation. A study by Stanford on improving this area of translation gives the examples that different probabilities will be assigned to "David is going for a walk" and "Ankit is going for a walk" for English as a target language due to the different number of occurrences for each name in the training data. A frustrating outcome of the same study by Stanford (and other attempts to improve named recognition translation) is that many times, a decrease in the Bilingual evaluation understudy|BLEU scores for translation will result from the inclusion of methods for named entity translation.<ref name="singla"/>

Translation from multiparallel sources
Some work has been done in the utilization of multiparallel text corpus|corpora, that is a body of text that has been translated into 3 or more languages.  Using these methods, a text that has been translated into 2 or more languages may be utilized in combination to provide a more accurate translation into a third language compared with if just one of those source languages were used alone.<ref>https://dowobeha.github.io/papers/amta08.pdf</ref><ref>http://homepages.inf.ed.ac.uk/mlap/Papers/acl07.pdf</ref><ref>https://www.jair.org/media/3540/live-3540-6293-jair.pdf</ref>

Ontologies in MT
An Ontology (information science)|ontology is a formal representation of knowledge which includes the concepts (such as objects, processes etc.) in a domain and some relations between them. If the stored information is of linguistic nature, one can speak of a lexicon.<ref name="Vossen">Vossen, Piek: ''Ontologies''. In: Mitkov, Ruslan (ed.) (2003): Handbook of Computational Linguistics, Chapter 25. Oxford: Oxford University Press.</ref>
In Natural language processing|NLP, ontologies can be used as a source of knowledge for machine translation systems. With access to a large knowledge base, systems can be enabled to resolve many (especially lexical) ambiguities on their own.
In the following classic examples, as humans, we are able to interpret the Adpositional phrase#Prepositional phrases|prepositional phrase according to the context because we use our world knowledge, stored in our lexicons:
<blockquote> "I saw a man/star/molecule with a microscope/telescope/binoculars."<ref name="Vossen" /> </blockquote>
A machine translation system initially would not be able to differentiate between the meanings because syntax does not change. With a large enough ontology as a source of knowledge however, the possible interpretations of ambiguous words in a specific context can be reduced.
Other areas of usage for ontologies within NLP include information retrieval, information extraction and automatic summarization|text summarization.<ref name="Vossen" />

=Building ontologies=
The ontology generated for the PANGLOSS knowledge-based machine translation system in 1993 may serve as an example of how an ontology for Natural language processing|NLP purposes can be compiled:<ref>cite web|last=Knight|first=Kevin|title=''Building a large ontology for machine translation (1993)''|url=https://arxiv.org/pdf/cmp-lg/9407029.pdf|accessdate=7 September 2014</ref>
* A large-scale ontology is necessary to help parsing in the active modules of the machine translation system.
* In the PANGLOSS example, about 50.000 nodes were intended to be subsumed under the smaller, manually-built ''upper'' (abstract) ''region'' of the ontology. Because of its size, it had to be created automatically.
* The goal was to merge the two resources LDOCE|LDOCE online and WordNet to combine the benefits of both: concise definitions from Longman, and semantic relations allowing for semi-automatic taxonomization to the ontology from WordNet.
** A ''definition match'' algorithm was created to automatically merge the correct meanings of ambiguous words between the two online resources, based on the words that the definitions of those meanings have in common in LDOCE and WordNet. Using a similarity matrix, the algorithm delivered matches between meanings including a confidence factor. This algorithm alone, however, did not match all meanings correctly on its own.
** A second ''hierarchy match'' algorithm was therefore created which uses the taxonomic hierarchies found in WordNet (deep hierarchies) and partially in LDOCE (flat hierarchies). This works by first matching unambiguous meanings, then limiting the search space to only the respective ancestors and descendants of those matched meanings. Thus, the algorithm matched locally unambiguous meanings (for instance, while the word ''Seal (disambiguation)|seal'' as such is ambiguous, there is only one meaning of ''Pinniped|"seal"'' in the ''animal'' subhierarchy).
* Both algorithms complemented each other and helped constructing a large-scale ontology for the machine translation system. The WordNet hierarchies, coupled with the matching definitions of LDOCE, were subordinated to the ontology's ''upper region''. As a result, the PANGLOSS MT system was able to make use of this knowledge base, mainly in its generation element.

Applications
While no system provides the holy grail of fully automatic high-quality machine translation of unrestricted text, many fully automated systems produce reasonable output.<ref>cite web|url=http://www.benjamins.com/cgi-bin/t_bookview.cgi?bookid=BTL%2014 |title=Melby, Alan. The Possibility of Language (Amsterdam:Benjamins, 1995, 27–41) |publisher=Benjamins.com |accessdate=2012-06-12</ref><ref>cite web|author=Adam |url=http://tandibusiness.blogspot.com/2006/02/simple-model-outlining-translation.html |title=Wooten, Adam. "A Simple Model Outlining Translation Technology" T&I Business (February 14, 2006) |publisher=Tandibusiness.blogspot.com |date=14 February 2006 |accessdate=2012-06-12</ref><ref>cite web|url=http://www.mt-archive.info/Bar-Hillel-1960-App3.pdf |title=Appendix III of 'The present status of automatic translation of languages', Advances in Computers, vol.1 (1960), p.158-163. Reprinted in Y.Bar-Hillel: Language and information (Reading, Mass.: Addison-Wesley, 1964), p.174-179. |format=PDF |accessdate=2012-06-12</ref> The quality of machine translation is substantially improved if the domain is restricted and controlled.<ref>cite web|url=http://tauyou.com/blog/?p=47 |title=Human quality machine translation solution by Ta with you |language=es |publisher=Tauyou.com |date=15 April 2009 |accessdate=2012-06-12</ref>

Despite their inherent limitations, MT programs are used around the world. Probably the largest institutional user is the European Commission. The MOLTO project, for example, coordinated by the University of Gothenburg, received more than 2.375 million euros project support from the EU to create a reliable translation tool that covers a majority of the EU languages.<ref>cite web|url=http://www.molto-project.eu/ |title=molto-project.eu |publisher=molto-project.eu |accessdate=2012-06-12</ref> The further development of MT systems comes at a time when budget cuts in human translation may increase the EU's dependency on reliable MT programs.<ref>cite web|url=http://www.spiegel.de/international/europe/google-translate-has-ambitious-goals-for-machine-translation-a-921646.html|title=Google Translate Has Ambitious Goals for Machine Translation|author=SPIEGEL ONLINE, Hamburg, Germany|date=13 September 2013|work=SPIEGEL ONLINE</ref> The European Commission contributed 3.072 million euros (via its ISA programme) for the creation of MT@EC, a statistical machine translation program tailored to the administrative needs of the EU, to replace a previous rule-based machine translation system.<ref>cite web|url=http://ec.europa.eu/isa/actions/02-interoperability-architecture/2-8action_en.htm|title=Machine Translation Service|date=5 August 2011|publisher=</ref>

In 2005, Google claimed that promising results were obtained using a proprietary statistical machine translation engine.<ref>[http://googleblog.blogspot.com/2005/08/machines-do-translating.html Google Blog: The machines do the translating] (by Franz Och)</ref> The statistical translation engine used in the Google tools#anchor language tools|Google language tools for Arabic <-> English and Chinese <-> English had an overall score of 0.4281 over the runner-up IBM's BLEU-4 score of 0.3954 (Summer 2006) in tests conducted by the National Institute for Standards and Technology.<ref>cite web|url=http://ieeexplore.ieee.org/iel5/2/32474/01516048.pdf?arnumber=1516048 |title=Geer, David, "Statistical Translation Gains Respect", pp. 18 – 21, IEEE Computer, October 2005 |doi=10.1109/MC.2005.353 |publisher=Ieeexplore.ieee.org |date=27 September 2011 |accessdate=2012-06-12</ref><ref>cite web|url=https://www.wired.com/wired/archive/14.12/translate.html |title=Ratcliff, Evan "Me Translate Pretty One Day", Wired December 2006 |publisher=Wired.com |date=4 January 2009 |accessdate=2012-06-12</ref><ref>cite web|url=http://www.itl.nist.gov/iad/mig//tests/mt/2006/doc/mt06eval_official_results.html_official_results.html |title="NIST 2006 Machine Translation Evaluation Official Results", November 1, 2006 |publisher=Itl.nist.gov |accessdate=2012-06-12</ref>

With the recent focus on terrorism, the military sources in the United States have been investing significant amounts of money in natural language engineering. ''In-Q-Tel''<ref>cite web |url=http://www.in-q-tel.com |title=In-Q-Tel |publisher=In-Q-Tel |accessdate=2012-06-12 |archive-url=http://arquivo.pt/wayback/20160520185002/https%3A//www.iqt.org/ |archive-date=20 May 2016 |dead-url=yes |df=dmy-all </ref> (a venture capital fund, largely funded by the US Intelligence Community, to stimulate new technologies through private sector entrepreneurs) brought up companies like Language Weaver. Currently the military community is interested in translation and processing of languages like Arabic machine translation|Arabic, Pashto language|Pashto, and Dari (Eastern Persian)|Dari.Citation needed|date=February 2007 Within these languages, the focus is on key phrases and quick communication between military members and civilians through the use of mobile phone apps.<ref>cite web |last=Gallafent |first=Alex |title=Machine Translation for the Military |journal=PRI's The World |publisher=PRI's The World |date=26 Apr 2011 |accessdate=17 Sep 2013 |url=http://www.theworld.org/2011/04/machine-translation-military/</ref> The Information Processing Technology Office in DARPA hosts programs like DARPA TIDES program|TIDES and Babylon translator. US Air Force has awarded a $1 million contract to develop a language translation technology.<ref>cite web|last=Jackson |first=William |url=http://gcn.com/articles/2003/09/09/air-force-wants-to-build-a-universal-translator.aspx |title=GCN – Air force wants to build a universal translator |publisher=Gcn.com |date=9 September 2003 |accessdate=2012-06-12</ref>

The notable rise of social networking on the web in recent years has created yet another niche for the application of machine translation software – in utilities such as Facebook, or instant messaging clients such as Skype, GoogleTalk, MSN Messenger, etc. – allowing users speaking different languages to communicate with each other. Machine translation applications have also been released for most mobile devices, including mobile telephones, pocket PCs, PDAs, etc. Due to their portability, such instruments have come to be designated as mobile translation tools enabling mobile business networking between partners speaking different languages, or facilitating both foreign language learning and unaccompanied traveling to foreign countries without the need of the intermediation of a human translator.

Despite being labelled as an unworthy competitor to human translation in 1966 by the Automated Language Processing Advisory Committee put together by the United States government,<ref>http://www.nap.edu/html/alpac_lm/ARC000005.pdf</ref> the quality of machine translation has now been improved to such levels that its application in online collaboration and in the medical field are being investigated. The application of this technology in medical settings where human translators are absent is another topic of research, but difficulties arise due to the importance of accurate translations in medical diagnoses.<ref>cite web|url=http://www.cfp.ca/content/59/4/382.full|title=Using machine translation in clinical practice|publisher=</ref>

Evaluation
Main|Evaluation of machine translation
There are many factors that affect how machine translation systems are evaluated. These factors include the intended use of the translation, the nature of the machine translation software, and the nature of the translation process.

Different programs may work well for different purposes. For example, statistical machine translation (SMT) typically outperforms example-based machine translation (EBMT), but researchers found that when evaluating English to French translation, EBMT performs better.<ref name="Way 295–309">cite journal|last=Way|first=Andy|author2=Nano Gough|title=Comparing Example-Based and Statistical Machine Translation|journal=Natural Language Engineering|date=20 September 2005|volume=11|issue=3|pages=295–309|doi=10.1017/S1351324905003888|url=http://journals.cambridge.org/abstract_S1351324905003888|accessdate=2014-03-23</ref> The same concept applies for technical documents, which can be more easily translated by SMT because of their formal language.

In certain applications, however, e.g., product descriptions written in a controlled language, a dictionary-based machine translation|dictionary-based machine-translation system has produced satisfactory translations that require no human intervention save for quality inspection.<ref>Muegge (2006), "[http://www.mt-archive.info/Aslib-2006-Muegge.pdf Fully Automatic High Quality Machine Translation of Restricted Text: A Case Study]," in ''Translating and the computer 28. Proceedings of the twenty-eighth international conference on translating and the computer, 16–17 November 2006, London'', London: Aslib. ISBN|978-0-85142-483-5.</ref>

There are various means for evaluating the output quality of machine translation systems. The oldest is the use of human judges<ref>cite web |url=http://www.morphologic.hu/public/mt/2008/compare12.htm |title=Comparison of MT systems by human evaluation, May 2008 |publisher=Morphologic.hu |accessdate=2012-06-12 |archive-url=https://web.archive.org/web/20120419072313/http://www.morphologic.hu/public/mt/2008/compare12.htm |archive-date=19 April 2012 |dead-url=yes |df=dmy-all </ref> to assess a translation's quality. Even though human evaluation is time-consuming, it is still the most reliable method to compare different systems such as rule-based and statistical systems.<ref>Anderson, D.D. (1995). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.961.5377&rep=rep1&type=pdf Machine translation as a tool in second language learning]. CALICO Journal. 13(1). 68–96.</ref> Automated means of evaluation include Bilingual evaluation understudy|BLEU, NIST (metric)|NIST, METEOR, and LEPOR.<ref>Han et al. (2012), "[http://repository.umac.mo/jspui/bitstream/10692/1747/1/10205_0_%5B2012-12-08~15%5D%20C.%20%28COLING2012%29%20LEPOR.pdf LEPOR: A Robust Evaluation Metric for Machine Translation with Augmented Factors]," in ''Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012): Posters, pages 441–450'', Mumbai, India.</ref>

Relying exclusively on unedited machine translation ignores the fact that communication in natural language|human language is context-embedded and that it takes a person to comprehend the context of the original text with a reasonable degree of probability. It is certainly true that even purely human-generated translations are prone to error. Therefore, to ensure that a machine-generated translation will be useful to a human being and that publishable-quality translation is achieved, such translations must be reviewed and edited by a human.<ref>J.M. Cohen observes (p.14): "Scientific translation is the aim of an age that would reduce all activities to Technology|techniques. It is impossible however to imagine a literary-translation machine less complex than the human brain itself, with all its knowledge, reading, and discrimination."</ref> The late Claude Piron wrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolve ambiguity|ambiguities in the source text, which the grammatical and Lexical (semiotics)|lexical exigencies of the target language require to be resolved. Such research is a necessary prelude to the pre-editing necessary in order to provide input for machine-translation software such that the output will not be garbage in garbage out|meaningless.<ref name="NIST">See the [https://www.nist.gov/speech/tests/mt/ annually performed NIST tests since 2001] and Bilingual Evaluation Understudy</ref>

In addition to disambiguation problems, decreased accuracy can occur due to varying levels of training data for machine translating programs. Both example-based and statistical machine translation rely on a vast array of real example sentences as a base for translation, and when too many or too few sentences are analyzed accuracy is jeopardized. Researchers found that when a program is trained on 203,529 sentence pairings, accuracy actually decreases.<ref name="Way 295–309"/> The optimal level of training data seems to be just over 100,000 sentences, possibly because as training data increases, the number of possible sentences increases, making it harder to find an exact translation match.

Using machine translation as a teaching tool
Although there have been concerns about machine translation's accuracy, Dr. Ana Nino of the University of Manchester has researched some of the advantages in utilizing machine translation in the classroom.  One such pedagogical method is called using "MT as a Bad Model."<ref name="Nino, Ana 2009">Nino, Ana. "[https://www.academia.edu/download/36295291/Machine_translation_in_foreign_language_learning.pdf Machine Translation in Foreign Language Learning: Language Learners' and Tutors' Perceptions of Its Advantages and Disadvantages]" ReCALL: the Journal of EUROCALL 21.2 (May 2009) 241–258.</ref>  MT as a Bad Model forces the language learner to identify inconsistencies or incorrect aspects of a translation; in turn, the individual will (hopefully) possess a better grasp of the language.  Dr. Nino cites that this teaching tool was implemented in the late 1980s.  At the end of various semesters, Dr. Nino was able to obtain survey results from students who had used MT as a Bad Model (as well as other models.)  Overwhelmingly, students felt that they had observed improved comprehension, lexical retrieval, and increased confidence in their target language.<ref name="Nino, Ana 2009"/>

Machine translation and signed languages
main|Machine translation of sign languages
In the early 2000s, options for machine translation between spoken and signed languages were severely limited. It was a common belief that deaf individuals could use traditional translators. However, stress, intonation, pitch, and timing are conveyed much differently in spoken languages compared to signed languages. Therefore, a deaf individual may misinterpret or become confused about the meaning of written text that is based on a spoken language.<ref name="Zhao, L. 2000">Zhao, L., Kipper, K., Schuler, W., Vogler, C., & Palmer, M. (2000). [http://repository.upenn.edu/cgi/viewcontent.cgi?article=1043&context=hms A Machine Translation System from English to American Sign Language]. Lecture Notes in Computer Science, 1934: 54–67.</ref>

Researchers Zhao, et al. (2000), developed a prototype called TEAM (translation from English to ASL by machine) that completed English to American Sign Language (ASL) translations. The program would first analyze the syntactic, grammatical, and morphological aspects of the English text. Following this step, the program accessed a sign synthesizer, which acted as a dictionary for ASL. This synthesizer housed the process one must follow to complete ASL signs, as well as the meanings of these signs. Once the entire text is analyzed and the signs necessary to complete the translation are located in the synthesizer, a computer generated human appeared and would use ASL to sign the English text to the user.<ref name="Zhao, L. 2000"/>

Copyright
Only creative work|works that are originality|original are subject to copyright protection, so some scholars claim that machine translation results are not entitled to copyright protection because MT does not involve creativity.<ref>cite web|url=http://www.seo-translator.com/machine-translation-no-copyright-on-the-result/|title=Machine Translation: No Copyright On The Result?|accessdate=24 November 2012|publisher=SEO Translator, citing Zimbabwe Independent</ref> The copyright at issue is for a derivative work; the author of the originality|original work in the original language does not lose his rights when a work is translated: a translator must have permission to publishing|publish a translation.

See also
div col|colwidth=18em
*Comparison of machine translation applications
*Statistical machine translation
*Controlled language in machine translation
*Cache language model
*Computational linguistics
*Universal Networking Language
*Computer-assisted translation and Translation memory
*Foreign language writing aid
*Controlled natural language
*Fuzzy matching
*Postediting
*History of machine translation
*Human language technology
*Humour in translation ("howlers")
*Language and Communication Technologies
*Language barrier
*List of emerging technologies
*List of research laboratories for machine translation
*Neural machine translation
*Pseudo-translation
*Round-trip translation
*Translation#Machine translation|Translation
*Translation memory
*Universal translator
*Phraselator
*Mobile translation
*ULTRA (machine translation system)
*Comparison of different machine translation approaches
*OpenLogos
div col end

Notes
reflist|30em

Further reading
* Citation |last=Cohen |first=J. M. |editor-last= |editor-first= |contribution=Translation |title=Encyclopedia Americana |location= |publisher= |year=1986 |volume=27 |pages=12–15 |isbn= |doi= |ref=none
*cite book |last=Hutchins |first=W. John |authorlink=W. John Hutchins |first2=Harold L. |last2=Somers |year=1992 |title=An Introduction to Machine Translation |url=http://www.hutchinsweb.me.uk/IntroMT-TOC.htm |publisher=Academic Press |location=London |isbn=0-12-362830-X
* Lewis-Kraus, Gideon, "Tower of Babble", ''New York Times Magazine'', June 7, 2015, pp.&nbsp;48–52.

External links
Wikiversity|Topic:Computational linguistics
* [http://www.omniglot.com/language/articles/machinetranslation.htm The Advantages and Disadvantages of Machine Translation]
* [http://www.eamt.org/iamt.php International Association for Machine Translation (IAMT)]
*[http://www.mt-archive.info Machine Translation Archive] by W. John Hutchins|John Hutchins. An electronic repository (and bibliography) of articles, books and papers in the field of machine translation and computer-based translation technology
*[http://www.hutchinsweb.me.uk/ Machine translation (computer-based translation)] – Publications by John Hutchins (includes PDF format|PDFs of several books on machine translation)
*[https://web.archive.org/web/20080120192259/http://bowland-files.lancs.ac.uk/monkey/ihe/mille/paper2.htm Machine Translation and Minority Languages]
*[http://www.foreignword.com/Technology/art/Hutchins/hutchins99.htm John Hutchins 1999]

Natural Language Processing
Approaches to machine translation
Emerging technologies

Authority control

Category:Artificial intelligence applications
Category:Computational linguistics
Category:Machine translation|*
Category:Computer-assisted translation
Category:Tasks of natural language processing