Statistical learning is the ability for humans and other animals to extract statistical regularities from the world around them to learn about the environment. Although statistical learning is now thought to be a generalized learning mechanism, the phenomenon was first identified in human infant language acquisition.

The earliest evidence for these statistical|statistics learning abilities comes from a study by Jenny Saffran, Richard N. Aslin|Richard Aslin, and Elissa L. Newport|Elissa Newport, in which 8-month-old infants were presented with nonsense streams of monotone speech. Each stream was composed of four three-syllable “pseudowords” that were repeated randomly. After exposure to the speech streams for two minutes, infants reacted differently to hearing “pseudowords” as opposed to “nonwords” from the speech stream, where nonwords were composed of the same syllables that the infants had been exposed to, but in a different order. This suggests that infants are able to learn statistical relationships between syllables even with very limited exposure to a language. That is, infants learn which syllables are always paired together and which ones only occur together relatively rarely, suggesting that they are parts of two different units. This method of learning is thought to be one way that children learn which groups of syllables form individual words.

Since the initial discovery of the role of statistical learning in lexical acquisition, the same mechanism has been proposed for elements of phonology|phonological acquisition,  and syntax|syntactical acquisition, as well as in non-linguistic domains. Further research has also indicated that statistical learning is likely a domain-general and even species-general learning mechanism, occurring for visual as well as auditory information, and in both primates and non-primates.

Lexical Acquisition
The role of statistical learning in language acquisition has been particularly well documented in the area of lexicon|lexical acquisition.<ref name="Saffran (2003)">cite journal|last=Saffran|first=Jenny R.|title=Statistical language learning: mechanisms and constraints|journal=Current Directions in Psychological Science|year=2003|volume=12|issue=4|pages=110–114|doi=10.1111/1467-8721.01243</ref> One important contribution to infants' understanding of segmenting words from a continuous stream of speech is their ability to recognize statistical regularities of the speech heard in their environments.<ref name="Saffran (2003)" /> Although many factors play an important role, this specific mechanism is powerful and can operate over a short time scale.<ref name="Saffran (2003)" />

=Original Findings=
File:Spectrogram-19thC.png|right|thumbnail|A spectrogram of a male speaker saying the phrase "nineteenth century." There is no clear demarcation where one word ends and the next begins.

It is a well-established finding that, unlike written language, spoken language does not have any clear boundaries between words; spoken language is a continuous stream of sound rather than individual words with silences between them.<ref name="Brent & Cartwright, 1996">cite journal|last=Brent|first=Michael R.|author2=Cartwright, Timothy A. |title=Distributional regularity and phonotactic constraints are useful for segmentation|journal=Cognition|year=1996|volume=61|issue=1–2|pages=93–125|doi=10.1016/S0010-0277(96)00719-6</ref> This lack of segmentation between linguistic units presents a problem for young children learning language, who must be able to pick out individual units from the continuous speech streams that they hear.<ref name="Saffran et al. (1996)">cite journal|last=Saffran|first=J. R.|author2=Aslin, R. N. |author3=Newport, E. L. |title=Statistical Learning by 8-Month-Old Infants|journal=Science|year=1996|volume=274|issue=5294|pages=1926–1928|doi=10.1126/science.274.5294.1926|pmid=8943209</ref> One proposed method of how children are able to solve this problem is that they are attentive to the statistical regularities of the world around them.<ref name="Brent & Cartwright, 1996" /><ref name="Saffran et al. (1996)" /> For example, in the phrase "pretty baby," children are more likely to hear the sounds ''pre'' and ''ty'' heard together during the entirety of the lexical input around them than they are to hear the sounds ''ty'' and ''ba'' together.<ref name="Saffran et al. (1996)" /> In an artificial grammar learning study with adult participants, Saffran, Newport, and Aslin found that participants were able to locate word boundaries based only on transitional probabilities, suggesting that adults are capable of using statistical regularities in a language-learning task.<ref name="Saffran, Newport, et al. (1996)">cite journal|last=Saffran|first=Jenny R.|author2=Newport, Elissa L. |author3=Aslin, Richard N. |title=Word Segmentation: The Role of Distributional Cues|journal=Journal of Memory and Language|year=1996|volume=35|issue=4|pages=606–621|doi=10.1006/jmla.1996.0032</ref> This is a robust finding that has been widely replicated.<ref name="Saffran (2003)" />

To determine if young children have these same abilities Saffran Aslin and Newport exposed 8-month-old infants to an artificial grammar.<ref name="Saffran et al. (1996)" /> The grammar was composed of four words, each composed of three nonsense syllables. During the experiment, infants heard a continuous speech stream of these words . Importantly, the speech was presented in a monotone with no cues (such as pauses, intonation, etc.) to word boundaries other than the statistical probabilities. Within a word, the transitional probability of two syllable pairs was 1.0: in the word ''bidaku'', for example, the probability of hearing the syllable ''da'' immediately after the syllable ''bi'' was 100%. Between words, however, the transitional probability of hearing a syllable pair was much lower: After any given word (e.g., ''bidaku'') was presented, one of three words could follow (in this case, ''padoti'', ''golabu'', or ''tupiro''), so the likelihood of hearing any given syllable after ''ku'' was only 33%.

To determine if infants were picking up on the statistical information, each infant was presented with multiple presentations of either a word from the artificial grammar or a nonword made up of the same syllables but presented in a random order. Infants who were presented with nonwords during the test phase listened significantly longer to these words than infants who were presented with words from the artificial grammar, showing a novelty preference for these new nonwords. However, the implementation of the test could also be due to infants learning serial-order information and not to actually learning transitional probabilities between words. That is, at test, infants heard strings such as ''dapiku'' and ''tilado'' that were never presented during learning; they could simply have learned that the syllable ''ku'' never followed the syllable ''pi''.<ref name="Saffran et al. (1996)" />

To look more closely at this issue, Saffran Aslin and Newport conducted another study in which infants underwent the same training with the artificial grammar but then were presented with either words or part-words rather than words or nonwords.<ref name="Saffran et al. (1996)" /> The part-words were syllable sequences composed of the last syllable from one word and the first two syllables from another (such as ''kupado''). Because the part-words had been heard during the time when children were listening to the artificial grammar, preferential listening to these part-words would indicate that children were learning not only serial-order information, but also the statistical likelihood of hearing particular syllable sequences. Again, infants showed greater listening times to the novel (part-) words, indicating that 8-month-old infants were able to extract these statistical regularities from a continuous speech stream.

=Further Research=
This result has been the impetus for much more research on the role of statistical learning in lexical acquisition and other areas (see <ref name="Saffran (2003)"/>). In a follow-up to the original report,<ref name="Saffran et al. (1996)" /> Richard N. Aslin|Aslin, Saffran, and Elissa L. Newport|Newport found that even when words and part words occurred equally often in the speech stream, but with different transitional probabilities between syllables of words and part words, infants were still able to detect the statistical regularities and still preferred to listen to the novel part-words over the familiarized words.<ref name="Aslin, Saffran, Newport, 1998">cite journal|last=Aslin|first=R. N.|author2=Saffran, J. R. |author3=Newport, E. L. |title=Computation of Conditional Probability Statistics by 8-Month-Old Infants|journal=Psychological Science|year=1998|volume=9|issue=4|pages=321–324|doi=10.1111/1467-9280.00063</ref> This finding provides stronger evidence that infants are able to pick up transitional probabilities from the speech they hear, rather than just being aware of frequencies of individual syllable sequences.<ref name="Saffran (2003)" />

Another follow-up study examined the extent to which the statistical information learned during this type of artificial grammar learning feeds into knowledge that infants may already have about their First language|native language.<ref name="Saffran, 2001a">cite journal|last=Saffran|first=Jenny R|title=Words in a sea of sounds: the output of infant statistical learning|journal=Cognition|year=2001a|volume=81|issue=2|pages=149–169|doi=10.1016/S0010-0277(01)00132-9</ref> Infants preferred to listen to words over part-words, whereas there was no significant difference in the nonsense frame condition. This finding suggests that even pre-linguistic infants are able to integrate the statistical cues they learn in a laboratory into their previously-acquired knowledge of a language.<ref name="Saffran (2003)" /><ref name="Saffran, 2001a" /> In other words, once infants have acquired some linguistic knowledge, they incorporate newly acquired information into that previously-acquired learning.

A related finding indicates that slightly older infants can acquire both lexical and grammatical regularities from a single set of input,<ref name="Saffran & Wilson, 2003">cite journal|last=Saffran|first=Jenny R.|author2=Wilson, Diana P. |title=From Syllables to Syntax: Multilevel Statistical Learning by 12-Month-Old Infants|journal=Infancy|year=2003|volume=4|issue=2|pages=273–284|doi=10.1207/S15327078IN0402_07</ref> suggesting that they are able to use outputs of one type of statistical learning (cues that lead to the discovery of word boundaries) as input to a second type (cues that lead to the discovery of syntactical regularities.<ref name="Saffran (2003)" /><ref name="Saffran & Wilson, 2003" /> At test, 12-month-olds preferred to listen to sentences that had the same grammatical structure as the artificial language they had been tested on rather than sentences that had a different (ungrammatical) structure. Because learning grammatical regularities requires infants to be able to determine boundaries between individual words, this indicates that infants who are still quite young are able to acquire multiple levels of language knowledge (both lexical and syntactical) simultaneously, indicating that statistical learning is a powerful mechanism at play in language learning.<ref name="Saffran (2003)" /><ref name="Saffran & Wilson, 2003" />

Despite the large role that statistical learning appears to play in lexical acquisition, it is likely not the only mechanism by which infants learn to segment words. Statistical learning studies are generally conducted with artificial grammars that have no cues to word boundary information other than transitional probabilities between words.  Real speech, though, has many different types of cues to word boundaries, including prosody (linguistics)|prosodic and phonotactics|phonotactic information.<ref name="Mattys et al., 1999">cite journal|last=Mattys|first=Sven L.|author2=Jusczyk, Peter W. |author3=Luce, Paul A. |author4= Morgan, James L. |title=Phonotactic and Prosodic Effects on Word Segmentation in Infants|journal=Cognitive Psychology|year=1999|volume=38|issue=4|pages=465–494|doi=10.1006/cogp.1999.0721</ref>

Together, the findings from these studies of statistical learning in language acquisition indicate that statistical properties of the language are a strong cue in helping infants learn their first language.<ref name="Saffran (2003)" />

Phonological Acquisition
There is much evidence that statistical learning is an important component of both discovering which phonemes are important for a given language and which contrasts within phonemes are important.<ref name="Gomez & Gerken (2000)">cite journal|last=Gómez|first=Rebecca L.|author2=Gerken, LouAnn |title=Infant artificial language learning and language acquisition|journal=Trends in Cognitive Sciences|year=2000|volume=4|issue=5|pages=178–186|doi=10.1016/S1364-6613(00)01467-4|pmid=10782103</ref><ref name="Werker et al. (2012)">cite journal|last=Werker|first=J. F.|author2=Yeung, H. H. |author3=Yoshida, K. A. |title=How Do Infants Become Experts at Native-Speech Perception?|journal=Current Directions in Psychological Science|year=2012|volume=21|issue=4|pages=221–226|doi=10.1177/0963721412449459</ref><ref name="Kuhl, 2004">cite journal|last=Kuhl|first=Patricia K.|title=Early language acquisition: cracking the speech code|journal=Nature Reviews Neuroscience|year=2004|volume=5|issue=11|pages=831–843|doi=10.1038/nrn1533|pmid=15496861</ref> Having this knowledge is important for aspects of both speech perception and speech production.

=Distributional Learning=
Since the discovery of infants’ statistical learning abilities in word learning, the same general mechanism has also been studied in other facets of language learning. For example, it is well-established that infants can discriminate between phonemes of many different languages but eventually become unable to discriminate between phonemes that do not appear in their native language;<ref name="Maye et al. 2002">cite journal|last=Maye|first=Jessica|author2=Werker, Janet F |author3=Gerken, LouAnn |title=Infant sensitivity to distributional information can affect phonetic discrimination|journal=Cognition|year=2002|volume=82|issue=3|pages=B101–B111|doi=10.1016/S0010-0277(01)00157-3</ref> however, it was not clear how this decrease in discriminatory ability came about. Maye et al. suggested that the mechanism responsible might be a statistical learning mechanism in which infants track the distributional regularities of the sounds in their native language.<ref name="Maye et al. 2002" /> To test this idea, Maye et al. exposed 6- and 8-month-old infants to a continuum of speech sounds that varied on the degree to which they were voice onset time|voiced. The distribution that the infants heard was either bimodal distribution|bimodal, with sounds from both ends of the voicing continuum heard most often, or unimodality|unimodal, with sounds from the middle of the distribution heard most often. The results indicated that infants from both age groups were sensitive to the distribution of phonemes. At test, infants heard either non-alternating (repeated exemplars of tokens 3 or 6 from an 8-token continuum) or alternating (exemplars of tokens 1 and 8) exposures to specific phonemes on the continuum. Infants exposed to the bimodal distribution listened longer to the alternating trials than the non-alternating trials while there was no difference in listening times for infants exposed to the unimodal distribution. This finding indicates that infants exposed the bimodal distribution were better able to discriminate sounds from the two ends of the distribution than were infants in the unimodal condition, regardless of age. This type of statistical learning differs from that used in lexical acquisition, as it requires infants to track frequencies rather than transitional probabilities, and has been named “distributional learning.”<ref name="Werker et al. (2012)"/>

Distributional learning has also been found to help infants contrast two phonemes that they initially have difficulty in discriminating between. Maye, Weiss, and Aslin found that infants who were exposed to a bimodal distribution of a non-native contrast that was initially difficult to discriminate were better able to discriminate the contrast than infants exposed to a unimodal distribution of the same contrast.<ref name="Maye et al. 2008">cite journal|last=Maye|first=Jessica|author2=Weiss, Daniel J. |author3=Aslin, Richard N. |title=Statistical phonetic learning in infants: facilitation and feature generalization|journal=Developmental Science|year=2008|volume=11|issue=1|pages=122–134|doi=10.1111/j.1467-7687.2007.00653.x</ref> Maye et al. also found that infants were able to abstract features of a contrast (i.e., voicing onset time) and generalize that feature to the same type of contrast at a different place of articulation, a finding that has not been found in adults.

In a review of the role of distributional learning on phonological acquisition, Werker et al. note that distributional learning cannot be the only mechanism by which phonetic categories are acquired.<ref name="Werker et al. (2012)" /> However, it does seem clear that this type of statistical learning mechanism can play a role in this skill, although research is ongoing.<ref name="Werker et al. (2012)" />

=Perceptual Magnet Effect=
A related finding regarding statistical cues to phonological acquisition is a phenomenon known as the perceptual magnet effect.<ref name=Kuhl,1991>cite journal|last=Kuhl|first=Patricia K.|title=Human adults and human infants show a "perceptual magnet effect" for the prototypes of speech categories, monkeys do not|journal=Perception & Psychophysics|year=1991|volume=50|issue=2|pages=93–107|doi=10.3758/BF03212211</ref><ref name="Kuhl, 2000">cite journal|last=Kuhl|first=P. K.|title=A new view of language acquisition|journal=Proceedings of the National Academy of Sciences|year=2000|volume=97|issue=22|pages=11850–11857|doi=10.1073/pnas.97.22.11850|pmc=34178</ref><ref name="Kuhl et al. 1992">cite journal|last=Kuhl|first=P.|author2=Williams, K. |author3=Lacerda, F |author4=Stevens, K. |author5= Lindblom, B |title=Linguistic experience alters phonetic perception in infants by 6 months of age|journal=Science|year=1992|volume=255|issue=5044|pages=606–608|doi=10.1126/science.1736364|pmid=1736364</ref> In this effect, a prototypical phoneme of a person’s native language acts as a “magnet” for similar phonemes, which are perceived as belonging to the same category as the prototypical phoneme. In the original test of this effect, adult participants were asked to indicate if a given exemplar of a particular phoneme differed from a referent phoneme.<ref name=Kuhl,1991 /> If the referent phoneme is a non-prototypical phoneme for that language, both adults and 6-month-old infants show less generalization to other sounds than they do for prototypical phonemes, even if the subjective distance between the sounds is the same.<ref name=Kuhl,1991 /><ref name="Kuhl et al. 1992" /> That is, adults and infants are both more likely to notice that a particular phoneme differs from the referent phoneme if that referent phoneme is a non-prototypical exemplar than if it is a prototypical exemplar. The prototypes themselves are apparently discovered through a distributional learning process, in which infants are sensitive to the frequencies with which certain sounds occur and treat those that occur most often as the prototypical phonemes of their language.<ref name="Kuhl, 2004"/>

Syntactical Acquisition
A statistical learning device has also been proposed as a component of syntactical acquisition for young children.<ref name="Saffran (2003)" /><ref name="Gomez & Gerken (2000)" /><ref name="Seidenberg (1997)">cite journal|last=Seidenberg|first=M. S.|title=Language Acquisition and Use: Learning and Applying Probabilistic Constraints|journal=Science|year=1997|volume=275|issue=5306|pages=1599–1603|doi=10.1126/science.275.5306.1599</ref> Early evidence for this mechanism came largely from studies of computer modeling or analyses of natural language corpora.<ref name="Cartwright & Brent, 1997">cite journal|last=Cartwright|first=Timothy A.|author2=Brent, Michael R. |title=Syntactic categorization in early language acquisition: formalizing the role of distributional analysis|journal=Cognition|year=1997|volume=63|issue=2|pages=121–170|doi=10.1016/S0010-0277(96)00793-7</ref><ref name="Redington et al., 1998">cite journal|last=Redington|first=M|title=Distributional information: A powerful cue for acquiring syntactic categories|journal=Cognitive Science|year=1998|volume=22|issue=4|pages=425–469|doi=10.1016/S0364-0213(99)80046-9</ref> These early studies focused largely on distributional information specifically rather than statistical learning mechanisms generally. Specifically, in these early papers it was proposed that children created templates of possible sentence structures involving unnamed categories of word types (i.e., nouns or verbs, although children would not put these labels on their categories). Children were thought to learn which words belonged to the same categories by tracking the similar contexts in which words of the same category appeared.

Later studies expanded these results by looking at the actual behavior of children or adults who had been exposed to artificial grammars.<ref name="Gomez & Gerken (2000)" /> These later studies also considered the role of statistical learning more broadly than the earlier studies, placing their results in the context of the statistical learning mechanisms thought to be involved with other aspects of language learning, such as lexical acquisition.

=Experimental Results=
Evidence from a series of four experiments conducted by Gomez and LouAnn Gerken|Gerken suggests that children are able to generalize grammar|grammatical structures with less than two minutes of exposure to an artificial grammar.<ref name="Gomez & Gerken (2000)" /><ref name="Gomez & Gerken, 1999">cite journal|last=Gomez|first=Rebecca L|author2=Gerken, LouAnn |title=Artificial grammar learning by 1-year-olds leads to specific and abstract knowledge|journal=Cognition|year=1999|volume=70|issue=2|pages=109–135|doi=10.1016/S0010-0277(99)00003-7</ref> In the first experiment, 11-12 month-old infants were trained on an artificial grammar composed of nonsense words with a set grammatical structure. At test, infants heard both novel grammatical and ungrammatical sentences. Infants oriented longer towards the grammatical sentences, in line with previous research that suggests that infants generally orient for a longer amount of time to natural instances of language rather than altered instances of language e.g.,.<ref name="Hirsh-Pasek et al., 1987">cite journal|last1=Hirsh-Pasek|first1=Kathy|last2=Kemler Nelson|first2=Deborah G.|last3=Jusczyk|first3=Peter W.|last4=Cassidy|first4=Kimberly Wright|last5=Druss|first5=Benjamin|last6=Kennedy|first6=Lori|title=Clauses are perceptual units for young infants|journal=Cognition|volume=26|issue=3|year=1987|pages=269–286|issn=0010-0277|doi=10.1016/S0010-0277(87)80002-1</ref> (This familiarity preference differs from the novelty preference generally found in word-learning studies, due to the differences between lexical acquisition and syntactical acquisition.) This finding indicates that young children are sensitive to the grammatical structure of language even after minimal exposure. Gomez and Gerken also found that this sensitivity is evident when ungrammatical transitions are located in the middle of the sentence (unlike in the first experiment, in which all the errors occurred at the beginning and end of the sentences), that the results could not be due to an innate preference for the grammatical sentences caused by something other than grammar, and that children are able to generalize the grammatical rules to new vocabulary.

Together these studies suggest that infants are able to extract a substantial amount of syntactic knowledge even from limited exposure to a language.<ref name="Gomez & Gerken (2000)" /><ref name="Gomez & Gerken, 1999"/> Children apparently detected grammatical anomalies whether the grammatical violation in the test sentences occurred at the end or in the middle of the sentence. Additionally, even when the individual words of the grammar were changed, infants were still able to discriminate between grammatical and ungrammatical strings during the test phase. This generalization indicates that infants were not learning vocabulary-specific grammatical structures, but abstracting the general rules of that grammar and applying those rules to novel vocabulary. Furthermore, in all four experiments, the test of grammatical structures occurred five minutes after the initial exposure to the artificial grammar had ended, suggesting that the infants were able to maintain the grammatical abstractions they had learned even after a short delay.

In a similar study, Saffran found that adults and older children (first grade|first and second grade children) were also sensitive to syntactical information after exposure to an artificial language which had no cues to phrase structure other than the statistical regularities that were present.<ref name="Saffran 2001b">cite journal|last=Saffran|first=Jenny R.|title=The Use of Predictive Dependencies in Language Learning|journal=Journal of Memory and Language|year=2001b|volume=44|issue=4|pages=493–515|doi=10.1006/jmla.2000.2759</ref> Both adults and children were able to pick out sentences that were ungrammatical at a rate greater than chance, even under an “incidental” exposure condition in which participants’ primary goal was to complete a different task while hearing the language.

Although the number of studies dealing with statistical learning of syntactical information is limited, the available evidence does indicate that the statistical learning mechanisms are likely a contributing factor to children’s ability to learn their language.<ref name="Gomez & Gerken (2000)"/><ref name="Seidenberg (1997)"/>

Statistical Learning in Bilingualism
Much of the early work using statistical learning paradigms focused on the ability for children or adults to learn a single language,<ref name="Saffran (2003)" /> consistent with the process of language acquisition for monolingualism|monolingual speakers or learners. However, it is estimated that approximately 60-75% of people in the world are multilingualism|bilingual.<ref name="Schneider & Hopp, 2011">cite journal|last=Schneider|first=Harry D.|author2=Hopp, Jenna P. |title=The use of the Bilingual Aphasia Test for assessment and transcranial direct current stimulation to modulate language acquisition in minimally verbal children with autism|journal=Clinical Linguistics & Phonetics|year=2011|volume=25|issue=6–7|pages=640–654|doi=10.3109/02699206.2011.570852</ref> More recently, researchers have begun looking at the role of statistical learning for those who speak more than one language. Although there are no reviews on this topic yet, Weiss, Gerfen, and Mitchel examined how hearing input from multiple artificial languages simultaneously can affect the ability to learn either or both languages.<ref name="Weiss et al., 2009">cite journal|last=Weiss|first=Daniel J.|author2=Gerfen, Chip |author3=Mitchel, Aaron D. |title=Speech Segmentation in a Simulated Bilingual Environment: A Challenge for Statistical Learning?|journal=Language Learning and Development|year=2009|volume=5|issue=1|pages=30–49|doi=10.1080/15475440802340101|pmc=3981102</ref> Over four experiments, Weiss et al. found that, after exposure to two artificial languages, adult learners are capable of determining word boundaries in both languages when each language is spoken by a different speaker. However, when the two languages were spoken by the same speaker, participants were able learn both languages only when they were “congruent”—when the word boundaries of one language matched the word boundaries of the other. When the languages were incongruent—a syllable that appeared in the middle of a word in one language appeared at the end of the word in the other language—and spoken by a single speaker, participants were able to learn, at best, one of the two languages. A final experiment showed that the inability to learn incongruent languages spoken in the same voice was not due to syllable overlap between the languages but due to differing word boundaries.

Similar work replicates the finding that learners are able to learn two sets of statistical representations when an additional cue is present (two different male voices in this case).<ref name="Franco et al., 2012">cite journal|last=Franco|first=Ana|author2=Cleeremans, Axel |author3=Destrebecqz, Arnaud |title=Statistical Learning of Two Artificial Languages Presented Successively: How Conscious?|journal=Frontiers in Psychology|year=2011|volume=2|doi=10.3389/fpsyg.2011.00229</ref> In their paradigm, the two languages were presented consecutively, rather than interleaved as in Weiss et al.’s paradigm,<ref name="Weiss et al., 2009" /> and participants did learn the first artificial language to which they had been exposed better than the second, although participants’ performance was above chance for both languages.

While statistical learning improves and strengthens multilingualism, it appears that the inverse is not true. In a study by Yim and Rudoy<ref>cite journal|last=Yim|first=Dongsum|author2=Rudoy, John |title=Implicit Statistical Learning and Language Skills in Bilingual Children|journal=Journal of Speech, Language, and Hearing Research|date=August 2012|volume=56|pages=310–322|doi=10.1044/1092-4388(2012/11-0243)</ref> it was found that both monolingual and bilingual children perform statistical learning tasks equally well.

Antovich and Graf Estes <ref>cite journal|last= Antovich|first=Dylan M.|author2=Graf Estes, Katharine |title=Learning across languages: bilingual experience supports dual language statistical word segmentation|journal= Developmental Science|date=January 2017|doi=10.1111/desc.12548 </ref> found that 14 month old bilingual children are better than monolinguals at segmenting two different artificial languages using transitional probability cues. They suggest that a bilingual environment in early childhood trains children to rely on statistical regularities to segment the speech flow and access two lexical systems.

Limitations on Statistical Learning

=Word-Referent Mapping=
A statistical learning mechanism has also been proposed for learning the meaning of words. Specifically, Yu and Linda B. Smith|Smith conducted a pair of studies in which adults were exposed to pictures of objects and heard nonsense words.<ref name="Yu & Smith, 2007">cite journal|last=Yu|first=C.|author2=Smith, L. B. |title=Rapid Word Learning Under Uncertainty via Cross-Situational Statistics|journal=Psychological Science|year=2007|volume=18|issue=5|pages=414–420|doi=10.1111/j.1467-9280.2007.01915.x|pmid=17576281</ref> Each nonsense word was paired with a particular object. There were 18 total word-referent pairs, and each participant was presented with either 2, 3, or 4 objects at a time, depending on the condition, and heard the nonsense word associated with one of those objects. Each word-referent pair was presented 6 times over the course of the training trials; after the completion of the training trials, participants completed a forced-alternative test in which they were asked to choose the correct referent that matched a nonsense word they were given. Participants were able to choose the correct item more often than would happen by chance, indicating, according to the authors, that they were using statistical learning mechanisms to track co-occurrence probabilities across training trials.

An alternative hypothesis is that learners in this type of task may be using a “propose-but-verify” mechanism rather than a statistical learning mechanism.<ref name="Medina et al., 2011">cite journal|last=Medina|first=T. N.|author2=Snedeker, J. |author3=Trueswell, J. C. |author4= Gleitman, L. R. |title=How words can and cannot be learned by observation|journal=Proceedings of the National Academy of Sciences|year=2011|volume=108|issue=22|pages=9014–9019|doi=10.1073/pnas.1105040108 |pmid=21576483 |pmc=3107260</ref><ref name="Trueswell et al., 2013">cite journal|last=Trueswell|first=John C.|author2=Medina, Tamara Nicol |author3=Hafri, Alon |author4= Gleitman, Lila R. |title=Propose but verify: Fast mapping meets cross-situational word learning|journal=Cognitive Psychology|year=2013|volume=66|issue=1|pages=126–156|doi=10.1016/j.cogpsych.2012.10.001 |pmid=23142693 |pmc=3529979</ref> Medina et al. and Trueswell et al. argue that, because Yu and Smith only tracked knowledge at the end of the training, rather than tracking knowledge on a trial-by-trial basis, it is impossible to know if participants were truly updating statistical probabilities of co-occurrence (and therefore maintaining multiple hypotheses simultaneously), or if, instead, they were forming a single hypothesis and checking it on the next trial.<ref name="Yu & Smith, 2007" /><ref name="Medina et al., 2011" /><ref name="Trueswell et al., 2013" /> For example, if a participant is presented with a picture of a dog and a picture of a shoe, and hears the nonsense word ''vash'' she might hypothesize that ''vash'' refers to the dog. On a future trial, she may see a picture of a shoe and a picture of a door and again hear the word ''vash''. If statistical learning is the mechanism by which word-referent mappings are learned, then the participant would be more likely to select the picture of the shoe than the door, as shoe would have appeared in conjunction with the word ''vash'' 100% of the time. However, if participants are simply forming a single hypothesis, they may fail to remember the context of the previous presentation of ''vash'' (especially if, as in the experimental conditions, there are multiple trials with other words in between the two presentations of ''vash'') and therefore be at chance in this second trial. According to this proposed mechanism of word learning, if the participant had correctly guessed that ''vash'' referred to the shoe in the first trial, her hypothesis would be confirmed in the subsequent trial.

To distinguish between these two possibilities, Trueswell et al. conducted a series of experiments similar to those conducted by Yu and Smith except that participants were asked to indicate their choice of the word-referent mapping on each trial, and only a single object name was presented on each trial (with varying numbers of objects).<ref name="Yu & Smith, 2007" /><ref name="Trueswell et al., 2013" /> Participants would therefore have been at chance when they are forced to make a choice in their first trial. The results from the subsequent trials indicate that participants were not using a statistical learning mechanism in these experiments, but instead were using a propose-and-verify mechanism, holding only one potential hypothesis in mind at a time. Specifically, if participants had chosen an incorrect word-referent mapping in an initial presentation of a nonsense word (from a display of five possible choices), their likelihood of choosing the correct word-referent mapping in the next trial of that word was still at chance, or 20%. If, though, the participant had chosen the correct word-referent mapping on an initial presentation of a nonsense word, the likelihood of choosing the correct word-referent mapping on the subsequent presentation of that word was approximately 50%. These results were also replicated in a condition where participants were choosing between only two alternatives. These results suggest that participants did not remember the surrounding context of individual presentations and were therefore not using statistical cues to determine the word-referent mappings. Instead, participants make a hypothesis regarding a word-referent mapping and, on the next presentation of that word, either confirm or reject the hypothesis accordingly.

Overall, these results, along with similar results from Medina et al., indicate that word meanings may not be learned through a statistical learning mechanism in these experiments, which ask participants to hypothesize a mapping even on the first occurrence (i.e., not cross-situationally).<ref name="Medina et al., 2011" /> However, when the propose-but-verify mechanism has been compared to a statistical learning mechanism, the former was unable to reproduce individual learning trajectories nor fit as well as the latter.<ref name="Kachergis et al., 2012">cite journal|last=Kachergis|first=G. N.|author2=Yu, C. |author3=Shiffrin, R. M. |title=Cross-situational word learning is better modeled by associations than hypotheses.|journal=IEEE Conference on Development and Learning / EpiRob 2012|year=2012|doi=10.1109/DevLrn.2012.6400861</ref>

=Need for Social Interaction=
Additionally, statistical learning by itself cannot account even for those aspects of language acquisition for which it has been shown to play a large role. For example, Patricia K. Kuhl|Kuhl, Tsao, and Liu found that young English-learning infants who spent time in a laboratory session with a native Mandarin Chinese|Mandarin speaker were able to distinguish between phonemes that occur in Mandarin but not in English, unlike infants who were in a control condition.<ref name="Kuhl et al., 2003">cite journal|last=Kuhl|first=P. K.|title=Foreign-language experience in infancy: Effects of short-term exposure and social interaction on phonetic learning|journal=Proceedings of the National Academy of Sciences|year=2003|volume=100|issue=15|pages=9096–9101|doi=10.1073/pnas.1532872100|pmid=12861072|pmc=166444</ref> Infants in this control condition came to the lab as often as infants in the experimental condition, but were exposed only to English; when tested at a later date, they were unable to distinguish the Mandarin phonemes. In a second experiment, the authors presented infants with audio or audiovisual recordings of Mandarin speakers and tested the infants’ ability to distinguish between the Mandarin phonemes. In this condition, infants failed to distinguish the foreign language phonemes. This finding indicates that social interaction is a necessary component of language learning and that, even if infants are presented with the raw data of hearing a language, they are unable to take advantage of the statistical cues present in that data if they are not also experiencing the social interaction.<ref name="Kuhl, 2004" />

Domain Generality
Although the phenomenon of statistical learning was first discovered in the context of language acquisition and there is much evidence of its role in that purpose, work since the original discovery has suggested that statistical learning may be a domain general skill and is likely not unique to humans.<ref name="Saffran et al. (1996)" /><ref name="Turk-Browne et al., 2005">cite journal|last=Turk-Browne|first=Nicholas B.|author2=Jungé, Justin A. |author3=Scholl, Brian J. |title=The Automaticity of Visual Statistical Learning.|journal=Journal of Experimental Psychology: General|date=1 January 2005|volume=134|issue=4|pages=552–564|doi=10.1037/0096-3445.134.4.552</ref> For example, Saffran, Johnson, Aslin, and Newport found that both adults and infants were able to learn statistical probabilities of “words” created by playing different musical tones (i.e., participants heard the musical notes D, E, and F presented together during training and were able to recognize those notes as a unit at test as compared to three notes that had not been presented together).<ref name="Saffran, Johnson, et al., 1999">cite journal|last=Saffran|first=Jenny R|author2=Johnson, Elizabeth K |author3=Aslin, Richard N |author4= Newport, Elissa L |title=Statistical learning of tone sequences by human infants and adults|journal=Cognition|year=1999|volume=70|issue=1|pages=27–52|doi=10.1016/S0010-0277(98)00075-4</ref> In non-auditory domains, there is evidence that humans are able to learn statistical visual information whether that information is presented across space, e.g.,<ref name="Fiser & Aslin, 2001">cite journal|last=Fiser|first=J.|author2=Aslin, R. N. |title=Unsupervised Statistical Learning of Higher-Order Spatial Structures from Visual Scenes|journal=Psychological Science|year=2001|volume=12|issue=6|pages=499–504|doi=10.1111/1467-9280.00392</ref> or time, e.g.,.<ref name="Fiser & Aslin, 2002">cite journal|last=Fiser|first=József|author2=Aslin, Richard N. |title=Statistical learning of higher-order temporal structure from visual shape sequences.|journal=Journal of Experimental Psychology: Learning, Memory, and Cognition|year=2002|volume=28|issue=3|pages=458–467|doi=10.1037/0278-7393.28.3.458</ref> Evidence of statistical learning has also been found in other primates, e.g.,<ref name="Newport et al., 2004">cite journal|last=Newport|first=Elissa L.|author2=Hauser, Marc D. |author3=Spaepen, Geertrui |author4= Aslin, Richard N. |title=Learning at a distance II. Statistical learning of non-adjacent dependencies in a non-human primate|journal=Cognitive Psychology|year=2004|volume=49|issue=2|pages=85–117|doi=10.1016/j.cogpsych.2003.12.002</ref> and some limited statistical learning abilities have been found even in non-primates like laboratory rat|rats.<ref name="Toro & Trobalon, 2005">cite journal|last=Toro|first=Juan M.|author2=Trobalón, Josep B.|title=Statistical computations over a speech stream in a rodent|journal=Perception & Psychophysics|year=2005|volume=67|issue=5|pages=867–875|doi=10.3758/BF03193539</ref> Together these findings suggest that statistical learning may be a generalized learning mechanism that happens to be utilized in language acquisition, rather than a mechanism that is unique to the human infant’s ability to learn his or her language(s).

Further evidence for domain general statistical learning was suggested in a study run through the University of Cornell Department of Psychology concerning visual statistical learning in infancy.  Researchers in this study questioned whether domain generality of statistical learning in infancy would be seen using visual information. After first viewing images in statistically predictable patterns, infants were then exposed to the same familiar patterns in addition to novel sequences of the same identical stimulus components. Interest in the visuals was measured by the amount of time the child looked at the stimuli in which the researchers named “looking time.” All ages of infant participants showed more interest in the novel sequence relative to the familiar sequence. In demonstrating a preference for the novel sequences (which violated the transitional probability that defined the grouping of the original stimuli) the results of the study support the likelihood of domain general statistical learning in infancy.<ref name="KirkhamSlemmer2002">cite journal|last1=Kirkham|first1=Natasha Z|last2=Slemmer|first2=Jonathan A|last3=Johnson|first3=Scott P|title=Visual statistical learning in infancy: evidence for a domain general learning mechanism|journal=Cognition|volume=83|issue=2|year=2002|pages=B35–B42|issn=0010-0277|doi=10.1016/S0010-0277(02)00004-5</ref>

References
Reflist

Category:Language acquisition