About|the cognitive process|the psychological phenomena of seeing faces in inanimate objects|Pareidolia|computer-based facial perception|Facial recognition system

Face perception is an individual's understanding and interpretation of the face, particularly the human face, especially in relation to the associated information processing in the brain.

The proportions and expressions of the human face are important to identify origin, emotional tendencies, health qualities, and some social information. From birth, faces are important in the individual's social interaction. Face perceptions are very complex as the recognition of facial expressions involves extensive and diverse areas in the brain. Sometimes, damaged parts of the brain can cause specific impairments in understanding faces or prosopagnosia.

Development
From birth, infants possess rudimentary facial processing capacities and show heightened interest in faces.<ref>Cite journal|last=Morton|first=John|last2=Johnson|first2=Mark H.|title=CONSPEC and CONLERN: A two-process theory of infant face recognition.|url=http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.98.2.164|journal=Psychological Review|language=en|volume=98|issue=2|pages=164–181|doi=10.1037/0033-295x.98.2.164|year=1991</ref><ref>Cite journal|last=Fantz|first=Robert L.|title=The Origin of Form Perception|url=http://www.nature.com/doifinder/10.1038/scientificamerican0561-66|journal=Scientific American|volume=204|issue=5|pages=66–73|doi=10.1038/scientificamerican0561-66|year=1961</ref> For example, newborns (1–3 days) have been shown to be able to recognize faces even when they are rotated up to 45 degrees.<ref name=":3">cite journal|pmid=16513867|pmc=2773688|year=2006|author1=Onitsuka|first1=T|title=Functional and structural deficits in brain regions subserving face perception in schizophrenia|journal=American Journal of Psychiatry|volume=163|issue=3|pages=455–62|last2=Niznikiewicz|first2=M. A.|last3=Spencer|first3=K. M.|last4=Frumin|first4=M|last5=Kuroki|first5=N|last6=Lucia|first6=L. C.|last7=Shenton|first7=M. E.|last8=McCarley|first8=R. W.|doi=10.1176/appi.ajp.163.3.455</ref> However, interest in faces is not continuously present in infancy and shows increases and decreases over time as the child grows older. Specifically, while newborns show a preference for faces, this behavior is reduced between one- to four months of age.<ref>Maurer, D. (1985). Infants' Perception of Facedness. In T. M. Field & N. A. Fox (Eds.), ''Social Perception in Infants'' (pp. 73-100). Norwood, NJ: Ablex Publishing Corporation.</ref> Around three months of age, a preference for faces re-emerges and interest in faces seems to peak late during the first year but then declines again slowly over the next two years of life.<ref>Cite journal|last=Libertus|first=Klaus|last2=Landa|first2=Rebecca J.|last3=Haworth|first3=Joshua L.|date=2017|title=Development of Attention to Faces during the First 3 Years: Influences of Stimulus Type|url=http://journal.frontiersin.org/article/10.3389/fpsyg.2017.01976/full|journal=Frontiers in Psychology|language=English|volume=8|doi=10.3389/fpsyg.2017.01976|issn=1664-1078</ref> The re-emergence of a preference for faces at three months of age may be influenced by the child's own motor abilities and experiences.<ref>Cite journal|last=Libertus|first=Klaus|last2=Needham|first2=Amy|date=2011-11-01|title=Reaching experience increases face preference in 3-month-old infants|url=http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2011.01084.x/abstract|journal=Developmental Science|language=en|volume=14|issue=6|pages=1355–1364|doi=10.1111/j.1467-7687.2011.01084.x|issn=1467-7687|pmid=22010895|pmc=3888836</ref><ref>Cite journal|last=Libertus|first=Klaus|last2=Needham|first2=Amy|date=2014-05-14|title=Face preference in infancy and its relation to motor activity|url=http://journals.sagepub.com/doi/10.1177/0165025414535122|journal=International Journal of Behavioral Development|language=en|volume=38|issue=6|pages=529–538|doi=10.1177/0165025414535122</ref>  Infants as young as two days of age are capable of mimicking the facial expressions of an adult, displaying their capacity to note details like mouth and eye shape as well as to move their own muscles in a way that produces similar patterns in their faces.<ref>Cite journal|last=Farroni|first=Teresa|last2=Menon|first2=Enrica|last3=Rigato|first3=Silvia|last4=Johnson|first4=Mark H.|date=2007-03-01|title=The perception of facial expressions in newborns|journal=The European Journal of Developmental Psychology|volume=4|issue=1|pages=2–13|doi=10.1080/17405620601046832|issn=1740-5629|pmc=2836746|pmid=20228970</ref><ref>cite journal|title= Discrimination and imitation of facial expressions by neonates|journal= Science|date=8 October 1982|volume= 218|issue= 4568|pages= 179–181|doi= 10.1126/science.7123230|url= http://www.sciencemag.org/content/218/4568/179| pmid = 7123230|last2= Woodson|last3= Greenberg|last4= Cohen |author1 = Tiffany M. Field|authorlink1 = Tiffany M. Field</ref> However, despite this ability, newborns are not yet aware of the emotional content encoded within facial expressions. Five-month-olds, when presented with an image of a person making a fearful expression and a person making a Happiness|happy expression, pay the same amount of attention to and exhibit similar event-related potentials (ERPs) for both. However, when seven-month-olds are given the same treatment, they focus more on the fearful face, and their event-related potential for the scared face shows a stronger initial negative central component than that for the happy face. This result indicates an increased attentional and cognitive focus toward fear that reflects the threat-salient nature of the emotion.<ref>Cite journal | title = Emergence of enhanced attention to fearful faces between 5 and 7 months of age | journal = Social Cognitive and Affective Neuroscience | volume = 4 | issue = 2 | pages = 134–142 |date=June 2009 | doi = 10.1093/scan/nsn046 | pmid = 19174536 | pmc = 2686224 | last2 = Leppänen | last3 = Mäki | last4 = Hietanen |author1 = Mikko J. Peltola|authorlink1 = Mikko J. Peltola</ref> In addition, infants' negative central components were not different for new faces that varied in the intensity of an emotional expression but portrayed the same emotion as a face they had been habituated to but were stronger for different-emotion faces, showing that seven-month-olds regarded happy and sadness|sad faces as distinct emotive categories.<ref name="ReferenceA">Cite journal | title = Categorical representation of facial expressions in the infant brain | journal = Infancy (journal)|Infancy | volume = 14 | issue = 3 | pages = 346–362 |date=May 2009 | doi = 10.1080/15250000902839393 | pmid = 20953267 | last1 = Leppanen | first1 = Jukka | last2 = Richmond | first2 = Jenny | last3 = Vogel-Farley | first3 = Vanessa | last4 = Moulson | first4 = Margaret | last5 = Nelson | first5 = Charles | pmc = 2954432</ref>  While seven-month-olds have been found to focus more on fearful faces, another study by Jessen, Altvater-Mackensen, and Grossmann found that "happy expressions elicit enhanced sympathetic arousal in infants" both when facial expressions were presented subliminally and when they were presented supraliminally, or in a way that the infants were consciously aware of the stimulus.<ref name=":0">Cite journal|last=Jessen|first=Sarah|last2=Altvater-Mackensen|first2=Nicole|last3=Grossmann|first3=Tobias|date=2016-05-01|title=Pupillary responses reveal infants' discrimination of facial emotions independent of conscious perception|url=http://www.sciencedirect.com/science/article/pii/S0010027716300385|journal=Cognition|volume=150|pages=163–169|doi=10.1016/j.cognition.2016.02.010|pmid=26896901</ref>  These results show that conscious awareness of a stimulus is not connected to an infant's reaction to that stimulus.<ref name=":0" />

The recognition of faces is an important neurological mechanism that individuals in society use every day. Jeffrey and Rhodes<ref>cite journal|last=Jeffery|first=L.|author2=Rhodes, G.|title=Insights into the development of face recognition mechanisms revealed by face after effects|journal=British Journal of Psychology|year= 2011|volume= 102|issue= 4|pages= 799–815|doi= 10.1111/j.2044-8295.2011.02066.x |pmid= 21988385</ref> write that faces "convey a wealth of information that we use to guide our social interactions".<ref name="Jeffery 2011 799–815">cite journal|last=Jeffery|first=L.|author2=Rhodes, G.|title=Insights into the development of face recognition mechanisms revealed by face aftereffects|journal=British Journal of Psychology|year= 2011|volume=102|issue=4|pages=799–815|doi=10.1111/j.2044-8295.2011.02066.x|pmid=21988385</ref> Emotions play a large role in our social interactions. The perception of a positive or negative emotion on a face affects the way that an individual perceives and processes that face. For example, a face that is perceived to have a negative emotion is processed in a less holistic manner than a face displaying a positive emotion.<ref>cite journal|last=Curby|first=K.M.|author2=Johnson, K.J., & Tyson A.|title=Face to face with emotion: Holistic face processing is modulated by emotional state|journal=Cognition and Emotion|year= 2012|volume= 26|issue= 1|pages= 93–102|doi= 10.1080/02699931.2011.555752|pmid= 21557121</ref>  The ability of face recognition is apparent even in early childhood. The neurological mechanisms responsible for face recognition are present by age five. Research shows that the way children process faces is similar to that of adults, but adults process faces more efficiently. The reason for this may be because of advancements in memory and cognitive functioning that occur with age.<ref name="Jeffery 2011 799–815"/>

Infants are able to comprehend facial expressions as social cues representing the feelings of other people before they are a year old. At seven months, the object of an observed face's apparent emotional reaction is relevant in processing the face. Infants at this age show greater negative central components to angry faces that are looking directly at them than elsewhere, although the direction of fearful faces' gaze produces no difference. In addition, two ERP components in the posterior part of the brain are differently aroused by the two negative expressions tested. These results indicate that infants at this age can at least partially understand the higher level of threat from anger directed at them as compared to anger directed elsewhere.<ref name="Stefanie Hoehl & Tricia Striano 2008 1752–1760" /> By at least seven months of age, infants are also able to use facial expressions to understand others' behavior. Seven-month-olds will look to facial cues to understand the motives of other people in ambiguous situations, as shown by a study in which they watched an experimenter's face longer if she took a toy from them and maintained a neutral expression than if she made a happy expression.<ref>Cite journal | author = Tricia Striano & Amrisha Vaish | title = Seven- to 9-month-old infants use facial expressions to interpret others' actions | journal = British Journal of Developmental Psychology | volume = 24 | pages = 753–760 | year = 2010 | doi = 10.1348/026151005X70319 | issue = 4 | last2 = Vaish </ref> Interest in the social world is increased by interaction with the physical environment. Training three-month-old infants to reach for objects with Velcro-covered "sticky mitts" increases the amount of attention that they pay to faces as compared to passively moving objects through their hands and non-trained control groups.<ref>Cite journal | author = Klaus Libertus & Amy Needham | title = Reaching experience increases face preference in 3-month-old infants | journal = Developmental Science | volume = 14 | issue = 6 | pages = 1355–1364 |date=November 2011 | doi = 10.1111/j.1467-7687.2011.01084.x | pmid = 22010895 | pmc = 3888836 | last2 = Needham </ref>

In following with the notion that seven-month-olds have categorical understandings of emotion, they are also capable of associating emotional prosodies with corresponding facial expressions. When presented with a happy or angry face, shortly followed by an emotionally neutral word read in a happy or angry tone, their ERPs follow different patterns. Happy faces followed by angry vocal tones produce more changes than the other incongruous pairing, while there was no such difference between happy and angry congruous pairings, with the greater reaction implying that infants held greater expectations of a happy vocal tone after seeing a happy face than an angry tone following an angry face. Considering an infant's relative immobility and thus their decreased capacity to elicit negative reactions from their parents, this result implies that experience has a role in building comprehension of facial expressions.<ref>Cite journal | title = Crossmodal integration of emotional information from face and voice in the infant brain | journal = Developmental Science | volume = 9 | issue = 3 | pages = 309–315 |date=May 2006 | doi = 10.1111/j.1467-7687.2006.00494.x | pmid = 16669802 | last2 = Striano | last3 = Friederici |author1 = Tobias Grossmann|authorlink1 = Tobias Grossmann</ref>

Several other studies indicate that early perceptual experience is crucial to the development of capacities characteristic of adult visual perception, including the ability to identify familiar people and to recognize and comprehend facial expressions.<ref name="Charles A. Nelson 2001 3–18">Cite journal | author = Charles A. Nelson | title = The development and neural bases of face recognition | journal = Infant and Child Development | volume = 10 | issue = 1–2 | pages = 3–18 |date=March–June 2001 | doi = 10.1002/icd.239</ref> The capacity to discern between faces, much like language, appears to have a broad potential in early life that is whittled down to kinds of faces that are experienced in early life.<ref name="Charles A. Nelson 2001 3–18"/> Infants can discern between macaque faces at six months of age, but, without continued exposure, cannot at nine months of age. Being shown photographs of macaques during this three-month period gave nine-month-olds the ability to reliably distinguish between unfamiliar macaque faces.<ref>Cite journal | title = Plasticity of face processing in infancy | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 102 | issue = 14 | pages = 5297–5300 |date=April 2005 | doi = 10.1073/pnas.0406627102 | pmid = 15790676 | pmc = 555965| last2 = Scott | last3 = Kelly | last4 = Shannon | last5 = Nicholson | last6 = Coleman | last7 = Nelson |author1 = O. Pascalis|authorlink1 = O. Pascalis</ref>

The neural substrates of face perception in infants are likely similar to those of adults, but the limits of imaging technology that are feasible for use with infants currently prevent very specific localization of function as well as specific information from subcortical areas<ref name="Emi Nakato, Yumiko Otsuka, So Kanazawa, Masami K. Yamaguchi & Ryusuke Kakigi 2011 1600–1606">Cite journal | title = Distinct differences in the pattern of hemodynamic response to happy and angry facial expressions in infants--a near-infrared spectroscopic study | journal = NeuroImage | volume = 54 | issue = 2 | pages = 1600–1606 |date=January 2011 | doi = 10.1016/j.neuroimage.2010.09.021 | pmid = 20850548 | last2 = Otsuka | last3 = Kanazawa | last4 = Yamaguchi | last5 = Kakigi |author1 = Emi Nakato|authorlink1 = Emi Nakato</ref> like the amygdala, which is active in the perception of facial expression in adults.<ref name="Charles A. Nelson 2001 3–18"/> In a study on healthy adults, it was shown that faces are likely to be processed, in part, via a retinotectal (subcortical) pathway.<ref>cite journal |author=Awasthi B, Friedman J,  Williams, MA| title=Processing of low spatial frequency faces at periphery in choice reaching tasks|journal=Neuropsychologia | volume = 49 | issue = 7 | pages = 2136–41 | year = 2011 | doi = 10.1016/j.neuropsychologia.2011.03.003 |pmid=21397615| last2=Friedman| last3=Williams</ref>

However, there is activity near the fusiform gyrus,<ref name="Emi Nakato, Yumiko Otsuka, So Kanazawa, Masami K. Yamaguchi & Ryusuke Kakigi 2011 1600–1606"/> as well as in occipital areas.<ref name="Stefanie Hoehl & Tricia Striano 2008 1752–1760">
Cite journal
 | author = Stefanie Hoehl & Tricia Striano 
| title = Neural processing of eye gaze and threat-related emotional facial expressions in infancy 
| journal = Child Development (journal)|Child Development | volume = 79 
| issue = 6 
| pages = 1752–1760 |date=November–December 2008 
| doi = 10.1111/j.1467-8624.2008.01223.x 
| pmid = 19037947 | last2 = Striano 

</ref> when infants are exposed to faces, and it varies depending on factors including facial expression and eye gaze direction.<ref name="ReferenceA"/><ref name="Stefanie Hoehl & Tricia Striano 2008 1752–1760"/>

Adult
Recognizing and perceiving faces are vital abilities needed to coexist in society.  Faces can tell things such as identity, mood, age, sex, race, and the direction that someone is looking.<ref name=":1">Cite journal|last=Quinn|first=Kimberly A.|last2=Macrae|first2=C. Neil|date=2011-11-01|title=The face and person perception: Insights from social cognition|url=http://onlinelibrary.wiley.com/doi/10.1111/j.2044-8295.2011.02030.x/abstract|journal=British Journal of Psychology|language=en|volume=102|issue=4|pages=849–867|doi=10.1111/j.2044-8295.2011.02030.x|issn=2044-8295</ref><ref name=":22">Cite journal|last=Young|first=Andrew W.|last2=de Haan|first2=Edward H. F.|last3=Bauer|first3=Russell M.|date=2008-03-01|title=Face perception: A very special issue|url=http://onlinelibrary.wiley.com/doi/10.1348/174866407X269848/abstract|journal=Journal of Neuropsychology|language=en|volume=2|issue=1|pages=1–14|doi=10.1348/174866407X269848|issn=1748-6653</ref><ref name=":42">Cite book|url=http://onlinelibrary.wiley.com/doi/10.1002/9780470478509.neubb002043/abstract|title=Handbook of Neuroscience for the Behavioral Sciences|last=Kanwisher|first=Nancy|last2=Yovel|first2=Galit|date=2009|publisher=John Wiley & Sons, Inc.|isbn=9780470478509|language=en|doi=10.1002/9780470478509.neubb002043/abstract</ref> Studies based on neuropsychology, behavior, electrophysiology, and neuro-imaging have supported the notion of a specialized mechanism for perceiving faces.<ref name=":42" /> Prosopagnosia patients demonstrate neuropsychological support for a specialized face perception mechanism as these people, due to brain damage, have deficits in facial perception, but their cognitive perception of objects remains intact. The face inversion effect provides behavioral support of a specialized mechanism as people tend to have greater deficits in task performance when prompted to react to an inverted face than to an inverted object.  Electrophysiological support comes from the finding that the N170 and M170 responses tend to be face-specific.  Neuro-imaging studies such as PET and fMRI studies have shown support for a specialized facial processing mechanism as they have identified regions of the fusiform gyrus that have higher activation during face perception tasks than other visual perception tasks.<ref name=":42" /> Theories about the processes involved in adult face perception have largely come from two sources: research on normal adult face perception and the study of impairments in face perception that are caused by acquired brain injury|brain injury or neurological illness. Novel optical illusions such as the Flashed Face Distortion Effect, in which scientific phenomenology (psychology)|phenomenology outpaces neurological theory, also provide areas for research.

One of the most widely accepted theories of face perception argues that understanding faces involves several stages:<ref name=Bruce /> from basic perceptual manipulations on the sensory information to derive details about the person (such as age, gender or attractiveness), to being able to recall meaningful details such as their name and any relevant past experiences of the individual.

This model (developed by psychologists Vicki Bruce and Andrew Young) argues that face perception might involve several independent sub-processes working in unison.
A "view centered description" is derived from the perceptual input. Simple physical aspects of the face are used to work out age, gender or basic facial expressions. Most analysis at this stage is on feature-by-feature basis. That initial information is used to create a structural model of the face, which allows it to be compared to other faces in memory, and across views. After several exposures to a face this structural code allows us to recognize that face in different contexts.<ref name=":02">Cite journal|last=Mansour|first=Jamal|last2=Lindsay|first2=Roderick|date=30 January 2010|title=Facial Recognition|url=http://onlinelibrary.wiley.com/doi/10.1002/9780470479216.corpsy0342/full|journal=Corsini Encyclopedia of Psychology|volume=|pages=|via=Wiley Online Library|doi=10.1002/9780470479216.corpsy0342</ref> This explains why the same person seen from a novel angle can still be recognized. This structural encoding can be seen to be specific for upright faces as demonstrated by the Thatcher effect. The structurally encoded representation is transferred to notional "face recognition units" that are used with "personal identity nodes" to identify a person through information from semantic memory. The natural ability to produce someone's name when presented with their face has been shown in experimental research to be damaged in some cases of brain injury, suggesting that naming may be a separate process from the memory of other information about a person.

The study of prosopagnosia (an impairment in recognizing faces which is usually caused by brain injury) has been particularly helpful in understanding how normal face perception might work. Individuals with prosopagnosia may differ in their abilities to understand faces, and it has been the investigation of these differences which has suggested that several stage theories might be correct.

Face perception is an ability that involves many areas of the brain; however, some areas have been shown to be particularly important. Brain imaging studies typically show a great deal of activity in an area of the temporal lobe known as the fusiform gyrus, an area also known to cause prosopagnosia when damaged (particularly when damage occurs on both sides). This evidence has led to a particular interest in this area and it is sometimes referred to as the ''fusiform face area'' (FFA) for that reason.<ref name="Kanwisher N, McDermott J, Chun MM 1997 4302–11">Cite journal|author=Kanwisher N, McDermott J, Chun MM |title =The fusiform face area: a module in human extrastriate cortex specialized for face perception |journal=J. Neurosci. |volume=17 |issue=11 |pages=4302–11 |date=1 June 1997 |pmid=9151747 |url= http://www.jneurosci.org/cgi/pmidlookup?view=long&pmid=9151747|last2 =McDermott |last3 =Chun </ref>

=Neuroanatomy of facial processing=
There are several parts of the brain that play a role in face perception. Rossion, Hanseeuw, and Dricot<ref>cite journal|last=Rossion|first=B.|author2=Hanseeuw, B. |author3=Dricot, L. |title=Defining face perception areas in the human brain: A large scale factorial fMRI face localizer analysis|journal=Brain and Cognition|year=2012|volume=79|issue=2|pages=138–157|doi=10.1016/j.bandc.2012.01.001|pmid=22330606</ref> used BOLD functional magnetic resonance imaging|fMRI mapping to identify activation in the brain when subjects viewed both cars and faces. The majority of BOLD fMRI studies use blood oxygen level dependent (BOLD) contrast to determine which areas of the brain are activated by various cognitive functions.<ref>cite journal|last=KannurpattiRypmaBiswal|first=S.S.B.|title=Prediction of task-related BOLD fMRI with amplitude signatures of resting-state fMRI|journal=Frontiers in Systems Neuroscience|date=March 2012|volume=6|pages=1–7|doi=10.3389/fnsys.2012.00007|last2=Rypma|first2=Bart|last3=Biswal|first3=Bharat B.</ref> They found that the occipital face area, located in the occipital lobe, the fusiform face area, the superior temporal sulcus, the amygdala, and the anterior/inferior cortex of the temporal lobe, all played roles in contrasting the faces from the cars, with the initial face perception beginning in the area and occipital face areas. This entire region links to form a network that acts to distinguish faces. The processing of faces in the brain is known as a "sum of parts" perception.<ref name="Gold 2012 427–434">cite journal|last=Gold|first=J.M.|author2=Mundy, P.J. |author3=Tjan, B.S. |title=The perception of a face is no more than the sum of its parts|journal=Psychological Science|year=2012|volume=23|issue=4|pages=427–434|doi=10.1177/0956797611427407|pmid=22395131|pmc=3410436</ref> However, the individual parts of the face must be processed first in order to put all of the pieces together. In early processing, the occipital face area contributes to face perception by recognizing the eyes, nose, and mouth as individual pieces.<ref>cite journal|last=Pitcher|first=D.|author2=Walsh, V. |author3=Duchaine, B. |title=The role of the occipital face area in the cortical face perception network|journal=Experimental Brain Research|year=2011|volume=209|issue=4|pages=481–493|doi=10.1007/s00221-011-2579-1|pmid=21318346</ref> Furthermore, Arcurio, Gold, and James<ref>cite journal|last=Arcurio|first=L.R.|author2=Gold, J.M. |author3=James, T.W. |title=The response of face-selective cortex with single face parts and part combinations|journal=Neuropsychologia|year=2012|volume=50|issue=10|pages=2454–2459|doi=10.1016/j.neuropsychologia.2012.06.016|pmid=22750118|pmc=3423083</ref> used BOLD fMRI mapping to determine the patterns of activation in the brain when parts of the face were presented in combination and when they were presented singly. The occipital face area is activated by the visual perception of single features of the face, for example, the nose and mouth, and preferred combination of two-eyes over other combinations. This research supports that the occipital face area recognizes the parts of the face at the early stages of recognition. On the contrary, the fusiform face area shows no preference for single features, because the fusiform face area is responsible for "holistic/configural" information,<ref>cite journal|last=Arcurio|first=L.R.|author2=Gold, J.M. |author3=James, T.W. |title=The response of face-selective cortex with single face parts and part combinations|journal=Neuropsychologia|year=2012|volume=50|issue=10|pages=2458|doi=10.1016/j.neuropsychologia.2012.06.016|pmid=22750118|pmc=3423083</ref> meaning that it puts all of the processed pieces of the face together in later processing. This theory is supported by the work of Gold et al.<ref name="Gold 2012 427–434"/> who found that regardless of the orientation of a face, subjects were impacted by the configuration of the individual facial features. Subjects were also impacted by the coding of the relationships between those features. This shows that processing is done by a summation of the parts in the later stages of recognition.

Facial perception has well identified, neuroanatomical correlates in the brain. During the perception of faces, major activations occur in the extrastriate areas bilaterally, particularly in the fusiform face area, the occipital face area (OFA), and the superior temporal sulcus (fSTS).<ref name="Liu">Liu J, Harris A, Kanwisher N. (2010). Perception of face parts and face configurations: An fmri study. ''Journal of Cognitive Neuroscience''. (1), 203–211.</ref><ref name="Rossion">Rossion, B., Caldara, R., Seghier, M., Schuller, A-M., Lazeyras, F., Mayer, E., (2003). A network of occipito-temporal face-sensitive areas besides the right middle fusiform gyrus is necessary for normal face processing. A Journal of Neurology, 126 11 2381-2395</ref> Perceiving an inverted human face involves increased activity in the inferior temporal cortex, while perceiving a misaligned face involves increased activity in the occipital cortex.  However, none of these results were found when perceiving a dog face, suggesting that this process may be specific to perception of human faces.<ref name=":92">Cite web|url=http://web.b.ebscohost.com/ehost/detail/detail?vid=7&sid=89cf12cb-933b-4c76-94b7-04b68f01fa7e@sessionmgr103&bdata=JnNpdGU9ZWhvc3QtbGl2ZQ#AN=17643154&db=a9h|title=Testing holistic processing hypothesis in human and animal face perception:...: EBSCOhost|website=web.b.ebscohost.com|language=en|access-date=2018-02-02Dead link|date=December 2018 |bot=InternetArchiveBot |fix-attempted=yes </ref>

The fusiform face area is located in the lateral fusiform gyrus. It is thought that this area is involved in holistic processing of faces and it is sensitive to the presence of facial parts as well as the configuration of these parts. The fusiform face area is also necessary for successful face detection and identification. This is supported by fMRI activation and studies on prosopagnosia, which involves lesions in the fusiform face area.<ref name="Liu"/><ref name="Rossion"/><ref name="McCarthy 1997"/>

The OFA is located in the inferior occipital gyrus.<ref name="Rossion"/> Similar to the FFA, this area is also active during successful face detection and identification, a finding that is supported by fMRI activation.<ref name="Liu"/> The OFA is involved and necessary in the analysis of facial parts but not in the spacing or configuration of facial parts. This suggests that the OFA may be involved in a facial processing step that occurs prior to the FFA processing.<ref name="Liu"/>

The fSTS is involved in recognition of facial parts and is not sensitive to the configuration of these parts. It is also thought that this area is involved in gaze perception.<ref name="Campbell">cite journal | last1 = Campbell | first1 = R. | last2 = Heywood | first2 = C.A. | last3 = Cowey | first3 = A. | last4 = Regard | first4 = M. | last5 = Landis | first5 = T. | year = 1990 | title = Sensitivity to eye gaze in prosopagnosic patients and monkeys with superior temporal sulcus ablation | url = | journal = Neuropsychologia | volume = 28 | issue = 11| pages = 1123–1142 | doi=10.1016/0028-3932(90)90050-x| pmid = 2290489 </ref> The fSTS has demonstrated increased activation when attending to gaze direction.<ref name="Liu"/> Recent studies have tried to delineate whether fSTS area lights up while people use gaze of others in order to establish joint attention and not fSTS but another area (the gaze following patch which is still close to fSTS but not overlapping) was found to be the core of the gaze processing system in humans.<ref name="Marquardt">cite journal | last1 = Marquardt | first1 = K. | last2 = Ramezanpour | first2 = H. | last3 = Dicke | first3 = P. | last4 = Thier | first4 = P. | year = 2017 | title = Following eye gaze activates a patch in the posterior temporal cortex that is not part of the human "face patch" system  | journal = eNeuro | volume = 4 | issue = 2| pages = 1–10 | doi=10.1523/ENEURO.0317-16.2017| pmid = 28374010 | pmc=5362938</ref>

Bilateral activation is generally shown in all of these specialized facial areas.<ref name= McCarthy>cite journal |volume=8 |issue=2 |pages=139–46 |year=1996 |pmid=9081548|name-list-format=vanc|author2=O'Leary DS|author3=Arndt S|display-authors=3|last4=Cizadlo|first4=T|last5=Hurtig|first5=R|last6=Rezai|first6=K|last7=Watkins|first7=GL|last8=Ponto|first8=LB|last9=Hichwa|first9=RD |title=Neural substrates of facial recognition|journal=The Journal of Neuropsychiatry and Clinical Neurosciences |author1=Andreasen |first1=N. C. |doi=10.1176/jnp.8.2.139</ref><ref>Cite journal|author=Haxby JV, Horwitz B, Ungerleider LG, Maisog JM, Pietrini P, Grady CL |title=The functional organization of human extrastriate cortex: a PET-rCBF study of selective attention to faces and locations |journal=J. Neurosci. |volume=14 |issue=11 Pt 1 |pages=6336–53 |date=1 November 1994 |pmid=7965040 |url=http://www.jneurosci.org/cgi/pmidlookup?view=long&pmid=7965040|last2=Horwitz |last3=Ungerleider |last4=Maisog |last5=Pietrini |last6=Grady </ref><ref>Cite journal|author=Haxby JV, Ungerleider LG, Clark VP, Schouten JL, Hoffman EA, Martin A |title=The effect of face inversion on activity in human neural systems for face and object perception |journal=Neuron |volume=22 |issue=1 |pages=189–99 |date=January 1999 |pmid=10027301 |url=http://linkinghub.elsevier.com/retrieve/pii/S0896-6273(00)80690-X |doi=10.1016/S0896-6273(00)80690-X|last2=Ungerleider |last3=Clark |last4=Schouten |last5=Hoffman |last6=Martin </ref><ref>Cite journal|author=Puce A, Allison T, Asgari M, Gore JC, McCarthy G |title=Differential sensitivity of human visual cortex to faces, letterstrings, and textures: a functional magnetic resonance imaging study |journal=J. Neurosci. |volume=16 |issue=16 |pages=5205–15 |date=15 August 1996 |pmid= 8756449 |url=http://www.jneurosci.org/cgi/pmidlookup?view=long&pmid=8756449|last2=Allison |last3=Asgari |last4=Gore |last5=McCarthy </ref><ref>Cite journal|author=Puce A, Allison T, Gore JC, McCarthy G |title=Face-sensitive regions in human extrastriate cortex studied by functional MRI |journal=J. Neurophysiol. |volume=74 |issue=3 |pages=1192–9 |date=September 1995 |pmid=7500143 |url=http://jn.physiology.org/cgi/pmidlookup?view=long&pmid=7500143|last2=Allison |last3=Gore |last4=McCarthy </ref><ref>Cite journal|author=Sergent J, Ohta S, MacDonald B |title=Functional neuroanatomy of face and object processing. A positron emission tomography study |journal=Brain |volume=115 |issue=Pt 1 |pages=15–36 |date=February 1992 |pmid=1559150 |url=http://brain.oxfordjournals.org/cgi/pmidlookup?view=long&pmid=1559150 |doi=10.1093/brain/115.1.15|last2=Ohta |last3=MacDonald </ref> However, there are some studies that include increased activation in one side over the other. For instance McCarthy (1997) has shown that the right fusiform gyrus is more important for facial processing in complex situations.<ref name="McCarthy 1997">McCarthy, G., Puce, A.,
Gore, J., Allison, T., (1997). Face-Specific Processing in the Human Fusiform Gyrus. Journal of Cognitive Neuroscience, 9 5 605-610</ref>

Gorno-Tempini and Price have shown that the fusiform gyri are preferentially responsive to faces, whereas the parahippocampal/lingual gyri are responsive to buildings.<ref>Cite journal|author=Gorno-Tempini ML, Price CJ |title=Identification of famous faces and buildings: a functional neuroimaging study of semantically unique items |journal=Brain |volume=124 |issue=Pt 10 |pages=2087–97 |date=October 2001 |pmid=11571224 |url=http://brain.oxfordjournals.org/cgi/pmidlookup?view=long&pmid=11571224 |doi=10.1093/brain/124.10.2087|last2=Price </ref>

It is important to note that while certain areas respond selectively to faces, facial processing involves many neural networks. These networks include visual and emotional processing systems as well. Emotional face processing research has demonstrated that there are some of the other functions at work. While looking at faces displaying emotions (especially those with fear facial expressions) compared to neutral faces there is increased activity in the right fusiform gyrus. This increased activity also correlates with increased amygdala activity in the same situations.<ref name="Vuilleumier">cite journal | last1 = Vuilleumier | first1 = P | last2 = Pourtois | first2 = G | year = 2007 | title = Distributed and interactive brain mechanisms during emotion face perception: Evidence from functional neuroimaging | url = | journal = Neuropsychologia | volume = 45 | issue = 1| pages = 174–194 | doi=10.1016/j.neuropsychologia.2006.06.003| pmid = 16854439 </ref> The emotional processing effects observed in the fusiform gyrus are decreased in patients with amygdala lesions.<ref name="Vuilleumier"/> This demonstrates possible connections between the amygdala and facial processing areas.<ref name="Vuilleumier"/>

Another aspect that affects both the fusiform gyrus and the amygdala activation is the familiarity of faces. Having multiple regions that can be activated by similar face components indicates that facial processing is a complex process.<ref name="Vuilleumier"/> Platek and Kemp (2009) further showed increased brain activation in precuneus and cuneus when differentiation of two faces are easy (e.g., kin and familiar non-kin faces) and the role of posterior medial substrates for visual processing of faces with familiar features (e.g., faces that are averaged with the face of a sibling).<ref>Cite journal|last=Platek|first=Steven M.|last2=Kemp|first2=Shelly M.|date=2009-02-01|title=Is family special to the brain? An event-related fMRI study of familiar, familial, and self-face recognition|url=http://www.sciencedirect.com/science/article/pii/S0028393208005095|journal=Neuropsychologia|volume=47|issue=3|pages=849–858|doi=10.1016/j.neuropsychologia.2008.12.027|pmid=19159636</ref>

Ishai and colleagues have proposed the object form topology hypothesis, which posits that there is a topological organization of neural substrates for object and facial processing.<ref>Cite journal|author=Ishai A, Ungerleider LG, Martin A, Schouten JL, Haxby JV |title=Distributed representation of objects in the human ventral visual pathway |journal=Proc. Natl. Acad. Sci. U.S.A.  |volume=96 |issue=16 |pages=9379–84 |date=August 1999 |pmid=10430951 |pmc=17791 |url=http://www.pnas.org/cgi/pmidlookup?view=long&pmid=10430951 |doi=10.1073/pnas.96.16.9379|last2=Ungerleider |last3=Martin |last4=Schouten |last5=Haxby </ref> However, Gauthier disagrees and suggests that the category-specific and process-map models could accommodate most other proposed models for the neural underpinnings of facial processing.<ref>Cite journal|author=Gauthier I |title=What constrains the organization of the ventral temporal cortex? |journal=Trends Cogn. Sci. (Regul. Ed.) |volume=4 |issue=1 |pages=1–2 |date=January 2000 |pmid=10637614 |url= http://linkinghub.elsevier.com/retrieve/pii/S1364-6613(99)01416-3 |doi=10.1016/S1364-6613(99)01416-3</ref>

Most neuroanatomical substrates for facial processing are perfused by the middle cerebral artery (MCA). Therefore, facial processing has been studied using measurements of mean cerebral blood flow velocity in the middle cerebral arteries bilaterally. During facial recognition tasks, greater changes in the right middle cerebral artery (RMCA) than the left (LMCA) have been observed.<ref>Cite journal |author=Droste DW, Harders AG, Rastogi E |title=A transcranial Doppler study of blood flow velocity in the middle cerebral arteries performed at rest and during mental activities |journal=Stroke |volume=20 |issue=8 |pages=1005–11 |date=August 1989 |pmid=2667197 |url=http://stroke.ahajournals.org/cgi/pmidlookup?view=long&pmid=2667197 |doi=10.1161/01.STR.20.8.1005 |last2=Harders |last3=Rastogi Dead link|date=December 2018 |bot=InternetArchiveBot |fix-attempted=yes </ref><ref>Cite journal|author=Harders AG, Laborde G, Droste DW, Rastogi E |title=Brain activity and blood flow velocity changes: a transcranial Doppler study |journal =Int. J. Neurosci. |volume=47 |issue=1–2 |pages=91–102 |date=July 1989 |pmid=2676884 |doi=10.3109/00207458908987421|last2=Laborde |last3=Droste |last4=Rastogi </ref> It has been demonstrated that men were right lateralized and women left lateralized during facial processing tasks.<ref>Cite journal|author=Njemanze PC |title=Asymmetry in cerebral blood flow velocity with processing of facial images during head-down rest |journal=Aviat Space Environ Med |volume=75 |issue=9 |pages=800–5 |date=September 2004 |pmid=15460633</ref>

Just as memory and cognitive function separate the abilities of children and adults to recognize faces, the familiarity of a face may also play a role in the perception of faces.<ref name="Gold 2012 427–434"/> Zheng, Mondloch, and Segalowitz recorded event-related potentials in the brain to determine the timing of recognition of faces in the brain.<ref name="Zheng 2012 1451–1461">cite journal|last=Zheng|first=X.|author2=Mondloch, C.J. & Segalowitz, S.J.|title=The timing of individual face recognition in the brain|journal=Neuropsychologia|year=2012|volume=50|issue=7|pages=1451–1461|doi=10.1016/j.neuropsychologia.2012.02.030|pmid=22410414</ref> The results of the study showed that familiar faces are indicated and recognized by a stronger N250,<ref name="Zheng 2012 1451–1461"/> a specific wavelength response that plays a role in the visual memory of faces.<ref>cite journal|last=Eimer|first=M.|author2=Gosling, A. |author3=Duchaine, B. |title=Electrophysiological markers of covert face recognition in developmental prosopagnosia|journal=Brain|year=2012|volume=135|issue=2|pages=542–554|doi=10.1093/brain/awr347|pmid=22271660</ref> Similarly, Moulson et al.<ref>cite journal|last=Moulson|first=M.C.|author2=Balas, B. |author3=Nelson, C. |author4=Sinha, P. |title=EEG correlates of categorical and graded face perception|journal=Neuropsychologia|year=2011|volume=49|issue=14|pages=3847–3853|doi=10.1016/j.neuropsychologia.2011.09.046|pmid=22001852 |pmc=3290448</ref> found that all faces elicit the N170 response in the brain.

Using fMRI&nbsp;with&nbsp;Single-unit recording|single-unit electrophysiological recordings, Doris Tsao's group revealed<ref>Cite journal|last=Chang|first=Le|last2=Tsao|first2=Doris Y.|date=2017-06-01|title=The Code for Facial Identity in the Primate Brain|url=http://www.cell.com/cell/abstract/S0092-8674(17)30538-X|journal=Cell|language=English|volume=169|issue=6|pages=1013–1028.e14|doi=10.1016/j.cell.2017.05.011|issn=0092-8674|pmid=28575666</ref> a code that brain uses to process faces in macaques. The brain conceptually needs only ~50 neurons to encode any human face, with facial features projected on individual axes (neurons) in a 50-dimensional "Face Space".

=Hemispheric asymmetries in facial processing capability=
The mechanisms underlying gender-related differences in facial processing have not been studied extensively.

Studies using electrophysiological techniques have demonstrated gender-related differences during a face recognition memory (FRM) task and a facial affect identification task (FAIT). The male subjects used a right, while the female subjects used a left, hemisphere neural activation system in the processing of faces and facial affect.<ref>Cite journal|author=Everhart DE, Shucard JL, Quatrin T, Shucard DW |title=Sex-related differences in event-related potentials, face recognition, and facial affect processing in prepubertal children |journal=Neuropsychology |volume=15 |issue=3 |pages=329–41 |date=July 2001 |pmid=11499988 |url=http://content.apa.org/journals/neu/15/3/329 |doi=10.1037/0894-4105.15.3.329|last2=Shucard |last3=Quatrin |last4=Shucard </ref> Moreover, in facial perception there was no association to estimated intelligence, suggesting that face recognition performance in women is unrelated to several basic cognitive processes.<ref>Cite journal|author=Herlitz A, Yonker JE |title=Sex differences in episodic memory: the influence of intelligence |journal=J Clin Exp Neuropsychol |volume=24 |issue=1 |pages=107–14 |date=February 2002 |pmid=11935429 |doi=10.1076/jcen.24.1.107.970|last2=Yonker </ref> Gender-related differences<ref>Cite journal|author=Smith WM |title=Hemispheric and facial asymmetry: gender differences |journal=Laterality |volume=5 |issue=3 |pages= 251–8 |date=July 2000 |pmid=15513145 |doi=10.1080/713754376</ref> may suggest a role for sex hormones. In females there may be variability for psychological functions<ref>Cite journal|author= Voyer D, Voyer S, Bryden MP |title=Magnitude of sex differences in spatial abilities: a meta-analysis and consideration of critical variables |journal=Psychol Bull |volume=117 |issue=2 |pages=250–70 |date=March 1995 |pmid=7724690 |url=http://content.apa.org/journals/bul/117/2/250 |doi=10.1037/0033-2909.117.2.250|last2=Voyer |last3=Bryden </ref> related to differences in hormonal levels during different phases of the menstrual cycle.<ref>Cite journal|author=Hausmann M |title=Hemispheric asymmetry in spatial attention across the menstrual cycle |journal=Neuropsychologia |volume=43 |issue=11 |pages=1559–67 |year=2005 |pmid=16009238 |doi= 10.1016/j.neuropsychologia.2005.01.017 |url=http://linkinghub.elsevier.com/retrieve/pii/S0028-3932(05)00096-5</ref>

Data obtained in norm and in pathology support asymmetric face processing.<ref>Cite journal|author=De Renzi E |title=Prosopagnosia in two patients with CT scan evidence of damage confined to the right hemisphere |journal=Neuropsychologia |volume=24 |issue=3 |pages=385–9 |year=1986 |pmid= 3736820 |doi=10.1016/0028-3932(86)90023-0</ref><ref>Cite journal|author=De Renzi E, Perani D, Carlesimo GA, Silveri MC, Fazio F |title=Prosopagnosia can be associated with damage confined to the right hemisphere--an MRI and PET study and a review of the literature |journal=Neuropsychologia |volume=32 |issue=8 |pages=893–902 |date=August 1994 |pmid=7969865 |url=http://linkinghub.elsevier.com/retrieve/pii/0028-3932(94)90041-8 |doi=10.1016/0028-3932(94)90041-8|last2=Perani |last3=Carlesimo |last4=Silveri |last5=Fazio </ref><ref>Cite journal|author=Mattson AJ, Levin HS, Grafman J |title=A case of prosopagnosia following moderate closed head injury with left hemisphere focal lesion |journal=Cortex |volume=36 |issue=1 |pages=125–37 |date=February 2000 |pmid=10728902 |doi=10.1016/S0010-9452(08)70841-4|last2=Levin |last3=Grafman </ref> Gorno-Tempini and others in 2001, suggested that the left inferior frontal cortex and the bilateral occipitotemporal junction respond equally to all face conditions. Some neuroscientists contend that both the left inferior frontal cortex (Brodmann area 47) and the occipitotemporal junction are implicated in facial memory.<ref>Cite journal|author=Barton JJ, Cherkasova M |title=Face imagery and its relation to perception and covert recognition in prosopagnosia |journal=Neurology |volume=61 |issue=2 |pages=220–5 |date=July 2003 |pmid=12874402 |url=http://www.neurology.org/cgi/pmidlookup?view=long&pmid=12874402|doi=10.1212/01.WNL.0000071229.11658.F8|last2=Cherkasova </ref><ref>Cite journal|author= Sprengelmeyer R, Rausch M, Eysel UT, Przuntek H |title=Neural structures associated with recognition of facial expressions of basic emotions |journal=Proc. Biol. Sci. |volume=265 |issue=1409 |pages=1927–31 |date=October 1998 |pmid=9821359 |pmc=1689486 |doi=10.1098/rspb.1998.0522 |url=http://rspb.royalsocietypublishing.org/cgi/pmidlookup?view=long&pmid=9821359|last2=Rausch |last3=Eysel |last4=Przuntek </ref><ref>Cite journal|author=Verstichel P |title=[Impaired recognition of faces: implicit recognition, feeling of familiarity, role of each hemisphere] |language=French |journal=Bull. Acad. Natl. Med. |volume=185 |issue=3 |pages=537–49; discussion 550–3 |year=2001 |pmid=11501262</ref> The right inferior temporal/fusiform gyrus responds selectively to faces but not to non-faces. The right temporal pole is activated during the discrimination of familiar faces and scenes from unfamiliar ones.<ref>Cite journal|author=Nakamura K |title=Functional delineation of the human occipito-temporal areas related to face and scene processing. A PET study |journal=Brain |volume=123 |issue=Pt 9 |pages=1903–12 |date=September 2000 |pmid=10960054 |url=http://brain.oxfordjournals.org/cgi/pmidlookup?view=long&pmid=10960054 |doi=10.1093/brain/123.9.1903|name-list-format=vanc|author2=Kawashima R|author3=Sato N|display-authors=3|last4=Nakamura|first4=A|last5=Sugiura|first5=M|last6=Kato|first6=T|last7=Hatano|first7=K|last8=Ito|first8=K|last9=Fukuda|first9=H</ref> Right asymmetry in the mid temporal lobe for faces has also been shown using 133-Xenon measured cerebral blood flow (CBF).<ref>Cite journal|author=Gur RC |title=Effects of memory processing on regional brain activation: cerebral blood flow in normal subjects |journal=Int. J. Neurosci. |volume=72 |issue=1–2 |pages=31–44 |date=September 1993 |pmid=8225798 |doi=10.3109/00207459308991621|name-list-format=vanc|author2=Jaggi JL|author3=Ragland JD|display-authors=3|last4=Resnick|first4=Susan M.|last5=Shtasel|first5=Derri|last6=Muenz|first6=Larry|last7=Gur|first7=Raquel E.</ref> Other investigators have observed right lateralization for facial recognition in previous electrophysiological and imaging studies.<ref>Cite journal|author=Ojemann JG, Ojemann GA, Lettich E |title=Neuronal activity related to faces and matching in human right nondominant temporal cortex |journal=Brain |volume=115 |issue=Pt 1 |pages=1–13 |date=February 1992 |pmid= 1559147 |url=http://brain.oxfordjournals.org/cgi/pmidlookup?view=long&pmid=1559147 |doi=10.1093/brain/115.1.1|last2=Ojemann |last3=Lettich </ref>

The implication of the observation of asymmetry for facial perception would be that different hemispheric strategies would be implemented. The right hemisphere would be expected to employ a holistic strategy, and the left an analytic strategy.<ref>Cite journal|author=Bogen JE |title=The other side of the brain. I. Dysgraphia and dyscopia following cerebral commissurotomy |journal=Bull Los Angeles Neurol Soc |volume=34 |issue=2 |pages=73–105 |date=April 1969 |pmid=5792283</ref><ref>Cite journal|author=Bogen JE |title=Some educational aspects of hemispheric specialization |journal=UCLA Educator |volume= 17 |pages=24–32 |year=1975</ref><ref>Cite journal|author=Bradshaw JL, Nettleton NC |title=The nature of hemispheric specialization in man |journal=Behavioral and Brain Sciences |volume=4 |pages=51–91 |year= 1981 |doi=10.1017/S0140525X00007548|last2=Nettleton </ref><ref>Cite journal|author=Galin D |title=Implications for psychiatry of left and right cerebral specialization. A neurophysiological context for unconscious processes |journal=Arch. Gen. Psychiatry |volume=31 |issue=4 |pages=572–83 |date=October 1974 |pmid=4421063 |url=http://archpsyc.ama-assn.org/cgi/pmidlookup?view=long&pmid=4421063 |doi=10.1001/archpsyc.1974.01760160110022 dead link|date=December 2016 |bot=InternetArchiveBot |fix-attempted=yes </ref> In 2007, Philip Njemanze, using a novel functional transcranial Doppler (fTCD) technique called Transcranial doppler#Functional transcranial Doppler (fTCD)|functional transcranial Doppler spectroscopy (fTCDS), demonstrated that men were right lateralized for object and facial perception, while women were left lateralized for facial tasks but showed a right tendency or no lateralization for object perception.<ref>Cite journal|author=Njemanze PC |title=Cerebral lateralisation for facial processing: gender-related cognitive styles determined using Fourier analysis of mean cerebral blood flow velocity in the middle cerebral arteries |journal=Laterality |volume=12 |issue=1 |pages=31–49 |date=January 2007 |pmid=17090448 |doi=10.1080/13576500600886796 |url=http://www.informaworld.com/openurl?genre=article&doi=10.1080/13576500600886796&magic=pubmed&#124;1B69BA326FFE69C3F0A8F227DF8201D0</ref> Njemanze demonstrated using fTCDS, summation of responses related to facial stimulus complexity, which could be presumed as evidence for topological organization of these cortical areas in men. It may suggest that the latter extends from the area implicated in object perception to a much greater area involved in facial perception.

This agrees with the object form topology hypothesis proposed by Ishai and colleagues in 1999. However, the relatedness of object and facial perception was process-based, and appears to be associated with their common holistic processing strategy in the right hemisphere. Moreover, when the same men were presented with facial paradigm requiring analytic processing, the left hemisphere was activated. This agrees with the suggestion made by Gauthier in 2000, that the extrastriate cortex contains areas that are best suited for different computations, and described as the process-map model. Therefore, the proposed models are not mutually exclusive, and this underscores the fact that facial processing does not impose any new constraints on the brain other than those used for other stimuli.

It may be suggested that each stimulus was mapped by category into face or non-face, and by process into holistic or analytic. Therefore, a unified category-specific process-mapping system was implemented for either right or left cognitive styles. Njemanze in 2007, concluded that, for facial perception, men used a category-specific process-mapping system for right cognitive style, but women used same for the left.

=Cognitive neuroscience=

Cognitive neuroscientists Isabel Gauthier and Michael Tarr are two of the major proponents of the view that face recognition involves expert discrimination of similar objects (See the [https://web.archive.org/web/20060509092446/http://www.psy.vanderbilt.edu/faculty/gauthier/PEN/ Perceptual Expertise Network]). Other scientists, in particular Nancy Kanwisher and her colleagues, argue that face recognition involves processes that are face-specific and that are not recruited by expert discriminations in other object classes (see the [http://web.mit.edu/bcs/nklab/expertise.shtml domain specificity]).

Studies by Gauthier have shown that an area of the brain known as the fusiform gyrus (sometimes called the fusiform face area because it is active during face recognition) is also active when study participants are asked to discriminate between different types of birds and cars,<ref>Cite journal|author=Gauthier I, Skudlarski P, Gore JC, Anderson AW |title=Expertise for cars and birds recruits brain areas involved in face recognition |journal=Nat. Neurosci. |volume=3 |issue=2 |pages=191–7 |date=February 2000 |pmid=10649576 |doi=10.1038/72140|last2=Skudlarski |last3=Gore |last4=Anderson </ref> and even when participants become expert at distinguishing computer generated nonsense shapes known as greeble (psychology)|greebles.<ref>Cite journal|author=Gauthier I, Tarr MJ, Anderson AW, Skudlarski P, Gore JC |title=Activation of the middle fusiform 'face area' increases with expertise in recognizing novel objects |journal=Nat. Neurosci. |volume=2 |issue=6 |pages=568–73 |date=June 1999 |pmid=10448223 |doi= 10.1038/9224|last2=Tarr |last3=Anderson |last4=Skudlarski |last5=Gore </ref> This suggests that the fusiform gyrus may have a general role in the recognition of similar visual objects. Yaoda Xu, then a post doctoral fellow with Nancy Kanwisher, replicated the car and bird expertise study using an improved fMRI design that was less susceptible to attentional accounts.

The activity found by Gauthier when participants viewed non-face objects was not as strong as when participants were viewing faces, however this could be because we have much more expertise for faces than for most other objects. Furthermore, not all findings of this research have been successfully replicated, for example, other research groups using different study designs have found that the fusiform gyrus is specific to faces and other nearby regions deal with non-face objects.<ref>Cite journal|author=Grill-Spector K, Knouf N, Kanwisher N |title=The fusiform face area subserves face perception, not generic within-category identification |journal=Nat. Neurosci. |volume=7 |issue=5 |pages=555–62 |date=May 2004 |pmid=15077112 |doi=10.1038/nn1224|last2=Knouf |last3=Kanwisher </ref>

However, these failures to replicate are difficult to interpret, because studies vary on too many aspects of the method. It has been argued that some studies test experts with objects that are slightly outside of their domain of expertise. More to the point, failures to replicate are null effects and can occur for many different reasons. In contrast, each replication adds a great deal of weight to a particular argument. With regard to "face specific" effects in neuroimaging, there are now multiple replications with Greebles, with birds and cars,<ref>Cite journal|author=Xu Y |title=Revisiting the role of the fusiform face area in visual expertise |journal=Cereb. Cortex |volume=15 |issue=8 |pages=1234–42 |date=August 2005 |pmid=15677350 |doi=10.1093/cercor/bhi006 |url=http://cercor.oxfordjournals.org/cgi/pmidlookup?view=long&pmid=15677350</ref> and two unpublished studies with chess experts.<ref>Cite journal|author=Righi G, Tarr MJ |title=Are chess experts any different from face, bird, or greeble experts? |journal=Journal of Vision |volume=4 |issue=8 |pages=504–504 |year=2004 |url=http://journalofvision.org/4/8/504/ |doi=10.1167/4.8.504|last2=Tarr </ref><ref>[https://www.youtube.com/watch?v=WLQbTd6RFhY] My Brilliant Brain, partly about grandmaster Susan Polgar, shows brain scans of the fusiform gyrus while Polgar viewed chess diagrams.</ref>

Although it is sometimes found that expertise recruits the FFA (e.g. as hypothesized by a proponent of this view in the preceding paragraph), a more common and less controversial finding is that expertise leads to focal category-selectivity in the fusiform gyrus—a pattern similar in terms of antecedent factors and neural specificity to that seen for faces. As such, it remains an open question as to whether face recognition and expert-level object recognition recruit similar neural mechanisms across different subregions of the fusiform or whether the two domains literally share the same neural substrates. Moreover, at least one study argues that the issue as to whether expertise-predicated category-selective areas overlap with the FFA is nonsensical in that multiple measurements of the FFA within an individual person often overlap no more with each other than do measurements of FFA and expertise-predicated regions.<ref>Cite journal|author=Kung CC, Peissig JJ, Tarr MJ |title=Is region-of-interest overlap comparison a reliable measure of category specificity? |journal=J Cogn Neurosci |volume=19 |issue=12 |pages=2019–34 |date=December 2007 |pmid=17892386 |doi=10.1162/jocn.2007.19.12.2019 |url=http://www.mitpressjournals.org/doi/abs/10.1162/jocn.2007.19.12.2019?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%3dncbi.nlm.nih.gov|last2=Peissig |last3=Tarr </ref> At the same time, numerous studies have failed to replicate them altogether.Citation needed|date=September 2008 For example, four published fMRI studies have asked whether expertise has any specific connection to the FFA in particular, by testing for expertise effects in both the FFA and a nearby but not face-selective region called LOC (Rhodes et al., JOCN 2004; Op de Beeck et al., JN 2006; Moore et al., JN 2006; Yue et al. VR 2006). In all four studies, expertise effects are significantly stronger in the LOC than in the FFA, and indeed expertise effects were only borderline significant in the FFA in two of the studies, while the effects were robust and significant in the LOC in all four studies.Citation needed|date=December 2010

Therefore, it is still not clear in exactly which situations the fusiform gyrus becomes active, although it is certain that face recognition relies heavily on this area and damage to it can lead to severe face recognition impairment.

=Self-face perception=
Studies regarding face perception have also looked specifically at self-face perception.  One study found that the perception/recognition of one's own face was unaffected by changing contexts, while the perception/recognition of familiar and unfamiliar faces was adversely affected.<ref name=":5" /> Another study that focused on older adults found that they had self-face advantage in configural processing but not featural processing.<ref name=":6" />

Face advantage in memory recall
During face perception, neural networks make connections with the brain to recall memories.<ref name="Mansour 2010">cite journal|last=Mansour|first=Jamal|author2=Lindsay, Roderick|title=Facial Recognition|journal=Corsini Encyclopedia of Psychology|date=30 January 2010|volume=1–2|doi=10.1002/9780470479216.corpsy0342|isbn=9780470479216</ref> According to the Seminal Model of face perception, there are three stages of face processing including recognition of the face, the recall of memories and information that are linked with that face, and finally name recall.<ref name=Bruce>cite journal|last=Bruce|first=V.|author2=Young, A|title=Understanding Face Recognition|journal=British Journal of Psychology|year=1986|issue=3|pages=305–327|pmid=3756376|doi=10.1111/j.2044-8295.1986.tb02199.x|volume=77</ref><ref name="Mansour 2010"/> There are, however, exceptions to this order. For example, names are recalled faster than semantic information in cases of highly familiar stimuli.<ref name=calderwood>cite journal|last=Calderwood|first=L|author2=Burton, A.M.|title=Children and adults recall the names of highly familiar faces faster than semantic information|journal=British Journal of Psychology|date=November 2006|volume=96|issue=4|pages=441–454|doi=10.1348/000712605X84124</ref> While the face is powerful identifier of individuals, the voice also helps in the recognition of people and is an identifier for important information.<ref name=ellis>cite journal|last=Ellis|first=Hadyn|author2=Jones, Dylan|title=Intra- and Inter-modal repetition priming of familiar faces and voices|journal=British Journal of Psychology|date=February 1997|volume=88|issue=1|pages=143–156|doi=10.1111/j.2044-8295.1997.tb02625.x|last3=Mosdell|first3=Nick</ref><ref name=nadal>cite journal|last=Nadal|first=Lynn|title=Speaker Recognition|journal=Encyclopedia of Cognitive Science|year=2005|volume=4|pages=142–145</ref>

Research has been conducted to see if faces or voices make it easier to identify individuals and recall semantic memory and episodic memory.<ref name="seed"/> These experiments look at all three stages of face processing. The experiment method was to show two groups celebrity and familiar faces or voices with a between-group design and ask the participants to recall information about them.<ref name=seed>cite journal|last=Bredart|first=S.|author2=Barsics, C.|title=Recalling Semantic and Episodic Information From Faces and Voices: A Face Advantage|journal=Current Directions in Psychological Science|date=3 December 2012|volume=21|issue=6|pages=378–381|doi=10.1177/0963721412454876</ref> The participants are first asked if the stimulus is familiar. If they answer yes then they are asked to information (semantic memory) and memories they have of the person (episodic memory) that fits the face or voice presented. These experiments all demonstrate the strong phenomenon of the face advantage and how it persists through different follow-up studies with different experimental controls and variables.<ref name=seed />

=Recognition-performance issue=
After the first experiments on the advantage of faces over voices in memory recall, errors and gaps were found in the methods used.<ref name=seed /> For one, there was not a clear face advantage for the recognition stage of face processing. Participants showed a familiarity-only response to voices more often than faces.<ref name="Hanley 2009 830–839">cite journal|last=Hanley|first=J. Richard|author2=Damjanovic, Ljubica|title=It is more difficult to retrieve a familiar person's name and occupation from their voice than from their blurred face|journal=Memory|date=November 2009|volume=17|issue=8|pages=830–839|doi=10.1080/09658210903264175|pmid=19882434</ref> In other words, when voices were recognized (about 60-70% of the time) they were much harder to recall biographical information but very good at being recognized.<ref name=seed /> The results were looked at as remember versus know judgements. A lot more remember results (or familiarity) occurred with voices, and more know (or memory recall) responses happened with faces.<ref name=nadal /> This phenomenon persists through experiments dealing with criminal line-ups in prisons. Witnesses are more likely to say that a suspect's voice sounded familiar than his/her face even though they cannot remember anything about the suspect.<ref name=yarmey>cite journal|last=Yarmey|first=Daniel A.|title=Face and Voice Identifications in showups and lineups|journal=Applied Cognitive Psychology|date=1 January 1994|volume=8|issue=5|pages=453–464|doi=10.1002/acp.2350080504|last2=Yarmey|first2=A. Linda|last3=Yarmey|first3=Meagan J.</ref> This discrepancy is due to a larger amount of guesswork and false alarms that occur with voices.<ref name=nadal />

To give faces a similar ambiguity to that of voices, the face stimuli were blurred in the follow-up experiment<ref name="Hanley 2009 830–839"/>  This experiment followed the same procedures as the first, presenting two groups with sets of stimuli made up of half celebrity faces and half unfamiliar faces.<ref name=seed /> The only difference was that the face stimuli were blurred so that detailed features could not be seen.  Participants were then asked to say if they recognized the person, if they could recall specific biographical information about them, and finally if they knew the person's name. The results were completely different from those of the original experiment, supporting the view that there were problems in the first experiment's methods.<ref name=seed /> According to the results of the followup, the same amount of information and memory could be recalled through voices and faces, dismantling the face advantage. However, these results are flawed and premature because other methodological issues in the experiment still needed to be fixed.<ref name=seed />

=Content of speech=
The process of controlling the content of speech extract has proven to be more difficult than the elimination of non facial cues in photographs.<ref name=seed />  Thus the findings of experiments that did not control this factor lead to misleading conclusions regarding the voice recognition over the face recognition.<ref name=seed />  For example, in an experiment it was found that 40% of the time participants could easily pair the celebrity-voice with their occupation just by guessing.<ref name="Hanley 2009 830–839"/> In order to eliminate these errors, experimenters removed parts of the voice samples that could possibly give clues to the identity of the target, such as catchphrases.<ref>cite journal|last=Van Lancker|first=Diana|author2=Kreiman, Jody|title=Voice discrimination and recognition are separate abilities|journal=Neuropsychologia|date=January 1987|volume=25|issue=5|pages=829–834|doi=10.1016/0028-3932(87)90120-5|pmid=3431677</ref>   Even after controlling the voice samples as well as the face samples (using blurred faces), studies have shown that semantic information can be more accessible to retrieve when individuals are recognizing faces than voices.<ref name="Barsics & Bredart 2011">cite journal|last=Barsics|first=Catherine|author2=Brédart, Serge|title=Recalling episodic information about personally known faces and voices|journal=Consciousness and Cognition|date=June 2011|volume=20|issue=2|pages=303–308|doi=10.1016/j.concog.2010.03.008|pmid=20381380</ref>

Another technique to control the content of the speech extracts is to present the faces and voices of personally familiar individuals, like the participant's teachers or neighbors, instead of the faces and voices of celebrities.<ref name=seed />  In this way alike words are used for the speech extracts.<ref name=seed />  For example, the familiar targets are asked to read exactly the same scripted speech for their voice extracts. The results showed again that semantic information is easier to retrieve when individuals are recognizing faces than voices.<ref name=seed />

=Frequency-of-exposure issue=
Another factor that has to be controlled in order for the results to be reliable is the frequency of exposure.<ref name=seed />  If we take the example of celebrities, people are exposed to celebrities' faces more often than their voices because of the mass media.<ref name=seed />  Through magazines, newspapers and the Internet, individuals are exposed to celebrities' faces without their voices on an everyday basis rather than their voices without their faces.<ref name=seed /> Thus, someone could argue that for all of the experiments that were done until now the findings were a result of the frequency of exposure to the faces of celebrities rather than their voices.<ref>cite book|last=Ethofer|first=edited by Belin Pascal, Salvatore Campanella, Thomas|title=Integrating face and voice in person perception|publisher=Springer|location=New York|isbn=978-1-4614-3584-6</ref>

To overcome this problem researchers decided to use personally familiar individuals as stimuli instead of celebrities.<ref name=seed />  Personally familiar individuals, such as participant's teachers, are for the most part heard as well as seen.<ref name="barsics and bredart and hanley 2009">cite journal|last=Brédart|first=Serge|author2=Barsics, Catherine |author3=Hanley, Rick |title=Recalling semantic information about personally known faces and voices|journal=European Journal of Cognitive Psychology|date=November 2009|volume=21|issue=7|pages=1013–1021|doi=10.1080/09541440802591821</ref>  Studies that used this type of control also demonstrated the face advantage.<ref name="barsics and bredart and hanley 2009"/>  Students were able to retrieve semantic information more readily when recognizing their teachers faces (both normal and blurred)rather their voices.<ref name="Barsics & Bredart 2011" />

However, researchers over the years have found an even more effective way to control not only the frequency of exposure but also the content of the speech extracts, the Learning|associative learning paradigm.<ref name=seed />  Participants are asked to link semantic information as well as names with pre-experimentally unknown voices and faces.<ref name="barsics and bredart 2012b">cite journal|last=Barsics|first=Catherine|author2=Brédart, Serge|title=Recalling semantic information about newly learned faces and voices|journal=Memory|date=July 2012|volume=20|issue=5|pages=527–534|doi=10.1080/09658211.2012.683012|pmid=22646520</ref><ref name="Associative learning paradigm">cite web|title=Learning.|url=http://www.credoreference.com/entry/estinsects/learning|work=Encyclopedia of Insects.|publisher=Oxford: Elsevier Science & Technology|accessdate=6 December 2013</ref>  In a current experiment that used this paradigm, a name and a profession were given together with, accordingly, a voice, a face or both to three participant groups.<ref name="barsics and bredart 2012b" />  The associations described above were repeated four times.<ref name="barsics and bredart 2012b" />  The next step was a Recall (memory)|cued recall task in which every stimulus that was learned in the previous phase was introduced and participants were asked to tell the profession and the name for every stimulus.<ref name="barsics and bredart 2012b" /><ref name="cued recall task">cite web|title=Memory, Explicit and Implicit.|url=http://www.credoreference.com/entry/esthumanbrain/memory_explicit_and_implicit|work=Encyclopedia of the Human Brain.|publisher=Oxford: Elsevier Science & Technology|accessdate=6 December 2013</ref>  Again, the results showed that semantic information can be more accessible to retrieve when individuals are recognizing faces than voices even when the frequency of exposure was controlled.<ref name=seed /><ref name="barsics and bredart 2012b" />

=Extension to episodic memory and explanation for existence=
Episodic memory is our ability to remember specific, previously experienced events.<ref>cite encyclopedia |year=2005 |title=Episodic Memory, Computational Models of |encyclopedia=Encyclopedia of Cognitive Science |publisher=John Wiley & Sons |location=Chichester, UK</ref> In recognition of faces as it pertains to episodic memory, there has been shown to be activation in the left lateral prefrontal cortex, parietal lobe, and the left medial frontal/anterior cingulate cortex.<ref name="Leube 2003 97–101">cite journal|last=Leube|first=Dirk T.|author2=Erb, Michael |author3=Grodd, Wolfgang |author4=Bartels, Mathias |author5= Kircher, Tilo T.J. |title=Successful episodic memory retrieval of newly learned faces activates a left fronto-parietal network|journal=Cognitive Brain Research|date=December 2003|volume=18|issue=1|pages=97–101|doi=10.1016/j.cogbrainres.2003.09.008|pmid=14659501</ref><ref>cite journal|last=Hofer|first=Alex|author2=Siedentopf, Christian M. |author3=Ischebeck, Anja |author4=Rettenbacher, Maria A. |author5=Verius, Michael |author6=Golaszewski, Stefan M. |author7=Felber, Stephan |author8= Fleischhacker, W. Wolfgang |title=Neural substrates for episodic encoding and recognition of unfamiliar faces|journal=Brain and Cognition|date=March 2007|volume=63|issue=2|pages=174–181|doi=10.1016/j.bandc.2006.11.005|pmid=17207899</ref> It was also found that a left lateralization during episodic memory retrieval in the parietal cortex correlated strongly with success in retrieval.<ref name="Leube 2003 97–101"/> This may possibly be due to the hypothesis that the link between face recognition and episodic memory were stronger than those of voice and episodic memory.<ref name="Hanley 2009 830–839"/> This hypothesis can also be supported by the existence of specialized face recognition devices thought to be located in the temporal lobes.<ref name="Leube 2003 97–101"/><ref>cite encyclopedia |year=2005 |title= Face Perception, Neural Basis of |encyclopedia=Encyclopedia of Cognitive Science |publisher=John Wiley & Sons</ref> There is also evidence of the existence of two separate neural systems for face recognition: one for familiar faces and another for newly learned faces.<ref name="Leube 2003 97–101"/> One explanation for this link between face recognition and episodic memory is that since face recognition is a major part of human existence, the brain creates a link between the two in order to be better able to communicate with others.<ref>cite encyclopedia |year=2005 |title=Face Perception, Psychology of |encyclopedia=Encyclopedia of Cognitive Science |publisher=John Wiley & Sons</ref>

Ethnicity
main|Cross-race effect
Differences in own- versus other-race face recognition and perceptual discrimination was first researched in 1914.<ref name="Feingold">cite journal | author = Feingold CA | year = 1914 | title = The influence of environment on identification of persons and things | url = | journal = Journal of Criminal Law and Police Science | volume = 5 | issue = | pages = 39–51 | doi=10.2307/1133283| jstor = 1133283 </ref> Humans tend to perceive people of other races than their own to all look alike:
<blockquote>Other things being equal, individuals of a given race are distinguishable from each other in proportion to our familiarity, to our contact with the race as whole. Thus, to the uninitiated American all Asiatics look alike, while to the Asiatics, all White men look alike.<ref name="Feingold"/></blockquote>

This phenomenon is known mainly as the cross-race effect, but is also called the own-race effect, other-race effect, own race bias or interracial-face-recognition-deficit.<ref>Cite journal|author=Walker PM, Tanaka JW |title=An encoding advantage for own-race versus other-race faces |journal=Perception |volume=32 |issue=9 |pages=1117–25 |year=2003 |pmid=14651324 |doi=10.1068/p5098|last2=Tanaka </ref>

In 1990, Mullen reported finding evidence that the other-race effect is larger among White subjects than among African American subjects, whereas Brigham and Williamson (1979, cited in Shepherd, 1981) obtained the opposite pattern.<ref name="otherrace">Cite journal|last=Lindsay|first=D. Stephen|last2=Jack, Jr.|first2=Philip C.|last3=Christian|first3=Christian A.|date=February 13, 1991|title=Other-Race Face Perception|url=http://web.uvic.ca/~slindsay/publications/1991LindJackChristian.pdf|journal=Journal of Applied Psychology|volume=76|issue=4|access-date=September 30, 2016|doi=10.1037/0021-9010.76.4.587|pages=587–589</ref> However, it should be noted that it is difficult to measure the true influence of the cross-race effect. D. Stephen Lindsay and colleagues note that results in these studies could be due to intrinsic difficulty in recognizing the faces presented, an actual difference in the size of cross-race effect between the two test groups, or some combination of these two factors.<ref name="otherrace" /> Shepherd reviewed studies that found better performance on both African American<ref>Chance, Goldstein, & McBride, 1975; Feinman & Entwistle, 1976; cited in Shepherd, 1981</ref> and White faces,<ref>Malpass & Kravitz, 1969; Cross, Cross, & Daly, 1971; Shepherd, Deregowski, & Ellis, 1974; all cited in Shepherd, 1981</ref> and yet Shepherd also reviewed other studies in which no difference was found.<ref>Brigham & Karkowitz, 1978; Brigham & Williamson, 1979; cited in Shepherd, 1981</ref> Overall, Shepherd reported a reliable positive correlation between the size of the effect and the amount of interaction subjects had with members of the other race. This correlation reflects the fact that African American subjects, who performed equally well on faces of both races in Shepherd's study, almost always responded with the highest possible self-rating of amount of interaction with white people (M = 4.75; 5 being the most interaction with people of that race, 1 being the least), whereas their white counterparts both displayed a larger other-race effect and reported less other-race interaction (M = 2.13). This difference in rating was found statistically reliable, £(30) = 7.86, p < .01.<ref name="otherrace" />

The cross-race effect seems to appear in humans around 6 months of age.<ref>Cite journal|last=Kelly|first=David J.|last2=Quinn|first2=Paul C.|last3=Slater|first3=Alan M.|last4=Lee|first4=Kang|last5=Ge|first5=Liezhong|last6=Pascalis|first6=Olivier|date=2007-12-01|title=The Other-Race Effect Develops During Infancy Evidence of Perceptual Narrowing|url=http://pss.sagepub.com/content/18/12/1084|journal=Psychological Science|language=en|volume=18|issue=12|pages=1084–1089|doi=10.1111/j.1467-9280.2007.02029.x|pmid=18031416|issn=0956-7976|pmc=2566514</ref> Cross-race effects can be changed from early childhood through adulthood through interaction with people of other races.<ref>Cite journal|last=Sangrigoli|first=S.|last2=Pallier|first2=C.|last3=Argenti|first3=A.-M.|last4=Ventureyra|first4=V. a. G.|last5=de Schonen|first5=S.|date=2005-06-01|title=Reversibility of the other-race effect in face recognition during childhood|journal=Psychological Science|volume=16|issue=6|pages=440–444|doi=10.1111/j.0956-7976.2005.01554.x|pmid=15943669|issn=0956-7976</ref> Other-race experience in own- versus other-race face processing is a major influence on the cross-race effect (O'Toole et al., 1991; Slone et al., 2000; Walker & Tanaka, 2003). In a series of studies, Walker and colleagues revealed that participants with greater other-race experience were consistently more accurate at discriminating between other-race faces than were participants with less other-race experience (Walker & Tanaka, 2003; Walker & Miles Hewstone|Hewstone, 2006a,b; 2007). Many current models of the cross-race effect assume that holistic face processing mechanisms are more fully engaged when viewing own-race faces compared to other-race faces.<ref>Cite journal|last=DeGutis|first=Joseph|last2=Mercado|first2=Rogelio J.|last3=Wilmer|first3=Jeremy|last4=Rosenblatt|first4=Andrew|date=2013-04-10|title=Individual Differences in Holistic Processing Predict the Own-Race Advantage in Recognition Memory|url=http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0058253|journal=PLoS ONE|volume=8|issue=4|pages=e58253|doi=10.1371/journal.pone.0058253|pmid=23593119|issn=1932-6203|pmc=3622684</ref>

The own-race effect appears to be related to increased ability to extract information about the spatial relationships between different facial features.<ref>Diamond & Carey, 1986; Rhodeset al.,1989</ref> Daniel T. Levin writes that a deficit occurs when viewing people of another race because visual information specifying race takes up mental attention at the expense of individuating information when recognizing faces of other races.<ref>Cite journal|author=Levin DT |title=Race as a visual feature: using visual search and perceptual discrimination tasks to understand face categories and the cross-race recognition deficit |journal=J Exp Psychol Gen |volume=129 |issue=4 |pages=559–74 |date=December 2000 |pmid=11142869 |url=http://content.apa.org/journals/xge/129/4/559 |doi=10.1037/0096-3445.129.4.559</ref> Further research using perceptual tasks could shed light on the specific cognitive processes involved in the other-race effect.<ref name="otherrace"/> Bernstein et al. (2007) demonstrate that the own-race effect likely extends beyond racial membership into In-group favoritism|in-group versus out-group concepts. It was shown that categorizing somebody by the university he or she attends results in similar results compared to studies about the own-race effect.<ref>Cite journal|last=Bernstein|first=Michael J.|last2=Young|first2=Steven G.|last3=Hugenberg|first3=Kurt|date=2007-08-01|title=The Cross-Category Effect Mere Social Categorization Is Sufficient to Elicit an Own-Group Bias in Face Recognition|url=http://pss.sagepub.com/content/18/8/706|journal=Psychological Science|language=en|volume=18|issue=8|pages=706–712|doi=10.1111/j.1467-9280.2007.01964.x|pmid=17680942|issn=0956-7976</ref> Hugenberg, Miller, and Claypool (2007) shed light on overcoming the own-race effect. They performed a study in which they introduced people to the concept of the own-race effect before presenting them faces and found that if people were made aware of the own-race effect prior to the experiment, the test subjects showed significantly less if any own-race effect.<ref>Cite journal|last=Hugenberg|first=Kurt|last2=Miller|first2=Jennifer|last3=Claypool|first3=Heather M.|date=2007-03-01|title=Categorization and individuation in the cross-race recognition deficit: Toward a solution to an insidious problem|url=http://www.sciencedirect.com/science/article/pii/S0022103106000382|journal=Journal of Experimental Social Psychology|volume=43|issue=2|pages=334–340|doi=10.1016/j.jesp.2006.02.010</ref>

Studies on adults have also shown sex differences in face recognition. Men tend to recognize fewer faces of women than women do, whereas there are no sex differences with regard to male faces.<ref>Cite journal|author=Rehnman J, Herlitz A |title=Higher face recognition ability in girls: Magnified by own-sex and own-ethnicity bias |journal=Memory |volume=14 |issue=3 |pages=289–96 |date=April 2006 |pmid= 16574585 |doi=10.1080/09658210500233581 |url=http://www.informaworld.com/openurl?genre=article&doi=10.1080/09658210500233581&magic=pubmed&#124;&#124;1B69BA326FFE69C3F0A8F227DF8201D0|last2=Herlitz </ref>

In individuals with autism spectrum disorder

Autism spectrum disorder (ASD) is a comprehensive neural developmental disorder that produces many deficits including social, communicative,<ref name=tanakabook>cite book|last=Tanaka|first=J.W.|title=The development of face processing|year=2003|publisher=Hogrefe & Huber Publishers|location=Ohio|isbn=9780889372641|pages=101–119|author2=Lincoln, S. |author3=Hegg, L. |editor=Schwarzer, G. |editor2=Leder, H.|chapter=A framework for the study and treatment of face processing deficits in autism</ref> and perceptual deficits.<ref name=Behrmann>cite journal|last=Behrmann|first=Marlene|author2=Avidan, Galia |author3=Leonard, Grace L. |author4=Kimchi, Rutie |author5=Beatriz, Luna |author6=Humphreys, Kate |author7= Minshew, Nancy |title=Configural processing in autism and its relationship to face processing|journal=Neuropsychologia|year=2006|volume=44|issue=1|pages=110–129|doi=10.1016/j.neuropsychologia.2005.04.002|pmid=15907952</ref> Of specific interest, individuals with autism exhibit difficulties in various aspects of facial perception, including facial identity recognition and recognition of emotional expressions.<ref name=Schreibman>cite book|last=Schreibman|first=Laura|title=Autism|year=1988|publisher=Sage Publications|location=Newbury Park|isbn=0803928092|pages=14–47</ref><ref name=Weigelt>cite journal|last=Weigelt|first=Sarah|author2=Koldewyn, Kami |author3=Kanwisher, Nancy |title=Face identity recognition in autism spectrum disorders: A review of behavioral studies|journal=Neuroscience & Biobehavioral Reviews|year=2012|volume=36|issue=3|pages=1060–1084|doi=10.1016/j.neubiorev.2011.12.008</ref> These deficits are suspected to be a product of abnormalities occurring in both the early and late stages of facial processing.<ref name=Dawson>cite journal|last=Dawson|first=Geraldine|author2=Webb, Sara Jane |author3=McPartland, James |title=Understanding the nature of face processing impairment in autism: Insights from behavioral and electrophysiological studies|journal=Developmental Neuropsychology|year=2005|volume=27|pages=403–424|pmid=15843104|doi=10.1207/s15326942dn2703_6|issue=3</ref>

=Speed and methods=
People with ASD process face and non-face stimuli with the same speed.<ref name=Dawson /><ref name=Kita>cite journal|last=Kita|first=Yosuke|author2=Inagaki, Masumi|title=Face recognition in patients with Autism Spectrum Disorder|journal=Brain and Nerve|year=2012|volume=64|pages=821–831|pmid=22764354|issue=7</ref> In typically developing individuals, there is a preference for face processing, thus resulting in a faster processing speed in comparison to non-face stimuli.<ref name=Dawson /><ref name=Kita /> These individuals primarily utilize global precedence|holistic processing when perceiving faces.<ref name=Behrmann /> Contrastingly, individuals with ASD employ part-based processing or top-down and bottom-up design|bottom-up processing, focusing on individual features rather than the face as a whole.<ref name=Grelotti>cite journal|last=Grelotti |first=David |author2=Gauthier, Isabel |author3=Schultz, Robert |title=Social interest and the development of cortical face specialization: What autism teaches us about face processing |url=http://www.psy.vanderbilt.edu/faculty/gauthier/publi/GrGaSc_inpress.pdf |journal=Developmental Psychobiology |year=2002 |volume=40 |issue=3 |pages=213–235 |doi=10.1002/dev.10028 |accessdate=2012-02-24 |deadurl=yes |archiveurl=https://web.archive.org/web/20060902194937/http://www.psy.vanderbilt.edu/faculty/gauthier/publi/GrGaSc_inpress.pdf |archivedate=2006-09-02 |df= </ref><ref name=Riby>cite journal|last=Riby|first=Deborah|author2=Doherty-Sneddon Gwyneth|title=The eyes or the mouth? Feature salience and unfamiliar face processing in Williams syndrome and autism|journal=The Quarterly Journal of Experimental Psychology|year=2009|volume=62|issue=1|pages=189–203|doi=10.1080/17470210701855629|pmid=18609381|last3=Bruce|first3=Vicki</ref> When focusing on the individual parts of the face, persons with ASD direct their gaze primarily to the lower half of the face, specifically the mouth, varying from the eye trained gaze of typically developing people.<ref name=Grelotti /><ref name=Riby /><ref name=Joseph>cite journal|last=Joseph|first=Robert|author2=Tanaka, James|title=Holistic and part-based face recognition in children with autism|journal=Journal of Child Psychology and Psychiatry|year=2003|volume=44|issue=4|pages=529–542|doi=10.1111/1469-7610.00142|pmid=12751845</ref><ref name=Langdell>cite journal|last=Langdell |first=Tim |title=Recognition of Faces: An approach to the study of autism |journal=Journal of Psychology and Psychiatry and Allied Disciplines (Blackwell) |year=1978 |volume=19 |issue=3 |pages=255–265 |url=http://illiad.davidson.edu/pdf/162574.pdf |accessdate=2/12/2013 |doi=10.1111/j.1469-7610.1978.tb00468.x dead link|date=December 2016 |bot=InternetArchiveBot |fix-attempted=yes </ref><ref name=Spezio>cite journal|last=Spezio|first=Michael|author2=Adolphs, Ralph |author3=Hurley, Robert |author4= Piven, Joseph |title=Abnormal use of facial information in high functioning autism|journal=Journal of Autism and Developmental Disorders|date=28 Sep 2006|volume=37|issue=5|pages=929–939|doi=10.1007/s10803-006-0232-9|pmid=17006775</ref>  This deviation from global precedence|holistic face processing does not employ the use of facial prototype theory|prototypes, which are templates stored in memory that make for easy retrieval.<ref name=Weigelt /><ref name=textbook>cite book|last=Revlin|first=Russell|title=Cognition: Theory and Practice|year=2013|publisher=Worth Publishers|isbn=9780716756675|pages=98–101</ref>

Additionally, individuals with ASD display difficulty with recognition memory, specifically memory that aids in identifying faces. The memory deficit is selective for faces and does not extend to other objects or visual inputs.<ref name=Weigelt /> Some evidence lends support to the theory that these face-memory deficits are products of interference between connections of face processing regions.<ref name=Weigelt />

=Associated difficulties=
The atypical facial processing style of people with ASD often manifests in constrained social ability, due to decreased eye contact, joint attention, interpretation of emotional expression, and communicative skills.<ref name=Triesch>cite journal|last=Triesch|first=Jochen|author2=Teuscher, Christof |author3=Deak, Gedeon O. |author4= Carlson, Eric |title=Gaze following: why (not) learn it?|journal=Developmental Science|year=2006|volume=9|issue=2|pages=125–157|doi=10.1111/j.1467-7687.2006.00470.x</ref> These deficiencies can be seen in infants as young as 9 months; specifically in terms of poor eye contact and difficulties engaging in joint attention.<ref name=Dawson />  Some experts have even used the term 'face avoidance' to describe the phenomena where infants who are later diagnosed with ASD preferentially attend to non-face objects over faces.<ref name=tanakabook /> Furthermore, some have proposed that the demonstrated impairment in children with ASD's ability to grasp emotional content of faces is not a reflection of the incapacity to process emotional information, but rather, the result of a general inattentiveness to facial expression.<ref name=tanakabook /> The constraints of these processes that are essential to the development of communicative and social-cognitive abilities are viewed to be the cause of impaired social engagement and responsivity.<ref name=Volkmar>cite journal|last=Volkmar|first=Fred|author2=Chawarska, Kasia |author3=Klin, Ami |title=Autism in infancy and early childhood|journal=Annual Review of Psychology|year=2005|volume=56|pages=315–316|doi=10.1146/annurev.psych.56.091103.070159|pmid=15709938</ref> Furthermore, research suggests that there exists a link between decreased face processing abilities in individuals with ASD and later deficits in Theory of Mind; for example, while typically developing individuals are able to relate others' emotional expressions to their actions, individuals with ASD do not demonstrate this skill to the same extent.<ref name=grosbois>cite book|last=Nader-Grosbois|first=N.|title=International handbook of autism and pervasive developmental disorders|year=2011|publisher=Springer Science & Business Media|location=New York|isbn=9781441980649|pages=127–157|author2=Day, J.M.|editor=Matson, J.L |editor2=Sturmey, R.|chapter=Emotional cognition: theory of mind and face recognition</ref>

There is some contention about this causation however, resembling the chicken or the egg dispute. Others theorize that social impairment leads to perceptual problems rather than vice versa.<ref name=Grelotti /> In this perspective, a biological lack of social interest inherent to ASD inhibits developments of facial recognition and perception processes due to underutilization.<ref name=Grelotti /> Continued research is necessary to determine which theory is best supported.

=Neurology =
Many of the obstacles that individuals with ASD face in terms of facial processing may be derived from abnormalities in the fusiform face area and amygdala, which have been shown to be important in face perception as discussed Face perception#Neuroanatomy of facial processing|above. Typically, the fusiform face area in individuals with ASD has reduced volume compared to normally developed persons.<ref name= Pierce>cite journal|last=Pierce|first=Karen|author2=Muller, R.A., Ambrose, J., Allen, G., Chourchesne|title=Face processing occurs outside the fusiform 'face area' in autism: evidence from functional MRI|url = http://brain.oxfordjournals.org/content/124/10/2059.full.pdf+html|journal=Brain|year=2001|volume=124|pages=2059–2073|accessdate=2013-02-13|issue=10|doi=10.1093/brain/124.10.2059</ref> This volume reduction has been attributed to deviant amygdala activity that does not flag faces as emotionally salient and thus decreases activation levels of the fusiform face area. This hypoactivity in the fusiform face area has been found in several studies.<ref name=Grelotti />

Studies are not conclusive as to which brain areas people with ASD use instead. One study found that, when looking at faces, people with ASD exhibit activity in brain regions normally active when typically developing individuals perceive objects.<ref name=Grelotti /> Another study found that during facial perception, people with ASD use different neural systems, with each one of them using their own unique neural circuitry.<ref name=Pierce />

=Compensation mechanisms=
As ASD individuals age, scores on behavioral tests assessing ability to perform face-emotion recognition increase to levels similar to controls.<ref name=Dawson /><ref name=Harms /> Yet, it is apparent that the recognition mechanisms of these individuals are still atypical, though often effective.<ref name=Harms>cite journal|last=Harms|first=Madeline|author2=Martin, Alex |author3=Wallace, Gregory |title=Facial emotion recognition in autism spectrum disorders: A review of behavioral and neuroimaging studies|journal=Neuropsychology Review|year=2010|volume=20|issue=3|pages=290–322|doi=10.1007/s11065-010-9138-6|pmid=20809200</ref> In terms of face identity-recognition, compensation can take many forms including a more pattern-based strategy which was first seen in Global precedence#Face inversion|face inversion tasks.<ref name=Langdell /> Alternatively, evidence suggests that older individuals compensate by using mimicry of other's facial expressions and rely on their motor feedback of facial muscles for face emotion-recognition.<ref name=Wright>cite journal|last=Wright|first=Barry|author2=Clarke, Natalie |author3=Jordan, Jo |author4=Young, Andrew |author5=Clarke, Paula |author6=Miles, Jermey |author7=Nation, Kate |author8=Clarke, Leesa |author9= Williams, Christine  |title=Emotion recognition in faces and the use of visual context Vo in young people with high-functioning autism spectrum disorders|journal=Autism|year=2008|volume=12|issue=6|page=607–|doi=10.1177/1362361308097118</ref> These strategies help overcome the obstacles individuals with ASD face in interacting within social contexts.

 In individuals with schizophrenia 
Attention, perception, memory, learning, processing, reasoning, and problem solving are known to be affected in individuals with schizophrenia.<ref name=":2">Cite journal|doi=10.1080/13546805.2015.1133407|pmid=26816133|title=Face perception in schizophrenia: A specific deficit|journal=Cognitive Neuropsychiatry|volume=21|issue=1|pages=60–72|year=2016|last1=Megreya|first1=Ahmed M.</ref> Schizophrenia has been linked to impaired face and emotion perception.<ref name=":2" /><ref name=":3"/><ref name=":4">cite journal|pmid=26778631|year=2016|author1=Tang|first1=D. Y.|title=Facial emotion perception impairments in schizophrenia patients with comorbid antisocial personality disorder|journal=Psychiatry Research|volume=236|pages=22–7|last2=Liu|first2=A. C.|last3=Lui|first3=S. S.|last4=Lam|first4=B. Y.|last5=Siu|first5=B. W.|last6=Lee|first6=T. M.|last7=Cheung|first7=E. F.|doi=10.1016/j.psychres.2016.01.005</ref><ref name=":5">cite journal|pmid=21803427|year=2012|author1=Soria Bauser|first1=D|title=Face and body perception in schizophrenia: A configural processing deficit?|journal=Psychiatry Research|volume=195|issue=1–2|pages=9–17|last2=Thoma|first2=P|last3=Aizenberg|first3=V|last4=Brüne|first4=M|last5=Juckel|first5=G|last6=Daum|first6=I|doi=10.1016/j.psychres.2011.07.017</ref> People with schizophrenia demonstrate worse accuracy and slower response time in face perception tasks in which they are asked to match faces, remember faces, and recognize which emotions are present in a face.<ref name=":5" /> People with schizophrenia have more difficulty matching upright faces than they do with inverted faces.<ref name=":2" /> A reduction in configural processing, using the distance between features of an item for recognition or identification (e.g. features on a face such as eyes or nose), has also been linked to schizophrenia.<ref name=":5" /> Schizophrenia patients are able to easily identify a "happy" affect but struggle to identify faces as "sad" or "fearful".<ref name=":4" /> Impairments in face and emotion perception are linked to impairments in social skills, due to the individual's inability to distinguish facial emotions.<ref name=":4" /><ref name=":5" /> People with schizophrenia tend to demonstrate a reduced N170 response, atypical face scanning patterns, and a configural processing dysfunction.<ref name=":112">Cite web|url=http://web.a.ebscohost.com/ehost/detail/detail?vid=3&sid=1a2fc56c-3c89-44b7-bdc8-45b75d6cc22d@sessionmgr4009&bdata=JnNpdGU9ZWhvc3QtbGl2ZQ#AN=2016-16329-005&db=psyh|title=Face perception in schizophrenia: A specific deficit: EBSCOhost|website=web.a.ebscohost.com|language=en|access-date=2018-01-30Dead link|date=December 2018 |bot=InternetArchiveBot |fix-attempted=yes </ref> The severity of schizophrenia symptoms has been found to correlate with the severity of impairment in face perception.<ref name=":5" />

Individuals with diagnosed schizophrenia and antisocial personality disorder have been found to have even more impairment in face and emotion perception than individuals with just schizophrenia. These individuals struggle to identify anger, surprise, and disgust. There is a link between aggression and emotion perception difficulties for people with this dual diagnosis.<ref name=":4" />

Data from magnetic resonance imaging and functional magnetic resonance imaging has shown that a smaller volume of the fusiform gyrus is linked to greater impairments in face perception.<ref name=":3" />

There is a positive correlation between self-face recognition and other-face recognition difficulties in individuals with schizophrenia.  The degree of schizotypy has also been shown to correlate with self-face difficulties, unusual perception difficulties, and other face recognition difficulties.<ref name=":82">Cite web|url=http://web.b.ebscohost.com/ehost/detail/detail?vid=15&sid=89cf12cb-933b-4c76-94b7-04b68f01fa7e@sessionmgr103&bdata=JnNpdGU9ZWhvc3QtbGl2ZQ#AN=27342823&db=a9h|title=Face recognition failures in schizotypy: EBSCOhost|website=web.b.ebscohost.com|language=en|access-date=2018-02-02Dead link|date=December 2018 |bot=InternetArchiveBot |fix-attempted=yes </ref> Schizophrenia patients report more feelings of strangeness when looking in a mirror than do normal controls. Hallucinations, somatic concerns, and depression have all been found to be associated with self-face perception difficulties.<ref name=":72">Cite web|url=http://web.a.ebscohost.com/ehost/detail/detail?vid=2&sid=1a2fc56c-3c89-44b7-bdc8-45b75d6cc22d@sessionmgr4009&bdata=JnNpdGU9ZWhvc3QtbGl2ZQ#AN=2017-24741-032&db=psyh|title=Mirror self-face perception in individuals with schizophrenia: Feelings of ...: EBSCOhost|website=web.a.ebscohost.com|language=en|access-date=2018-01-30Dead link|date=December 2018 |bot=InternetArchiveBot |fix-attempted=yes </ref>

In animals
Neurobiologist Jenny Morton and her team have been able to teach sheep to choose a familiar face over unfamiliar one when presented with two photographs, which has led to the discovery that sheep can recognise human faces.<ref>cite web|title=Sheep are able to recognise human faces from photographs|url=https://www.cam.ac.uk/research/news/sheep-are-able-to-recognise-human-faces-from-photographs|website=University of Cambridge|accessdate=8 November 2017|date=8 November 2017</ref><ref>cite web|last1=Rincon|first1=Paul|title=Sheep 'can recognise human faces'|url=https://www.bbc.co.uk/news/science-environment-41905652|website=BBC News|accessdate=8 November 2017|date=8 November 2017</ref> Archerfish (distant relatives of humans) were able to differentiate between forty-four different human faces, which supports the theory that there is no need for a neocortex or a history of discerning human faces in order to do so.<ref name=":102">Cite web|url=http://web.b.ebscohost.com/ehost/detail/detail?vid=19&sid=89cf12cb-933b-4c76-94b7-04b68f01fa7e@sessionmgr103&bdata=JnNpdGU9ZWhvc3QtbGl2ZQ#AN=119335637&db=a9h|title=Face facts: Even nonhuman animals discriminate human faces: EBSCOhost|website=web.b.ebscohost.com|language=en|access-date=2018-02-02Dead link|date=December 2018 |bot=InternetArchiveBot |fix-attempted=yes </ref> Pigeons were found to use the same parts of the brain as humans do to distinguish between happy and neutral faces or male and female faces.<ref name=":102" />

Artificial
A great deal of effort has been put into developing facial recognition system|software that can recognize human faces. Much of the work has been done by a branch of artificial intelligence known as computer vision which uses findings from the psychology of face perception to inform software design. Recent breakthroughs using noninvasive functional transcranial Doppler spectroscopy as demonstrated by Njemanze, 2007, to locate specific responses to facial stimuli have led to improved systems for facial recognition. The new system uses input responses called cortical long-term potentiation (CLTP) derived from Fourier analysis of mean blood flow velocity to trigger target face search from a computerized face database system.<ref>Njemanze, P.C. Transcranial doppler spectroscopy for assessment of brain cognitive functions. United States Patent Application No. 20040158155, August 12th, 2004</ref><ref>Njemanze, P.C. Noninvasive transcranial doppler ultrasound face and object recognition testing system. United States Patent No. 6,773,400, August 10th, 2004</ref> Such a system provides for brain-machine interface for facial recognition, and the method has been referred to as cognitive biometrics.

Another application is the estimation of human age from face images. As an important hint for human communication, facial images contain lots of useful information including gender, expression, age, etc. Unfortunately, compared with other cognition problems, age estimation from facial images is still very challenging. This is mainly because the aging process is influenced not only by a person's genes but also many external factors. Physical condition, living style etc. may accelerate or slow the aging process. Besides, since the aging process is slow and with long duration, collecting sufficient data for training is fairly demanding work.<ref>Cite journal |url=http://pages.cs.wisc.edu/~huangyz/caip09_Long.pdf |title=Human age estimation by metric learning for regression problems |author=YangJing Long |journal=Proc. International Conference on Computer Analysis of Images and Patterns |year=2009 |pages=74–82 |deadurl=yes |archiveurl=https://web.archive.org/web/20100108055346/http://pages.cs.wisc.edu/~huangyz/caip09_Long.pdf |archivedate=2010-01-08 |df= </ref>

 Genetic basis 
While it has been widely recognized that many cognitive abilities, such as general intelligence, have genetic bases, evidence for the genetic basis of facial recognition abilities specifically is fairly recent. Some of the earliest published research on the relationship between facial recognition and genetics focused on the genetic bases of facial recognition in the context of genetic disorders which impair facial recognition abilities, such as Turner syndrome. In a study by Lawrence, K. et al. in 2003<ref name=":6">Cite journal|last=Lawrence|first=Kate|last2=Kuntsi|first2=Jonna|last3=Coleman|first3=Michael|last4=Campbell|first4=Ruth|last5=Skuse|first5=David|date=2003-01-01|title=Face and emotion recognition deficits in Turner syndrome: a possible role for X-linked genes in amygdala development|journal=Neuropsychology|volume=17|issue=1|pages=39–49|issn=0894-4105|pmid=12597072|doi=10.1037/0894-4105.17.1.39</ref> the authors found significantly poorer facial recognition abilities in individuals with Turner syndrome, a genetic disorder which results in impaired amygdala functioning, suggesting that amygdala functioning may impact face perception.<ref name=":6" /> Evidence for the genetic basis of facial recognition abilities in the general population, however, comes from studies on face perception in twin participants by Wilmer, J. B. et al. in 2009,<ref name=":7">Cite journal|last=Wilmer|first=Jeremy B.|last2=Germine|first2=Laura|last3=Chabris|first3=Christopher F.|last4=Chatterjee|first4=Garga|last5=Williams|first5=Mark|last6=Loken|first6=Eric|last7=Nakayama|first7=Ken|last8=Duchaine|first8=Bradley|date=2010-03-16|title=Human face recognition ability is specific and highly heritable|journal=Proceedings of the National Academy of Sciences of the United States of America|volume=107|issue=11|pages=5238–5241|doi=10.1073/pnas.0913053107|issn=1091-6490|pmc=2841913|pmid=20176944</ref> in which the facial recognition scores on the Prosopagnosia|Cambridge Face Memory test were twice as similar for Twin|monozygotic twins in comparison to Twin|dizygotic twins.<ref name=":7" /> This finding was supported by a twin study on the genetic bases of facial recognition by Zhu, Q. et al. in (2009) which found a similar difference in facial recognition scores when comparing Twin|monozygotic and Twin|dizygotic twins<ref>Cite journal|last=Zhu|first=Qi|last2=Song|first2=Yiying|last3=Hu|first3=Siyuan|last4=Li|first4=Xiaobai|last5=Tian|first5=Moqian|last6=Zhen|first6=Zonglei|last7=Dong|first7=Qi|last8=Kanwisher|first8=Nancy|last9=Liu|first9=Jia|date=2010-01-26|title=Heritability of the specific cognitive ability of face perception|journal=Current Biology|volume=20|issue=2|pages=137–142|doi=10.1016/j.cub.2009.11.067|issn=1879-0445|pmid=20060296</ref> and Shakeshaft, N. G. & Plomin, R. (2015),<ref name=":8">Cite journal|last=Shakeshaft|first=Nicholas G.|last2=Plomin|first2=Robert|date=2015-10-13|title=Genetic specificity of face recognition|journal=Proceedings of the National Academy of Sciences of the United States of America|volume=112|issue=41|pages=12887–12892|doi=10.1073/pnas.1421881112|issn=0027-8424|pmc=4611634|pmid=26417086</ref> which determined the heritability of facial recognition to be approximately 61%, using a similar set of twin studies.<ref name=":8" /> There was also no significant relationship identified between facial recognition scores and measures of any other cognitive abilities,<ref name=":7" /> most notably the lack of a correlation with general object recognition abilities. This suggests that facial recognition abilities are not only heritable, but that their genetic basis is independent from the bases of other cognitive abilities and are specialized for face perception.<ref name=":7" /> Research by Cattaneo, Z. et al. (2016)<ref name=":9">Cite journal|last=Cattaneo|first=Zaira|last2=Daini|first2=Roberta|last3=Malaspina|first3=Manuela|last4=Manai|first4=Federico|last5=Lillo|first5=Mariarita|last6=Fermi|first6=Valentina|last7=Schiavi|first7=Susanna|last8=Suchan|first8=Boris|last9=Comincini|first9=Sergio|date=2016-12-17|title=Congenital prosopagnosia is associated with a genetic variation in the oxytocin receptor (OXTR) gene: An exploratory study|journal=Neuroscience|volume=339|pages=162–173|doi=10.1016/j.neuroscience.2016.09.040|issn=1873-7544|pmid=27693815</ref> and suggest that the more extreme examples of facial recognition abilities, specifically hereditary prosopagnosics, are also highly genetically correlated.<ref name=":9" /> For hereditary prosopagnosics, an Dominance (genetics)|autosomal dominant model of inheritance has been proposed by Kennerknecht, I. et al. (2006).<ref>Cite journal|last=Kennerknecht|first=Ingo|last2=Grueter|first2=Thomas|last3=Welling|first3=Brigitte|last4=Wentzek|first4=Sebastian|last5=Horst|first5=Jürgen|last6=Edwards|first6=Steve|last7=Grueter|first7=Martina|date=2006-08-01|title=First report of prevalence of non-syndromic hereditary prosopagnosia (HPA)|journal=American Journal of Medical Genetics. Part A|volume=140|issue=15|pages=1617–1622|doi=10.1002/ajmg.a.31343|issn=1552-4825|pmid=16817175</ref> Research by Cattaneo, Z. et al. (2016)<ref name=":9" /> also correlated the probability of hereditary prosopagnosia with the presence of Single-nucleotide polymorphism|single nucleotide polymorphisms<ref name=":9" /> along the Oxytocin receptor|Oxytocin receptor gene (OXTR), specifically at nucleotides [http://snpedia.com/index.php/Rs2254298 rs2254298] and [https://www.snpedia.com/index.php/Rs53576 rs53576] on OXTR intron three,<ref name=":9" /> suggesting that these alleles may serve a critical role in normal face perception. Mutation from the wild type allele at these Locus (genetics)|loci has also been found to result in other disorders in which social and facial recognition deficits are common,<ref name=":9" /> such as Autism spectrum|autism spectrum disorder, which may imply that the genetic bases for general facial recognition are complex and Polygene|polygenic.<ref name=":9" /> This relationship between the OXTR gene and facial recognition abilities is also supported by studies of individuals who do not suffer from hereditary prosopagnosia by Melchers, M. et al. (2013)<ref name=":10">Cite journal|last=Melchers|first=Martin|last2=Montag|first2=Christian|last3=Markett|first3=Sebastian|last4=Reuter|first4=Martin|date=2013-10-01|title=Relationship between oxytocin receptor genotype and recognition of facial emotion|journal=Behavioral Neuroscience|volume=127|issue=5|pages=780–787|doi=10.1037/a0033748|issn=1939-0084|pmid=24128365</ref> and Westberg, L. et al. (2016)<ref name=":11">Cite journal|last=Westberg|first=Lars|last2=Henningsson|first2=Susanne|last3=Zettergren|first3=Anna|last4=Svärd|first4=Joakim|last5=Hovey|first5=Daniel|last6=Lin|first6=Tian|last7=Ebner|first7=Natalie C.|last8=Fischer|first8=Håkan|date=2016-09-22|title=Variation in the Oxytocin Receptor Gene Is Associated with Face Recognition and its Neural Correlates|journal=Frontiers in Behavioral Neuroscience|volume=10|doi=10.3389/fnbeh.2016.00178|issn=1662-5153|pmc=5031602|pmid=27713694</ref> which correlated general facial recognition abilities with different Genetic polymorphism|polymorphisms of the OXTR gene, specifically [http://snpedia.com/index.php/Rs7632287 rs7632287]<ref name=":11" /> and [http://snpedia.com/index.php/Rs2268498 rs2268498].<ref name=":10" /> Further research is needed to confirm the specific mechanisms of these genetic components on face perception; however, current evidence does suggest that facial recognition abilities are highly linked to genetic, rather than environmental, bases.

See also
* Prosopagnosia
* Autism 
* Nonverbal learning disorder 
* Social intelligence 
* Facial expression 
* Apophenia, seeing meaningful patterns in random data 
* Pareidolia
* Capgras delusion
* Cognitive neuropsychology
* Delusional misidentification syndrome
* Facial recognition system
* Fregoli syndrome
* Hollow face illusion
* Social cognition

References
Reflist|30em

Further reading
* Bruce, V. and Young, A. (2000) ''In the Eye of the Beholder: The Science of Face Perception''. Oxford: Oxford University Press. ISBN|0-19-852439-0

External links
* [http://www.face-rec.org Face Recognition Homepage]
* [https://web.archive.org/web/20160927124648/http://scienceaid.co.uk/psychology/cognition/face.html Science Aid: Face Recognition]
* [http://www.faceresearch.org/ FaceResearch]&nbsp;– Scientific research and online studies on face perception
* [http://www.faceblind.org Face Blind] Prosopagnosia Research Centers at Harvard and University College London
* [https://web.archive.org/web/20060620080614/http://www.icn.ucl.ac.uk/facetests/ Face Recognition Tests] - online tests for self-assessment of face recognition abilities.
* [https://web.archive.org/web/20060509092446/http://www.psy.vanderbilt.edu/faculty/gauthier/PEN/ Perceptual Expertise Network (PEN)] Collaborative group of cognitive neuroscientists studying perceptual expertise, including face recognition.
* [http://www.psychology.uwa.edu.au/research/facelab Face Lab]  at the University of Western Australia
* [http://www.perceptionlab.com Perception Lab]  at the University of St Andrews, Scotland
* [http://hdl.handle.net/1893/112 The effect of facial expression and identity information on the processing of own and other race faces] by Yoriko Hirose, PhD thesis from the University of Stirling
* [https://web.archive.org/web/20080708184525/http://www.globalemotion.com/ Global Emotion] Online-Training to overcome Caucasian-Asian other-race effect

Human group differences

DEFAULTSORT:Face Perception
Category:Attention
Category:Cognition
Category:Face recognition|*
Category:Vision