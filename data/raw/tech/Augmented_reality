{{distinguish|Virtual reality}}
{{Use dmy dates|date=June 2012}}

[[File:Virtual-Fixtures-USAF-AR.jpg|thumb|[[Virtual Fixture]]s –  first A.R. system,
1992, U.S. Air Force, WPAFB]]
'''Augmented reality''' ('''AR''') is an interactive experience of a real-world environment where the objects that reside in the real-world are "augmented" by computer-generated perceptual information, sometimes across multiple sensory modalities, including [[visual]], [[Hearing|auditory]], [[haptic perception|haptic]], [[Somatosensory system|somatosensory]], and [[olfactory]].<ref>{{Cite news|url=http://images.huffingtonpost.com/2016-05-13-1463155843-8474094-AR_history_timeline.jpg|title=The Lengthy History of Augmented Reality|last=|first=|date=May 15, 2016|work=Huffington Post|access-date=}}</ref><ref>{{Cite book|url=http://www.heg-fr.ch/EN/School-of-Management/Communication-and-Events/events/Pages/EventViewer.aspx?Event=patrick-schuffel.aspx|title=The Concise Fintech Compendium|last=Schueffel|first=Patrick|publisher=School of Management Fribourg/Switzerland|year=2017|isbn=|location=Fribourg|pages=}}</ref>  The overlaid sensory information can be constructive (i.e. additive to the natural environment) or destructive (i.e. masking of the natural environment) and is seamlessly interwoven with the physical world such that it is perceived as an [[immersion (virtual reality)|immersive]] aspect of the real environment.<ref name=":1" />  In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas [[virtual reality]] completely replaces the user's real-world environment with a simulated one.<ref>Steuer,{{Cite web |url=http://ww.cybertherapy.info/pages/telepresence.pdf |title=Archived copy |access-date=27 November 2018 |archive-url=https://web.archive.org/web/20160524233446/http://ww.cybertherapy.info/pages/telepresence.pdf |archive-date=24 May 2016 |dead-url=yes |df=dmy-all }}, Department of Communication, Stanford University. 15 October 1993.</ref><ref>[http://archive.ncsa.illinois.edu/Cyberia/VETopLevels/VR.Overview.html Introducing Virtual Environments] National Center for Supercomputing Applications, University of Illinois.</ref> Augmented reality is related to two largely synonymous terms: [[mixed reality]] and [[computer-mediated reality]].

The primary value of augmented reality is that it brings components of the digital world into a person's perception of the real world, and does so not as a simple display of data, but through the integration of immersive sensations that are perceived as natural parts of an environment. The first functional AR systems that provided immersive mixed reality experiences for users were invented in the early 1990s, starting with the [[Virtual Fixtures]] system developed at the U.S. Air Force's [[Armstrong Laboratory]] in 1992.<ref name=":1">{{Cite journal|last=Rosenberg|first=L.B.|year=1992|title=The Use of Virtual Fixtures As Perceptual Overlays to Enhance Operator Performance in Remote Environments|url=|journal=Technical Report AL-TR-0089, USAF Armstrong Laboratory, Wright-Patterson AFB OH, 1992.|volume= |pages= |via=}}</ref><ref>{{Cite journal|last=Rosenberg|first=L.B.|year=1993|title=Virtual Fixtures: Perceptual Overlays for Telerobotic Manipulation |url=|journal=Proc. Of the IEEE Annual Int. Symposium on Virtual Reality (1993)|volume=|pages=76–82|via=}}</ref><ref name= "Dupzyk 2016">{{Cite news|url=http://www.popularmechanics.com/technology/a22384/hololens-ar-breakthrough-awards/|title=I Saw the Future Through Microsoft's Hololens|last=Dupzyk|first=Kevin|work=Popular Mechanics|date = 6 September 2016|access-date=|via=}}</ref><ref name="huffingtonpost.com">{{Cite web|url=https://www.huffingtonpost.com/dennis-williams-ii/the-history-of-augmented-_b_9955048.html|title= The History of Augmented Reality (Infographic)|last=II|first=Dennis Williams|date=2016-05-13|website=Huffington Post|language=en-US|access-date=2018-06-17}}</ref>  The first commercial augmented reality experiences were used largely in the entertainment and gaming businesses, but now other industries are also getting interested about AR's possibilities for example in knowledge sharing, educating, managing the information flood and organizing distant meetings. Augmented reality is also transforming the world of education, where content may be accessed by scanning or viewing an image with a mobile device or by bringing immersive, markerless AR experiences to the classroom.<ref>{{Cite web | url=https://www.edsurge.com/news/2015-11-02-how-to-transform-your-classroom-with-augmented-reality | title=How to Transform Your Classroom with Augmented Reality - EdSurge News| date=2015-11-02}}</ref><ref>{{Cite web|url=https://medium.com/ancient-eu/why-we-need-more-tech-in-history-education-805fa10a7251|title=Why We Need More Tech in History Education|last=Crabben|first=Jan van der|date=2018-10-16|website=ancient.eu|access-date=2018-10-23}}</ref> Another example is an AR helmet for construction workers which display information about the construction sites.

Augmented reality is used to enhance natural environments or situations and offer perceptually enriched experiences. With the help of advanced AR technologies (e.g. adding [[computer vision]] and [[object recognition]]) the information about the surrounding real world of the user becomes [[interactive]] and digitally manipulable. Information about the environment and its objects is overlaid on the real world.  This information can be virtual<ref>Chen, Brian X. [https://www.wired.com/2009/08/augmented-reality/ If You’re Not Seeing Data, You’re Not Seeing], ''Wired'', 25 August 2009.</ref><ref>Maxwell, Kerry. [http://www.macmillandictionary.com/buzzword/entries/augmented-reality.html Augmented Reality], ''Macmillan Dictionary Buzzword''.</ref><ref>[http://www.augmentedrealityon.com/ Augmented reality-Everything about AR] {{webarchive|url=https://web.archive.org/web/20120405071414/http://www.augmentedrealityon.com/|date=5 April 2012}}, ''Augmented Reality On''.</ref><ref name="Azuma_survey">Azuma, Ronald. [http://www.cs.unc.edu/~azuma/ARpresence.pdf ''A Survey of Augmented Reality''] Presence: Teleoperators and Virtual Environments, pp. 355–385, August 1997.</ref><ref>Chatzopoulos D., Bermejo C, Huang Z, and Hui P [http://ieeexplore.ieee.org/document/7912316/ Mobile Augmented Reality Survey: From Where We Are to Where We Go].</ref><ref>Huang Z, P Hui., et al. [https://arxiv.org/abs/1309.4413 Mobile augmented reality survey: a bottom-up approach].</ref> or real, e.g. seeing other real sensed or measured information such as electromagnetic radio waves overlaid in exact alignment with where they actually are in space.<ref>[http://wearcam.org/PhenomenalAugmentedReality.pdf Phenomenal Augmented Reality, IEEE Consumer Electronics, Volume 4, No. 4, October 2015, cover+pp92-97]</ref><ref>Time-frequency perspectives, with applications, in Advances in Machine Vision, Strategies and Applications, World Scientific Series in Computer Science: Volume 32, C Archibald and Emil Petriu, Cover + pp&nbsp;99–128, 1992.</ref><ref>{{Cite book|last=Mann|first=Steve|last2=Feiner|first2=Steve|last3=Harner|first3=Soren|last4=Ali|first4=Mir Adnan|last5=Janzen|first5=Ryan|last6=Hansen|first6=Jayse|last7=Baldassi|first7=Stefano|date=2015-01-15|chapter-url=http://dl.acm.org/citation.cfm?id=2677199.2683590|publisher=ACM|pages=497–500|doi=10.1145/2677199.2683590|isbn=9781450333054|chapter=Wearable Computing, 3D Aug* Reality, Photographic/Videographic Gesture Sensing, and Veillance|title=Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction - TEI '14}}</ref> Augmented reality also has a lot of potential in the gathering and sharing of tacit knowledge. Augmentation techniques are typically performed in real time and in semantic context with environmental elements.  Immersive perceptual information is sometimes combined with supplemental information like scores over a live video feed of a sporting event.  This combines the benefits of both augmented reality technology and [[heads up display]] technology (HUD).

{{toclimit|3}}

== Technology ==

[[File:MicrosoftHoloLensBloomGesture.JPG|thumb|A [[Microsoft HoloLens]] being worn by a man]]

=== Hardware ===

Hardware components for augmented reality are: processor, display, sensors and input devices. Modern [[mobile computing]] devices like [[smartphone]]s and [[tablet computer]]s contain these elements which often include a camera and [[MEMS]] sensors such as [[accelerometer]], [[GPS]], and [[Digital magnetic compass|solid state compass]], making them suitable AR platforms.<ref>Metz, Rachel. [http://www.technologyreview.com/news/428654/augmented-reality-is-finally-getting-real/ Augmented Reality Is Finally Getting Real] ''Technology Review'', 2 August 2012.</ref>

There are 2 technologies: ''diffractive [[Waveguide (optics)|waveguides]]'' and ''reflective waveguides''. Augmented reality systems guru Karl Guttag compared the optics of diffractive waveguides against the competing technology, reflective waveguides.<ref>[https://www.kguttag.com/2018/10/22/magic-leap-hololens-and-lumus-resolution-shootout-ml1-review-part-3/ Karl Guttag on Technology]</ref>

==== Display ====

Various technologies are used in augmented reality rendering, including [[optical head-mounted display|optical projection systems]], [[computer monitor|monitors]], [[mobile device|handheld devices]], and display systems worn on the human body.

A [[head-mounted display]] (HMD) is a display device worn on the forehead, such as a harness or helmet. HMDs place images of both the physical world and virtual objects over the user's field of view. Modern HMDs often employ sensors for six [[Degrees of freedom (mechanics)|degrees of freedom]] monitoring that allow the system to align virtual information to the physical world and adjust accordingly with the user's head movements.<ref>[http://www.eweek.com/c/a/Security/Fleet-Week-Office-of-Naval-Research-Technology/4/ Fleet Week: Office of Naval Research Technology- Virtual Reality Welder Training], ''eweek'', 28 May 2012.</ref><ref>Rolland, Jannick; Baillott, Yohan; Goon, Alexei.[ftp://ftp.cis.upenn.edu/pub/cg/public_html/research/AF/papers/tracking-chapter.pdf A Survey of Tracking Technology for Virtual Environments]{{dead link|date=October 2016 |bot=InternetArchiveBot |fix-attempted=yes }}, Center for Research and Education in Optics and Lasers, University of Central Florida.</ref><ref name=displays>Klepper, Sebastian.[http://campar.in.tum.de/twiki/pub/Chair/TeachingSs07ArProseminar/1_Display-Systems_Klepper_Report.pdf Augmented Reality – Display Systems] {{webarchive |url=https://web.archive.org/web/20130128175343/http://campar.in.tum.de/twiki/pub/Chair/TeachingSs07ArProseminar/1_Display-Systems_Klepper_Report.pdf |date=28 January 2013 }}.</ref> HMDs can provide VR users with mobile and collaborative experiences.<ref name="hmdcollab">{{cite journal|last=Rolland|first=J|author2=Biocca F|author3=Hamza-Lup F|author4=Yanggang H|author5=Martins R|title=Development of Head-Mounted Projection Displays for Distributed, Collaborative, Augmented Reality Applications|url=http://www.creol.ucf.edu/Research/Publications/1357.pdf|journal=Presence: Teleoperators & Virtual Environments|date=October 2005|volume=14|issue=5|pages=528–549|doi=10.1162/105474605774918741}}</ref> Specific providers, such as [[uSens]] and [[Gestigon]], include [[Gesture recognition|gesture controls]] for full virtual [[Immersion (virtual reality)|immersion]].<ref>{{cite web|title=Gestigon Gesture Tracking – TechCrunch Disrupt|url=https://techcrunch.com/video/gestigon-gesture-tracking/517762030/|website=TechCrunch|accessdate=11 October 2016}}</ref><ref>{{cite web|last1=Matney|first1=Lucas|title=uSens shows off new tracking sensors that aim to deliver richer experiences for mobile VR|url=https://techcrunch.com/2016/08/29/usens-unveils-vr-sensor-modules-with-hand-tracking-and-mobile-positional-tracking-tech-baked-in/|website=TechCrunch|accessdate=29 August 2016}}</ref>

In January 2015, [[Meta (company)|Meta]] launched a project led by [[Horizons Ventures]], [[Tim Draper]], [[Alexis Ohanian]], BOE Optoelectronics and [[Garry Tan]].<ref>{{cite news|url=https://blogs.wsj.com/venturecapital/2015/01/28/augmented-reality-headset-maker-meta-secures-23-million/|title=Augmented-Reality Headset Maker Meta Secures $23 Million|last=Chapman|first=Lizette|work=[[Wall Street Journal]]|date=2015-01-28|accessdate=2016-02-29}}</ref><ref>{{cite news|url=https://techcrunch.com/2016/03/02/hands-on-with-the-949-mind-bending-meta-2-augmented-reality-headset/|title=Hands-on with the $949 mind-bending Meta 2 augmented reality headset|last=Matney|first=Lucas|work=[[TechCrunch]]|date=2016-03-02|accessdate=2016-03-02}}</ref><ref>{{cite news|url=https://gigaom.com/2015/01/28/meta-raises-23m-series-a-to-refine-its-augmented-reality-glasses/|title=Meta raises $23M Series A to refine its augmented reality glasses|last=Brewster|first=Signe|work=[[Gigaom]]|date=2015-01-28|accessdate=2016-02-29}}</ref> On February 17, 2016, [[Meta (company)|Meta]] announced their second-generation product at [[TED (conference)|TED]], Meta 2. The Meta 2 [[head-mounted display]] [[Virtual reality headset|headset]] uses a sensory array for hand interactions and [[positional tracking]], visual field view of 90 degrees (diagonal), and resolution display of 2560 x 1440 (20 pixels per degree), which is considered the largest [[field of view]] (FOV) currently available.<ref>{{cite news|url=http://uploadvr.com/meta-2-ar-glasses-ted/|title=Meta Unveils Incredible Augmented Reality Headset at TED|work=[[UploadVR]]|date=2016-02-17|accessdate=2016-02-29}}</ref><ref>{{cite news|url=https://www.bbc.com/news/technology-35583356/|title=TED 2016: Meta augmented reality headset demoed at TED|last=Wakefield|first=Jane|work=[[BBC]]|date=2016-02-17|accessdate=2016-02-29}}</ref><ref>{{cite news|url=https://www.forbes.com/sites/miguelhelft/2016/02/17/new-augmented-reality-startup-meta-dazzles-ted-crowd/#7fcc96713f13/|title=New Augmented Reality Startup Meta Dazzles TED Crowd|last=Helft|first=Miguel|work=[[Forbes]]|date=2016-02-17|accessdate=2016-02-29}}</ref><ref>{{cite news|url=https://www.forbes.com/sites/stevenrosenbaum/2016/02/17/meron-gribetz-wants-to-build-the-ios-of-the-mind/#1bdde5b134bc/|title=Meron Gribetz Wants To Build The IOS Of The Mind|last=Rosenbaum|first=Steven|work=[[Forbes]]|date=2016-02-17|accessdate=2016-02-29}}</ref>

===== Eyeglasses =====
[[File:Vuzix AR3000 AugmentedReality SmartGlasses.png|thumb|[[Smartglasses]] for augmented reality]]

AR displays can be rendered on devices resembling eyeglasses. Versions include eyewear that employs cameras to intercept the real world view and re-display its augmented view through the eyepieces<ref>Grifatini, Kristina. [http://www.technologyreview.com/news/421606/augmented-reality-goggles/ Augmented Reality Goggles], ''Technology Review'' 10 November 2010.</ref> and devices in which the AR imagery is projected through or reflected off the surfaces of the eyewear's lenspieces.<ref>Arthur, Charles. [https://www.theguardian.com/technology/2012/sep/10/augmented-reality-glasses-google-project UK company's 'augmented reality' glasses could be better than Google's], ''The Guardian'', 10 September 2012.</ref><ref>Gannes, Liz. {{cite web |url=http://allthingsd.com/20120404/google-unveils-project-glass-wearable-augmented-reality-glasses/ |title=Google Unveils Project Glass: Wearable Augmented-Reality Glasses |work=allthingsd.com |accessdate=2012-04-04}}, All Things D.</ref><ref>Benedetti, Winda. [http://www.nbcnews.com/technology/ingame/xbox-leak-reveals-kinect-2-augmented-reality-glasses-833583 Xbox leak reveals Kinect 2, augmented reality glasses] ''NBC News''.</ref>

====== HUD ======
[[File:Headset_computer.png|thumb|Headset computer]]
{{Main|Head-up display}}

A head-up display (HUD) is a transparent display that presents data without requiring users to look away from their usual viewpoints. A precursor technology to augmented reality, heads-up displays were first developed for pilots in the 1950s, projecting simple flight data into their line of sight, thereby enabling them to keep their "heads up" and not look down at the instruments. Near-eye augmented reality devices can be used as portable head-up displays as they can show data, information, and images while the user views the real world. Many definitions of augmented reality only define it as overlaying the information.<ref>{{Cite web|title = augmented reality {{!}} an enhanced version of reality created by the use of technology to overlay digital information on an image of something being viewed through a device (as a smartphone camera) also : the technology used to create augmented reality|url = http://www.merriam-webster.com/dictionary/augmented%2520reality|website = www.merriam-webster.com|accessdate = 2015-10-08}}</ref><ref>{{Cite web|title = augmented reality: definition of augmented reality in Oxford dictionary (American English) (US)|url = http://www.oxforddictionaries.com/us/definition/american_english/augmented-reality|website = www.oxforddictionaries.com|accessdate = 2015-10-08}}</ref>  This is basically what a head-up display does; however, practically speaking, augmented reality is expected to include registration and tracking between the superimposed perceptions, sensations, information, data, and images and some portion of the real world.<ref>{{Cite web|title = What is Augmented Reality (AR): Augmented Reality Defined, iPhone Augmented Reality Apps and Games and More|url = http://www.digitaltrends.com/features/what-is-augmented-reality-iphone-apps-games-flash-yelp-android-ar-software-and-more/|website = Digital Trends|accessdate = 2015-10-08|date = 2009-11-03}}</ref>

A number of [[smartglasses]] have been launched for augmented reality. Due to encumbered control, smartglasses are primarily designed for micro-interaction like reading a text message but still far from more well-rounded applications of augmented reality.<ref>{{cite arxiv|eprint=1707.09728|title=Interaction Methods for Smart Glasses|author=Lik-Hang Lee and Pan Hui|class=cs.HC|year=2017}}</ref>

===== Contact lenses =====

Contact lenses that display AR imaging are in development. These [[bionic contact lens]]es might contain the elements for display embedded into the lens including integrated circuitry, LEDs and an antenna for wireless communication.  The first contact lens display was reported in 1999,<ref>{{cite web|url=http://www.google.com/patents/CA2280022|title=Patent CA2280022A1 – Contact lens for the display of information such as text, graphics, or pictures|publisher=}}</ref> then 11 years later in 2010-2011.<ref>Greenemeier, Larry. [http://blogs.scientificamerican.com/observations/2011/11/23/computerized-contact-lenses-could-enable-in-eye-augmented-reality/ Computerized Contact Lenses Could Enable In-Eye Augmented Reality]. ''Scientific American'', 23 November 2011.</ref><ref>Yoneda, Yuka. [http://inhabitat.com/solar-powered-augmented-contact-lenses-cover-your-eye-with-100s-of-leds/ Solar Powered Augmented Contact Lenses Cover Your Eye with 100s of LEDs]. ''inhabitat'', 17 March 2010.</ref><ref>{{cite web |last=Rosen |first=Kenneth |title=Contact Lenses Can Display Your Text Messages |url=http://mashable.com/2012/12/08/contact-lenses-text-messages/|work=Mashable.com |publisher=Mashable.com |accessdate=2012-12-13}}</ref><ref>{{cite news|last=O'Neil |first=Lauren |title=LCD contact lenses could display text messages in your eye |url=http://www.cbc.ca/news/yourcommunity/2012/12/lcd-contact-lenses-could-display-text-messages-in-your-eye.html |publisher=CBC |accessdate=2012-12-12 |deadurl=yes |archiveurl=https://web.archive.org/web/20121211075000/http://www.cbc.ca/news/yourcommunity/2012/12/lcd-contact-lenses-could-display-text-messages-in-your-eye.html |archivedate=11 December 2012 }}</ref> Another version of contact lenses, in development for the U.S. military, is designed to function with AR spectacles, allowing soldiers to focus on close-to-the-eye AR images on the spectacles and distant real world objects at the same time.<ref>Anthony, Sebastian. [http://www.extremetech.com/computing/126043-us-military-developing-multi-focus-augmented-reality-contact-lenses US military developing multi-focus augmented reality contact lenses]. ''ExtremeTech'', 13 April 2012.</ref><ref>Bernstein, Joseph. [http://www.popsci.com/diy/article/2012-05/2012-invention-awards-augmented-reality-contact-lenses 2012 Invention Awards: Augmented-Reality Contact Lenses] ''Popular Science'', 5 June 2012.</ref>

The [[science fiction|futuristic]] short film ''Sight''<ref>[https://vimeo.com/46304267 ''Sight'']</ref> features contact lens-like augmented reality devices.<ref>{{cite news|last1=Kosner|first1=Anthony Wing|title=Sight: An 8-Minute Augmented Reality Journey That Makes Google Glass Look Tame|url=https://www.forbes.com/sites/anthonykosner/2012/07/29/sight-an-8-minute-augmented-reality-journey-that-makes-google-glass-look-tame/|publisher=Forbes|accessdate=3 August 2015|date=29 July 2012}}</ref><ref>{{cite web|last1=O'Dell|first1=J.|title=Beautiful short film shows a frightening future filled with Google Glass-like devices|url=https://venturebeat.com/2012/07/27/sight-systems/|accessdate=3 August 2015|date=27 July 2012}}</ref>

Many scientists have been working on contact lenses capable of many different technological feats. The company Samsung has been working on a contact lens as well. This lens, when finished, is meant to have a built-in camera on the lens itself.<ref>{{Cite web|url=https://www.sciencealert.com/samsung-just-patented-smart-contact-lenses-with-a-built-in-camera|title=Samsung Just Patented Smart Contact Lenses With a Built-in Camera|last=|first=|date=|website=Science Alert|access-date=}}</ref> The design is intended to have you blink to control its interface for recording purposes. It is also intended to be linked with your smartphone to review footage, and control it separately. When successful, the lens would feature a camera, or sensor inside of it. It is said that it could be anything from a light sensor, to a temperature sensor.

In Augmented Reality,  the distinction is made between two distinct modes of tracking, known as ''marker'' and ''[[Markerless motion capture|markerless]]''. Marker are visual cues which trigger the display of the virtual information.<ref>{{Cite news|url=https://anymotion.com/en/wissensgrundlagen/augmented-reality-marker|title=What are augmented reality markers ?|last=|first=|date=|work=|language=}}</ref> A piece of paper with some distinct geometries can be used. The camera recognizes the geometries by identifying specific points in the drawing. Markerless tracking, also called instant tracking, does not use markers. Instead the user positions the object in the camera view preferably in a horizontal plane. It uses sensors in mobile devices to accurately detect the real-world environment, such as the locations of walls and points of intersection.<ref>{{Cite news|url=https://www.marxentlabs.com/what-is-markerless-augmented-reality-dead-reckoning/|title=Markerless Augmented Reality is here.|date=2014-05-09|work=Marxent {{!}} Top Augmented Reality Apps Developer|access-date=2018-01-23|language=en-US}}</ref>

===== Virtual retinal display =====

A [[virtual retinal display]] (VRD) is a personal display device under development at the [[University of Washington]]'s Human Interface Technology Laboratory under Dr. Thomas A. Furness III.<ref name=":2">{{Cite journal|last=Viirre|first=E.|last2=Pryor|first2=H.|last3=Nagata|first3=S.|last4=Furness|first4=T. A.|date=1998|title=The virtual retinal display: a new technology for virtual reality and augmented vision in medicine|journal=Studies in Health Technology and Informatics|volume=50|pages=252–257|issn=0926-9630|pmid=10180549}}</ref> With this technology, a display is scanned directly onto the [[retina]] of a viewer's eye. This results in bright images with high resolution and high contrast. The viewer sees what appears to be a conventional display floating in space.<ref>Tidwell, Michael; Johnson, Richard S.; Melville, David; Furness, Thomas A.[http://www.hitl.washington.edu/publications/p-95-1/ The Virtual Retinal Display – A Retinal Scanning Imaging System] {{webarchive|url=https://web.archive.org/web/20101213134809/http://www.hitl.washington.edu/publications/p-95-1/ |date=13 December 2010 }}, Human Interface Technology Laboratory, University of Washington.</ref>

Several of tests were done in order to analyze the safety of the VRD.<ref name=":2" /> In one test, patients with partial loss of vision were selected to view images using the technology having either macular degeneration (a disease that degenerates the retina) or keratoconus. In the macular degeneration group, 5 out of 8 subjects preferred the VRD images to the CRT or paper images and thought they were better and brighter and were able to see equal or better resolution levels. The Kerocunus patients could all resolve smaller lines in several line tests using the VDR as opposed to their own correction. They also found the VDR images to be easier to view and sharper. As a result of these several tests, virtual retinal display is considered safe technology.

Virtual retinal display creates images that can be seen in ambient daylight and ambient roomlight. The VRD is considered a preferred candidate to use in a surgical display due to its combination of high resolution and high contrast and brightness. Additional tests show high potential for VRD to be used as a display technology for patients that have low vision.

===== EyeTap =====

The [[EyeTap]] (also known as Generation-2 Glass<ref name="GlassEyes">[https://www.webcitation.org/6DKyiVEP3?url=http://wearcam.org/glass.pdf "GlassEyes": The Theory of EyeTap Digital Eye Glass, supplemental material for IEEE Technology and Society, Volume Vol. 31, Number 3, 2012, pp. 10–14].</ref>) captures rays of light that would otherwise pass through the center of the lens of the eye of the wearer, and substitutes synthetic computer-controlled light for each ray of real light.

The Generation-4 Glass<ref name="GlassEyes" /> (Laser EyeTap) is similar to the VRD (i.e. it uses a computer-controlled laser light source) except that it also has infinite depth of focus and causes the eye itself to, in effect, function as both a camera and a display by way of exact alignment with the eye and resynthesis (in laser light) of rays of light entering the eye.<ref>"Intelligent Image Processing", John Wiley and Sons, 2001, {{ISBN|0-471-40637-6}}, 384 p.</ref>

===== Handheld =====

A Handheld display employs a small display that fits in a user's hand. All handheld AR solutions to date opt for video see-through. Initially handheld AR employed [[fiducial marker]]s,<ref name="markersnonmarkers">[http://researchguides.dartmouth.edu/content.php?pid=227212&sid=1891183 Marker vs Markerless AR] {{webarchive|url=https://web.archive.org/web/20130128175349/http://researchguides.dartmouth.edu/content.php?pid=227212&sid=1891183 |date=28 January 2013 }}, Dartmouth College Library.</ref> and later [[GPS]] units and [[MEMS]] sensors such as digital compasses and [[six degrees of freedom]] [[accelerometer]]–[[gyroscope]]. Today [[Simultaneous localization and mapping|SLAM]] markerless trackers such as PTAM are starting to come into use. Handheld display AR promises to be the first commercial success for AR technologies. The two main advantages of handheld AR are the portable nature of handheld devices and the ubiquitous nature of camera phones. The disadvantages are the physical constraints of the user having to hold the handheld device out in front of them at all times, as well as the distorting effect of classically wide-angled mobile phone cameras when compared to the real world as viewed through the eye.<ref>{{cite web |last=Feiner |first=Steve |title=Augmented reality: a long way off? |url=http://www.pocket-lint.com/news/38869/augmented-reality-interview-steve-feiner |work=AR Week |publisher=Pocket-lint |accessdate=2011-03-03|date=2011-03-03 }}</ref>

Games such as ''[[Pokémon Go]]'' and ''[[Ingress (video game)|Ingress]]'' utilize an [[Image Linked Map]] (ILM) interface, where approved [[geotagged]] locations appear on a stylized map for the user to interact with.<ref>{{cite web |last=Borge |first=Ariel |title=The story behind 'Pokémon Go's' impressive mapping |url=http://mashable.com/2016/07/10/john-hanke-pokemon-go/ |date=2016-07-11 |work=Mashable |accessdate=2016-07-13}}</ref>

===== Spatial =====

[[Projection mapping|Spatial augmented reality]] (SAR) augments real-world objects and scenes without the use of special displays such as [[Computer monitor|monitors]], [[head-mounted display]]s or hand-held devices. SAR makes use of digital projectors to display graphical information onto physical objects. The key difference in SAR is that the display is separated from the users of the system. Because the displays are not associated with each user, SAR scales naturally up to groups of users, thus allowing for collocated collaboration between users.

Examples include [[shader lamps]], mobile projectors, virtual tables, and smart projectors. Shader lamps mimic and augment reality by projecting imagery onto neutral objects, providing the opportunity to enhance the object's appearance with materials of a simple unit - a projector, camera, and sensor.

Other applications include table and wall projections. One innovation, the Extended Virtual Table, separates the virtual from the real by including [[beam splitter|beam-splitter]] mirrors attached to the ceiling at an adjustable angle.<ref>Bimber, Oliver; Encarnação, Miguel; Branco, Pedro. [http://www.mitpressjournals.org/doi/abs/10.1162/105474601753272862?journalCode=pres The Extended Virtual Table: An Optical Extension for Table-Like Projection Systems], ''MIT Press Journal'' Vol. 10, No. 6, Pages 613–631, March 13, 2006.</ref> Virtual showcases, which employ beam-splitter mirrors together with multiple graphics displays, provide an interactive means of simultaneously engaging with the virtual and the real. Many more implementations and configurations make spatial augmented reality display an increasingly attractive interactive alternative.

A SAR system can display on any number of surfaces of an indoor setting at once. SAR supports both a graphical visualization and passive [[Haptic perception|haptic]] sensation for the end users. Users are able to touch physical objects in a process that provides passive haptic sensation.<ref name="Azuma_survey" /><ref name="raskarSAR">Ramesh Raskar, Greg Welch, Henry Fuchs [http://www.cs.unc.edu/~raskar/Office Spatially Augmented Reality], First International Workshop on Augmented Reality, Sept 1998.</ref><ref>Knight, Will. [https://www.newscientist.com/article/dn7695 Augmented reality brings maps to life] 19 July 2005.</ref><ref>Sung, Dan. [http://www.pocket-lint.com/news/38802/augmented-reality-maintenance-and-repair Augmented reality in action – maintenance and repair]. ''Pocket-lint'', 1 March 2011.</ref>

==== Tracking ====

Modern mobile augmented-reality systems use one or more of the following [[motion capture|motion tracking]] technologies:
[[digital camera]]s and/or other [[image sensor|optical sensors]], [[accelerometer]]s, [[GPS]], [[gyroscope]]s, [[Digital magnetic compass|solid state compasses]], [[RFID]]. These technologies offer varying levels of accuracy and precision. The most important is the position and orientation of the user's head. [[Hand tracking|Tracking the user's hand(s)]] or a handheld input device can provide a 6DOF interaction technique.<ref>Stationary systems can employ 6DOF track systems such as Polhemus, ViCON, A.R.T, or Ascension.</ref><ref name="SolinixAR">Solinix Company (Spanish Language) [http://www.solinix.co Mobile Marketing based on Augmented Reality],{{dead link|date=January 2019}} First Company that revolutionizes the concept Mobile Marketing based on Augmented Reality, January 2015.</ref>

==== Networking ====

Mobile augmented reality applications are gaining popularity due to the wide adoption of mobile and especially wearable devices. However, they often rely on computationally intensive computer vision algorithms with extreme latency requirements. To compensate for the lack of computing power, offloading data processing to a distant machine is often desired. Computation offloading introduces new constraints in applications, especially in terms of latency and bandwidth. Although there are a plethora of real-time multimedia transport protocols, there is a need for support from network infrastructure as well.<ref>Braud T, Hassani F, et al. [http://www.cse.ust.hk/~panhui/papers/future-networking-challenges_CameraReady.pdf Future Networking Challenges: The Case of Mobile Augmented Reality].</ref>

==== Input devices ====

Techniques include [[speech recognition]] systems that translate a user's spoken words into computer instructions, and [[gesture recognition]] systems that interpret a user's body movements by visual detection or from sensors embedded in a peripheral device such as a wand, stylus, pointer, glove or other body wear.<ref>Marshall, Gary.[http://www.techradar.com/news/computing/beyond-the-mouse-how-input-is-evolving-626794?artc_pg=1 Beyond the mouse: how input is evolving, Touch, voice and gesture recognition and augmented reality]''TechRadar.computing''\''PC Plus'' 23 August 2009.</ref><ref>Simonite, Tom. [http://www.technologyreview.com/news/425431/augmented-reality-meets-gesture-recognition/ Augmented Reality Meets Gesture Recognition], ''Technology Review'', 15 September 2011.</ref><ref>Chaves, Thiago; Figueiredo, Lucas; Da Gama, Alana; de Araujo, Christiano; Teichrieb, Veronica. [http://dl.acm.org/citation.cfm?id=2377147 Human Body Motion and Gestures Recognition Based on Checkpoints]. SVR '12 Proceedings of the 2012 14th Symposium on Virtual and Augmented Reality pp. 271–278.</ref><ref>Barrie, Peter; Komninos, Andreas; Mandrychenko, Oleksii.[http://www.buccleuchpark.net/MUCOM/publi/acmMobility09.pdf A Pervasive Gesture-Driven Augmented Reality Prototype using Wireless Sensor Body Area Networks].</ref> Products which are trying to serve as a controller of AR headsets include Wave by Seebright Inc. and Nimble by [[Intugine]] Technologies.

==== Computer ====

The computer analyzes the sensed visual and other data to synthesize and position augmentations. Computers are responsible for the graphics that go with augmented reality. Augmented reality uses a computer-generated image and it has an striking effect on the way the real world is shown. With the improvement of technology and computers, augmented reality is going to have a drastic change on our perspective of the real world.<ref>{{Cite web|url=https://computer.howstuffworks.com/augmented-reality.htm|title=How Augmented Reality Works|last=Bosnor|first=Kevin|website=howstuffworks|date=2001-02-19}}</ref> According to Time Magazine, in about 15–20 years it is predicted that Augmented reality and virtual reality are going to become the primary use for computer interactions.<ref>{{Cite web|url=http://time.com/4654944/this-technology-could-replace-the-keyboard-and-mouse/|title=This Technology Could Replace the Keyboard and Mouse|last=Bajarin|first=Tim|website=Time Magazine|access-date=}}</ref> Computers are improving at a very fast rate, which means that we are figuring out new ways to improve other technology. The more that computers progress, augmented reality will become more flexible and more common in our society. Computers are the core of augmented reality.

<ref>{{Cite journal|date=1999-04-06|others=Jeffrey Meisner, Walter P. Donnelly, Richard Roosen, Jeffrey Meisner, Walter P. Donnelly, Richard Roosen|title=Augmented reality technology|url=https://patents.google.com/patent/US6625299B1/en}}</ref> The Computer receives data from the sensors which determine the relative position of objects surface. This translates to an input to the computer which then outputs to the users by adding something that would otherwise not be there. The computer comprises memory and a processor.<ref>{{Cite book|title=A Survey of Augmented Reality Technologies, Applications and Limitations|last=Krevelen, Poelman|first=D.W.F, Ronald|publisher=International Journal of Virtual Reality|year=2010|isbn=|location=|pages=3,6}}</ref> The computer takes the scanned environment then generates images or a video and puts it on the receiver for the observer to see. The fixed marks on an objects surface are stored in the memory of a computer. The computer also withdrawals from its memory to present images realistically to the onlooker. The best example of this is of the Pepsi Max AR Bus Shelter.<ref>{{Citation|last=Pepsi Max|title=Unbelievable Bus Shelter {{!}} Pepsi Max. Unbelievable #LiveForNow|date=2014-03-20|url=https://www.youtube.com/watch?time_continue=80&v=Go9rf9GmYpM|accessdate=2018-03-06}}</ref>

=== Software and algorithms ===

A key measure of AR systems is how realistically they integrate augmentations with the real world. The software must derive real world coordinates, independent from the camera, from camera images. That process is called [[image registration]], and uses different methods of [[computer vision]], mostly related to [[video tracking]].<ref name="recentadvances" /><ref>Maida, James; Bowen, Charles; Montpool, Andrew; Pace, John. [http://research.jsc.nasa.gov/PDF/SLiSci-14.pdf Dynamic registration correction in augmented-reality systems] {{webarchive|url=https://web.archive.org/web/20130518032710/http://research.jsc.nasa.gov/PDF/SLiSci-14.pdf |date=18 May 2013 }}, ''Space Life Sciences'', NASA.</ref> Many computer vision methods of augmented reality are inherited from [[visual odometry]].

Usually those methods consist of two parts. The first stage is to detect [[interest point detection|interest points]], [[fiducial marker]]s or [[optical flow]] in the camera images. This step can use [[Feature detection (computer vision)|feature detection]] methods like [[corner detection]], [[blob detection]], [[edge detection]] or [[Thresholding (image processing)|thresholding]], and other [[image processing]] methods.<ref>State, Andrei; Hirota, Gentaro; Chen, David T; Garrett, William; Livingston, Mark. [http://www.cs.princeton.edu/courses/archive/fall01/cs597d/papers/state96.pdf Superior Augmented Reality Registration by Integrating Landmark Tracking and Magnetic Tracking], Department of Computer ScienceUniversity of North Carolina at Chapel Hill.</ref><ref>Bajura, Michael; Neumann, Ulrich. [http://graphics.usc.edu/cgit/publications/papers/DynamicRegistrationVRAIS95.pdf Dynamic Registration Correction in Augmented-Reality Systems] University of North Carolina, University of Southern California.</ref> The second stage restores a real world coordinate system from the data obtained in the first stage. Some methods assume objects with known geometry (or fiducial markers) are present in the scene. In some of those cases the scene 3D structure should be precalculated beforehand. If part of the scene is unknown [[simultaneous localization and mapping]] (SLAM) can map relative positions. If no information about scene geometry is available, [[structure from motion]] methods like [[bundle adjustment]] are used. Mathematical methods used in the second stage include [[projective geometry|projective]] ([[Epipolar geometry|epipolar]]) geometry, [[geometric algebra]], [[Rotation formalisms in three dimensions|rotation representation]] with [[Rotation matrix#Exponential map|exponential map]], [[Kalman filter|kalman]] and [[Particle filter|particle]] filters, [[nonlinear optimization]], [[robust statistics]].{{citation needed|date=February 2017}}

[[Augmented Reality Markup Language]] (ARML) is a data standard developed within the [[Open Geospatial Consortium]] (OGC),<ref>{{cite web
 | title = ARML 2.0 SWG
 | work = Open Geospatial Consortium website
 | publisher = Open Geospatial Consortium
 | url = http://www.opengeospatial.org/projects/groups/arml2.0swg
 | format =
 | doi =
 | accessdate = 12 November 2013
 }}</ref> which consists of [[XML]] grammar to describe the location and appearance of virtual objects in the scene, as well as ECMAScript bindings to allow dynamic access to properties of virtual objects.

To enable rapid development of augmented reality applications, some software development kits (SDKs) have emerged.<ref>{{cite web|url = http://augmentedrealitynews.org/ar-sdk/top-5-augmented-reality-sdks/|title = Top 5 AR SDKs |publisher = Augmented Reality News |accessdate = 15 November 2013}}</ref><ref>{{cite web|url = http://augmentedworldexpo.com/news/tutorial-top-10-mobile-augmented-reality-sdks-for-developers//|title = Top 10 AR SDKs|publisher = Augmented World Expo|accessdate = 15 November 2013|archive-url = https://web.archive.org/web/20131123011106/http://augmentedworldexpo.com/news/tutorial-top-10-mobile-augmented-reality-sdks-for-developers/|archive-date = 23 November 2013|dead-url = yes|df = dmy-all}}</ref> A few SDKs such as CloudRidAR<ref>Huang, Z., Li, W., Hui, P., Peylo, C. [http://www.cse.ust.hk/~panhui/papers/mars2014_cloudridar.pdf]. ''CloudRidAR: A Cloud-based Architecture for Mobile''
Augmented Reality'' Proceeding of MARS'14, July 2014.''</ref> leverage cloud computing for performance improvement. AR SDKs are offered by Vuforia,<ref>{{cite web|url = https://www.vuforia.com |title = Vuforia AR SDK |publisher = Vuforia |accessdate = 15 November 2013}}</ref> [[ARToolKit]], Catchoom CraftAR<ref>[http://catchoom.com/product/craftar/augmented-reality-sdk/ Catchoom CraftAR]</ref> Mobinett AR,<ref>{{cite web|url = http://www.mobinett.com |title = Mobinett AR SDK |publisher = Mobinett |accessdate = 15 November 2014}}</ref> Wikitude,<ref>{{cite web|url = http://www.wikitude.com |title = Wikitude AR SDK |publisher = Wikitude |accessdate = 15 November 2013}}</ref> Blippar<ref>{{cite web|url = https://blippar.com |title = Blippar AR |publisher = Blippar |accessdate = 3 January 2015}}</ref> [[Layar]],<ref>{{cite web|url = https://www.layar.com |title = Layar AR SDK |publisher = Layar |accessdate = 15 November 2013}}</ref> [[Meta (company)|Meta]].<ref>{{cite news|url=http://www.cnn.com/2013/10/31/tech/innovation/meta-augmented-reality-glasses/|title=Glasses to make you a real-life Tony Stark|last=Angley|first=Natalie|work=[[CNN]]|date=2013-10-31|accessdate=2014-11-14}}</ref><ref>{{cite news|url=https://www.usatoday.com/story/tech/2013/07/29/change-agents-meron-gribetz-meta-3d-glasses/2579315/|title=Change Agents: Seeing world through Meta's 3-D glasses|last=Cava|first=Marco|work=[[USATODAY]]|date=2013-07-30|accessdate=2016-02-28}}</ref> and ARLab.<ref>{{cite web |url = https://www.arlab.com |title = ARLab Augmented Reality SDK |publisher = ARLab |deadurl = yes |archiveurl = https://web.archive.org/web/20170718060716/http://www.arlab.com/ |archivedate = 18 July 2017 |df = dmy-all }}</ref>

=== Development ===
The implementation of Augmented Reality in consumer products requires considering the design of the applications and the related constraints of the technology platform. Since AR system rely heavily on the immersion of the user and the interaction between the user and the system, design can facilitate the adoption of virtuality. For most Augmented Reality systems, a similar design guideline can be followed. The following lists some considerations for designing Augmented Reality applications:

==== Environmental/context design<ref name=":3">{{Cite web|url=https://uxdesign.cc/the-principles-of-good-user-experience-design-for-augmented-reality-d8e22777aabd.|title="The Principles of Good UX for Augmented Reality – UX Collective." UX Collective|last=Wilson|first=Tyler|date=|website=|access-date=}}{{dead link|date=September 2018|bot=medic}}{{cbignore|bot=medic}}</ref> ====

Context Design focuses on the end-user's physical surrounding, spatial space, and accessibility that may play a role when using the AR system. &nbsp;Designers should be aware of the possible physical scenarios the end-user may be in such as:

* Public, in which the users uses their whole body to interact with the software
* Personal, in which the user uses a smartphone in a public space
* Intimate, in which the user is sitting with a desktop and is not really in movement
* Private, in which the user has on a wearable.

By evaluating each physical scenario, potential safety hazard can be avoided and changes can be made to greater improve the end-user's immersion. UX designers will have to define user journeys for the relevant physical scenarios and define how the interface will react to each.

Especially in AR systems, it is vital to also consider the spatial space and the surrounding elements that change the effectiveness of the AR technology. Environmental elements such as lighting, and sound can prevent the sensor of AR devices from detecting necessary data and ruin the immersion of the end-user.<ref name=":4">{{Cite web|url=https://www.igi-global.com/book/emerging-technologies-augmented-reality/338.|title=Emerging Technologies of Augmented Reality: Interfaces and Design|last=Haller, Michael, Billinghurst, Mark, Thomas, and Bruce|date=|website=|access-date=}}</ref>

Another aspect of context design involves the design of the system's functionality and its ability to accommodate for user preferences.<ref name=":5">{{Cite web|url=https://blog.google/products/google-vr/best-practices-mobile-ar-design/|title=Best Practices for Mobile AR Design- Google|last=|first=|date=2017-12-13|website=|access-date=}}</ref><ref>{{Cite web|url=http://www.eislab.fim.uni-passau.de/files/publications/2014/TR2014-HCIwithAR_1.pdf|title=Human Computer Interaction with Augmented Reality|last=|first=|date=|website=|access-date=}}</ref> While accessibility tools are common in basic application design, some consideration should be made when designing time-limited prompts (to prevent unintentional operations), audio cues and overall engagement time. It is important to note that in some situations, the application's functionality may hinder the user's ability. For example, applications that is used for driving should reduce the amount of user interaction and user audio cues instead.

==== Interaction design ====

[[Interaction design]] in augmented reality technology centers on the user's engagement with the end product to improve the overall user experience and enjoyment. The purpose of Interaction Design is to avoid alienating or confusing the user by organising the information presented. Since user interaction relies on the user's input, designers must make system controls easier to understand and accessible. A common technique to improve usability for augmented reality applications is by discovering the frequently accessed areas in the device's touch display and design the application to match those areas of control.<ref>{{Cite web|url=https://theblog.adobe.com/basic-patterns-of-mobile-navigation/|title=Basic Patterns of Mobile Navigation|last=|first=|date=2017-05-09|website=|access-date=}}</ref> It is also important to structure the [[user journey maps]] and the flow of information presented which reduce the system's overall cognitive load and greatly improves the learning curve of the application.<ref>{{Cite web|url=https://www.thinkwithgoogle.com/marketing-resources/experience-design/principles-of-mobile-app-design-engage-users-and-drive-conversions/|title=Principles of Mobile App Design: Engage Users and Drive Conversions|last=|first=|date=|website=|archive-url=https://web.archive.org/web/20180413185621/https://www.thinkwithgoogle.com/marketing-resources/experience-design/principles-of-mobile-app-design-engage-users-and-drive-conversions/|archive-date=2018-04-13|dead-url=yes|access-date=}}</ref>

In interaction design, it is important for developers to utilize augmented reality technology that complement the system's function or purpose.<ref>{{Cite web|url=https://www.uxmatters.com/mt/archives/2009/08/inside-out-interaction-design-for-augmented-reality.php|title=Inside Out: Interaction Design for Augmented Reality-UXmatters|last=|first=|date=|website=|access-date=}}</ref> For instance, the utilization of exciting AR filters and the design of the unique sharing platform in [[Snapchat]] enables users to better the user's social interactions. In other applications that require users to understand the focus and intent, designers can employ a [[reticle]] or [[Ray casting|raycast]] from the device.<ref name=":5" /> Moreover, augmented reality developers may find it appropriate to have digital elements scale or react to the direction of the camera and the context of objects that can are detected.<ref name=":4" /> &nbsp;

Augmented reality technology allows to utilize the introduction of [[Three-dimensional space|3D space]]. This means that a user can potentially access multiple copies of 2D interfaces within a single AR application.<ref name=":4" />

==== Visual design ====

In general, [[Visual design elements and principles|visual design]] is the appearance of the developing application that engages the user. To improve the graphic interface elements and user interaction, developers may use visual cues to inform user what elements of UI are designed to interact with and how to interact with them. Since navigating in AR application may appear difficult and seem frustrating, visual cues design can make interactions seem more natural.<ref name=":3" />

In some augmented reality applications that uses a 2D device as an interactive surface, the 2D control environment does not translate well in 3D space making users hesitant to explore their surroundings. To solve this issue, designers should apply visual cues to assist and encourage users to explore their surroundings.

It is important to note the two main objects in AR when developing VR applications: 3D [[volumetric]] objects that are manipulatable and realistically interact with light and shadow; and animated media imagery such as images and videos which are mostly traditional 2D media rendered in a new context for augmented reality.<ref name=":3" /> When virtual objects are projected onto a real environment, it is challenging for augmented reality application designers to ensure a perfectly seamless integration relative to the real-world environment, especially with 2D objects. As such, designers can add weight to objects, use depths maps, and choose different material properties that highlight the object's presence in the real world. Another visual design that can be applied is using different [[lighting]] techniques or casting shadows to improve overall depth judgment. For instance, a common lighting technique is simply placing a light source overhead at the 12 o’clock position, to create shadows upon virtual objects.<ref name=":3" />

== Possible applications ==
{{editorial|section|date=June 2013}}

Augmented reality has been explored for many applications, from gaming and entertainment to medicine, education and business. Example application areas described below include Archaeology, Architecture, Commerce and Education.  Some of the earliest cited examples include Augmented Reality used to support surgery by providing virtual overlays to guide medical practitioners to AR content for astronomy and welding.<ref>{{Cite news|url=http://images.huffingtonpost.com/2016-05-13-1463155843-8474094-AR_history_timeline.jpg|title=The Lengthy History of Augmented Reality|last=|first=|date=May 15, 2016|work=Huffington Post|access-date=}}</ref><ref name="Dupzyk 2016"/><ref>{{Cite news|url=https://www.slashgear.com/dont-be-blind-on-wearable-cameras-insists-ar-genius-20239514/|title=Don’t be blind on wearable cameras insists AR genius|date=2012-07-20|work=SlashGear|access-date=2018-10-21|language=en-US}}</ref>

=== Literature ===
[[File:Ar code.png|thumb|An example of an AR code containing a [[QR code]]]]
The first description of AR as it is known today was in ''[[Virtual Light]]'', the 1994 novel by William Gibson. In 2011, AR was blended with poetry by [[ni ka]] from Sekai Camera in Tokyo, Japan. The prose of these AR poems come from [[Paul Celan]], "[[Die Niemandsrose]]", expressing the aftermath of the [[2011 Tōhoku earthquake and tsunami]].<ref>「AR技術による喪の空間の創造　ni_kaのAR詩について」『[[DOMMUNE]] OFFICIAL GUIDE BOOK2』[[河出書房新社]]　2011年 pp&nbsp;49–50</ref><ref>「ni_kaの「AR詩」」『[[Web Designing]]』2012年6月号　[[マイナビ]]　p43</ref><ref>{{Cite web|url=http://yaplog.jp/tipotipo/category_33/|title=ＡＲ詩 ｜ にかにかブログ！　（おぶんがく＆包丁＆ちぽちぽ革命）|website=にかにかブログ！　（おぶんがく＆包丁＆ちぽちぽ革命）|language=ja-JP|access-date=2018-05-20}}</ref>

=== Archaeology ===

AR has been used to aid archaeological research. By augmenting archaeological features onto the modern landscape, AR allows archaeologists to formulate possible site configurations from extant structures.<ref>{{cite journal |title=Augmenting Phenomenology: Using Augmented Reality to Aid Archaeological Phenomenology in the Landscape |author=Stuart Eve |doi=10.1007/s10816-012-9142-7 | volume=19 |issue=4 |journal=Journal of Archaeological Method and Theory |pages=582–600|url=http://discovery.ucl.ac.uk/1352447/1/Eve_2012_Augmented_Phenomenology.pdf |year=2012 }}</ref> Computer generated models of ruins, buildings, landscapes or even ancient people have been recycled into early archaeological AR applications.<ref>{{cite book |url=http://portal.acm.org/citation.cfm?id=854948 |title=Archeoguide: System Architecture of a Mobile Outdoor Augmented Reality System |author1=Dähne, Patrick |author2=Karigiannis, John N. |accessdate=2010-01-06|isbn=9780769517810 |year=2002 }}</ref><ref>{{cite web |url=http://archpro.lbg.ac.at/press-release/school-gladiators-discovered-roman-carnuntum-austria |title=School of Gladiators discovered at Roman Carnuntum, Austria |author=LBI-ArchPro |accessdate=2014-12-29|date=2011-09-05 }}</ref><ref name="ref0">{{Cite journal|title = Mixing virtual and real scenes in the site of ancient Pompeii|journal = Computer Animation and Virtual Worlds|date = February 1, 2005|issn = 1546-427X|pages = 11–24|volume = 16|issue = 1|doi = 10.1002/cav.53|first = George|last = Papagiannakis|first2 = Sébastien|last2 = Schertenleib|first3 = Brian|last3 = O'Kennedy|first4 = Marlene|last4 = Arevalo-Poizat|first5 = Nadia|last5 = Magnenat-Thalmann|first6 = Andrew|last6 = Stoddart|first7 = Daniel|last7 = Thalmann|citeseerx = 10.1.1.64.8781}}</ref> For example, implementing a system like, "VITA (Visual Interaction Tool for Archaeology)" will allow users to imagine and investigate instant excavation results without leaving their home. Each user can collaborate by mutually "navigating, searching, and viewing data." Hrvoje Benko, a researcher for the computer science department at Columbia University, points out that these particular systems and others like it can provide "3D panoramic images and 3D models of the site itself at different excavation stages" all the while organizing much of the data in a collaborative way that is easy to use. Collaborative AR systems supply multimodal interactions that combine the real world with virtual images of both environments.<ref>{{Cite journal|last=Benko|first=Hrvoje|date=2004|title=Collaborative Mixed Reality Visualization of an Archaeological Excavation|url=|journal=1|volume=|pages=1–3|doi=10.1145/1040000/1033710/21910132|via=|doi-broken-date=2018-12-20}}</ref> 
AR has been recently adopted also in the underwater archaeology field to efficiently support and facilitate the manipulation of archaeological artefacts.<ref>{{cite journal|last1= Bruno|first1=Fabio|last2=Lagudi|first2=Antonio|last3=Barbieri|first3=Loris|last4=Rizzo|first4=Domenico|last5=Muzzupappa|first5=Maurizio|last6=De Napoli|first6=Luigi|title=Augmented reality visualization of scene depth for aiding ROV pilots in underwater manipulation|journal=Ocean Engineering|date=2018|volume=168|pages=140–154|doi=10.1016/j.oceaneng.2018.09.007}}</ref>

=== Architecture ===

AR can aid in visualizing building projects. Computer-generated images of a structure can be superimposed into a real-life local view of a property before the physical building is constructed there; this was demonstrated publicly by [[Trimble Navigation]] in 2004. AR can also be employed within an architect's workspace, rendering animated 3D visualizations of their 2D drawings. Architecture sight-seeing can be enhanced with AR applications, allowing users viewing a building's exterior to virtually see through its walls, viewing its interior objects and layout.<ref>Divecha, Devina.[http://www.designmena.com/inspiration/augmented-reality-ar-part-architecture-design Augmented Reality (AR) used in architecture and design]. ''designMENA'' 8 September 2011.</ref><ref>[http://www.news.uwa.edu.au/201203054410/events/architectural-dreams-agumented-reality Architectural dreams in augmented reality]. ''University News'', University of Western Australia. 5 March 2012.</ref><ref name="Outdoor AR">[https://www.youtube.com/watch?v=jL3C-OVQKWU Outdoor AR]. ''TV One News'', 8 March 2004.</ref>

With the continual improvements to [[Global Positioning System|GPS]] accuracy, businesses are able to use augmented reality to visualize [[georeference]]d models of construction sites, underground structures, cables and pipes using mobile devices.<ref>{{cite web|last=Churcher|first=Jason|title=Internal accuracy vs external accuracy|url=http://www.augview.net/blog/archive-7May2013.html|accessdate=7 May 2013}}</ref>  Augmented reality is applied to present new projects, to solve on-site construction challenges, and to enhance promotional materials.<ref>{{cite web|title=Augment for Architecture & Construction|url=http://www.augmentedev.com/augmented-reality-architecture/|accessdate=12 October 2015|archive-url=https://web.archive.org/web/20151108054418/http://www.augmentedev.com/augmented-reality-architecture/|archive-date=8 November 2015|dead-url=yes|df=dmy-all}}</ref>  Examples include the [[Daqri]] Smart Helmet, an Android-powered hard hat used to create augmented reality for the industrial worker, including visual instructions, real-time alerts, and 3D mapping.

Following the [[Christchurch earthquake]], the University of Canterbury released CityViewAR,<ref>{{Cite web|url=https://www.stuff.co.nz/technology/digital-living/6121248/App-gives-a-view-of-city-as-it-used-to-be|title=App gives a view of city as it used to be|website=Stuff|language=en|access-date=2018-05-20}}</ref> which enabled city planners and engineers to visualize buildings that had been destroyed.<ref>{{cite book|last=Lee|first=Gun|title=CityViewAR outdoor AR visualization|year=2012|publisher=ACM|isbn=978-1-4503-1474-9|page=97|url=http://dl.acm.org/citation.cfm?id=2379281}}</ref> Not only did this provide planners with tools to reference the previous [[cityscape]], but it also served as a reminder to the magnitude of the devastation caused, as entire buildings had been demolished.

=== Visual art ===

[[File:10.000 Moving Cities, Augmented Reality Multiplayer Game.png|thumb|10.000 Moving Cities, [[Marc Lee]], Augmented Reality Multiplayer Game, Art Installation<ref>{{cite web|title=10.000 Moving Cities – Same but Different, AR (Augmented Reality) Art Installation, 2018|publisher = Marc Lee|url=http://marclee.io/en/10-000-moving-cities-same-but-different-ar/|accessdate=2018-12-24 }}</ref>]]

AR applied in the visual arts allows objects or places to trigger artistic multidimensional experiences and interpretations of reality.

Augmented Reality can aid in the progression of visual art in museums by allowing museum visitors to view artwork in galleries in a multidimensional way through their phone screens. [[Museum of Modern Art|The Museum of Modern Art]] in New York has created an exhibit in their art museum showcasing Augmented Reality features that viewers can see using an app on their smartphone.<ref>{{Cite book|url=https://books.google.com/?id=OyGiW2OYI8AC&pg=PR1&dq=augmented+reality:+an+emerging+technologies+guide+to+AR#v=onepage&q=augmented%20reality:%20an%20emerging%20technologies%20guide%20to%20AR&f=false|title=Augmented Reality: An Emerging Technologies Guide to AR|last=Kipper|first=Greg|last2=Rampolla|first2=Joseph|date=2012-12-31|publisher=Elsevier|isbn=9781597497343|language=en}}</ref> The museum has developed their personal app, called MoMAR Gallery, that museum guests can download and use in the Augmented Reality specialized gallery in order to view the museum's paintings in a different way.<ref>{{Cite news|url=https://www.wired.com/story/augmented-reality-art-museums/|title=Augmented Reality Is Transforming Museums|work=WIRED|access-date=2018-09-30|language=en-US}}</ref> This allows individuals to see hidden aspects and information about the paintings, and to be able to have an interactive technological experience with artwork as well.

AR technology aided the development of [[eye tracking]] technology to translate a disabled person's eye movements into drawings on a screen.<ref>Webley, Kayla. [http://www.time.com/time/specials/packages/article/0,28804,2029497_2030618_2029822,00.html The 50 Best Inventions of 2010 – EyeWriter] ''Time'', 11 November 2010.</ref>

=== Commerce ===

[[File:AR-Icon.svg|thumb|The AR-Icon can be used as a marker on print as well as on online media. It signals the viewer that digital content is behind it. The content can be viewed with a smartphone or tablet.]]
AR is used to integrate print and video marketing. Printed marketing material can be designed with certain "trigger" images that, when scanned by an AR-enabled device using image recognition, activate a video version of the promotional material. A major difference between augmented reality and straightforward image recognition is that one can overlay multiple media at the same time in the view screen, such as social media share buttons, the in-page video even audio and 3D objects. Traditional print-only publications are using augmented reality to connect many different types of media.<ref>Katts, Rima. [http://www.mobilemarketer.com/cms/news/software-technology/13810.html Elizabeth Arden brings new fragrance to life with augmented reality] ''Mobile Marketer'', 19 September 2012.</ref><ref>Meyer, David. [http://gigaom.com/europe/telefonica-bets-on-augmented-reality-with-aurasma-tie-in/ Telefónica bets on augmented reality with Aurasma tie-in] ''gigaom'', 17 September 2012.</ref><ref>Mardle, Pamela.[http://www.printweek.com/news/1153133/Video-becomes-reality-Stuprintcom/ Video becomes reality for Stuprint.com] {{webarchive |url=https://web.archive.org/web/20130312171811/http://www.printweek.com/news/1153133/Video-becomes-reality-Stuprintcom/ |date=12 March 2013 }}. ''Printweek'', 3 October 2012.</ref><ref>Giraldo, Karina.[http://www.solinix.co/blog/marketing-movil-su-importancia-para-las-marcas/ Why mobile marketing is important for brands?] {{webarchive|url=https://web.archive.org/web/20150402135323/http://solinix.co/blog/marketing-movil-su-importancia-para-las-marcas/ |date=2 April 2015 }}. ''SolinixAR'', Enero 2015.</ref><ref>{{cite news|title=Augmented reality could be advertising world’s best bet|url=http://www.financialexpress.com/article/industry/companies/augmented-reality-could-be-advertising-worlds-best-bet/64855/|agency=The Financial Express|date=18 April 2015|deadurl=yes|archiveurl=https://web.archive.org/web/20150521061314/http://www.financialexpress.com/article/industry/companies/augmented-reality-could-be-advertising-worlds-best-bet/64855/|archivedate=21 May 2015|df=dmy-all}}</ref>

AR can enhance product previews such as allowing a customer to view what's inside a product's packaging without opening it.<ref>Humphries, Mathew.[http://www.geek.com/articles/gadgets/lego-demos-augmented-reality-boxes-with-gesture-recognition-20110919/].''Geek.com'' 19 September 2011.</ref> AR can also be used as an aid in selecting products from a catalog or through a kiosk. Scanned images of products can activate views of additional content such as customization options and additional images of the product in its use.<ref>Netburn, Deborah.[http://www.latimes.com/business/technology/la-ikeas-augmented-reality-app-20120723,0,1261315.story Ikea introduces augmented reality app for 2013 catalog]. ''Los Angeles Times'', 23 July 2012.</ref>

By 2010, virtual dressing rooms had been developed for e-commerce.<ref>[https://www.researchgate.net/profile/Rick_Van_Krevelen2/publication/279867852_A_Survey_of_Augmented_Reality_Technologies_Applications_and_Limitations/links/58dab7f445851578dfcac285/A-Survey-of-Augmented-Reality-Technologies-Applications-and-Limitations.pdf The International Journal of Virtual Reality, 2010, 9 (2)]</ref>
[[File:Augmented Reality for eCommerce.jpg|alt=Augment SDK|thumb|[[Augment (app)|Augment]] SDK offers brands and retailers the capability to personalize their customers' shopping experience by embedding AR product visualization into their eCommerce platforms.]]

In 2012, a mint used AR techniques to market a commemorative coin for Aruba. The coin itself was used as an AR trigger, and when held in front of an AR-enabled device it revealed additional objects and layers of information that were not visible without the device.<ref>Alexander, Michael.[http://news.coinupdate.com/arbua-shoco-owl-silver-coin-with-augmented-reality-1490/ Arbua Shoco Owl Silver Coin with Augmented Reality], ''Coin Update'' July 20, 2012.</ref><ref>[http://www.todaysxm.com/2012/08/07/royal-mint-produces-revolutionary-commemorative-coin-for-aruba/ Royal Mint produces revolutionary commemorative coin for Aruba] {{webarchive |url=https://web.archive.org/web/20150904090653/http://www.todaysxm.com/2012/08/07/royal-mint-produces-revolutionary-commemorative-coin-for-aruba/ |date=4 September 2015 }}, ''Today'' August 7, 2012.</ref>

In 2015, the Bulgarian startup iGreet developed its own AR technology and used it to make the first premade "live" greeting card. A traditional paper card was augmented with digital content which was revealed by using the iGreet app.<ref>{{Cite web|url=http://time.com/3665770/5-apps-evernote/|title=5 Apps You Just Can't Miss This Week|date=|website=time.com|publisher=|access-date=}}</ref><ref>{{Cite web|url=http://bnr.bg/en/post/100678361/greeting-cards-brought-back-to-life-via-bulgarian-mobile-application|title=Greeting cards brought back to life via Bulgarian mobile application|date=|website=bnr.bg|publisher=|access-date=}}</ref>

In 2017, [[Ikea]] announced Ikea Place app. The app contains a catalogue of over 2,000 products—nearly the company's full collection of umlauted sofas, armchairs, coffee tables, and storage units which one can place anywhere in a room with their phone.<ref name="Wired.com">{{cite journal | url = https://www.wired.com/story/ikea-place-ar-kit-augmented-reality/ | title = IKEA's new app flaunts what you'll love most about AR| journal = Wired| accessdate = 20 September 2017| date = 2017-09-20}}</ref>

In 2018, [[Apple Inc.|Apple]] announced USDZ AR file support for iPhones and iPads with iOS12. Apple has created an AR QuickLook Gallery that allows masses experience Augmented reality on their own Apple device.<ref name="ComputerWorld.com">{{cite web | url = https://www.computerworld.com/article/3307437/mobile-wireless/this-small-ios-12-feature-is-the-birth-of-a-whole-industry.html | title = This small iOS 12 feature is the birth of a whole industry | publisher = Jonny Evans | accessdate = 19 September 2018| date = 2018-09-19 }}</ref>

In 2018, [[Shopify]], the Canadian commerce company, announced ARkit2 integrations and their merchants are able to use the tools to upload 3D models of their products, which users will be able to tap on the goods inside Safari to view in their real-world environments.<ref name="Techcrunch.com">{{cite web | url = https://techcrunch.com/2018/09/17/shopify-is-bringing-apples-latest-ar-tech-to-their-platform/ | title = Shopify is bringing Apple's latest AR tech to their platform | publisher = Lucas Matney | accessdate = 3 December 2018}}</ref>

In 2018, [[Twinkl]] released free AR classroom application, pupils can see how York looked over 1,900 years ago.<ref name="https://www.qaeducation.co.uk">{{cite journal | url = https://www.qaeducation.co.uk/article/ar-classroom-york | title = History re-made: New AR classroom application lets pupils see how York looked over 1,900 years ago | journal = QA Education| accessdate = 4 September 2018| date = 2018-09-04}}</ref> Twinkl launched the first ever multi-player AR game, Little Red<ref name="https://www.prolificnorth.co.uk">{{cite journal | url = https://www.prolificnorth.co.uk/news/digital/2018/09/sheffields-twinkl-claims-ar-first-new-game| title = Sheffield's Twinkl claims AR first with new game | journal = Prolific North| accessdate = 19 September 2018| date = 2018-09-19}}</ref> and has over 100 free AR educational models.<ref name="http://www.the-educator.org">{{cite journal | url = http://www.the-educator.org/technology-from-twinkl-brings-never-seen-before-objects-to-the-classroom/ | title = Technology from Twinkl brings never seen before objects to the classroom | journal = The Educator UK| accessdate = 21 December 2018| date = 2018-09-21}}</ref>

=== Education ===

In educational settings, AR has been used to complement a standard curriculum. Text, graphics, video, and audio may be superimposed into a student's real-time environment. Textbooks, flashcards and other educational reading material may contain embedded "[[fiducial marker|markers]]" or triggers that, when scanned by an AR device, produced supplementary information to the student rendered in a multimedia format.<ref>[http://www.prweb.com/releases/2011/10/prweb8899908.htm Groundbreaking Augmented Reality-Based Reading Curriculum Launches], ‘’PRweb’’, 23 October 2011.</ref><ref>Stewart-Smith, Hanna. [http://www.zdnet.com/blog/asia/education-with-augmented-reality-ar-textbooks-released-in-japan-video/1541 Education with Augmented Reality: AR textbooks released in Japan], ‘’ZDnet’’, 4 April 2012.</ref><ref>[http://smarterlearning.wordpress.com/2011/11/10/augmented-reality-in-education/ Augmented reality in education] ''smarter learning''.</ref>

As AR evolves, students can participate interactively and interact with knowledge more authentically. Instead of remaining passive recipients, students can become active learners, able to interact with their learning environment. Computer-generated simulations of historical events allow students to explore and learning details of each significant area of the event site.<ref>Lubrecht, Anna. [http://digitalunion.osu.edu/2012/04/24/augmented-reality-for-education/ Augmented Reality for Education] ‘’The Digital Union’’, The Ohio State University 24 April 2012.</ref>

In higher education, Construct3D, a Studierstube system, allows students to learn mechanical engineering concepts, math or geometry.<ref>{{Cite web |url=http://acdc.sav.us.es/pixelbit/images/stories/p41/15.pdf |title=Archived copy |access-date=19 June 2014 |archive-url=https://web.archive.org/web/20150417053823/http://acdc.sav.us.es/pixelbit/images/stories/p41/15.pdf |archive-date=17 April 2015 |dead-url=yes |df=dmy-all }}</ref> Chemistry AR apps allow students to visualize and interact with the spatial structure of a molecule using a marker object held in the hand.<ref>Maier, Patrick; Tönnis, Marcus; Klinker, Gudron. [http://ar.in.tum.de/pub/maierp2009ijas/maierp2009ijas.pdf Augmented Reality for teaching spatial relations], ''Conference of the International Journal of Arts & Sciences (Toronto 2009'').</ref> Others have used HP Reveal, a free app, to create AR notecards for studying organic chemistry mechanisms or to create virtual demonstrations of how to use laboratory instrumentation.<ref>{{Cite journal|title=A Simple and Practical Method for Incorporating Augmented Reality into the Classroom and Laboratory|last=Plunkett|first=Kyle|date=2018-09-27|doi=10.26434/chemrxiv.7137827.v1}}</ref> Anatomy students can visualize different systems of the human body in three dimensions.<ref>{{cite web|url=https://www.vuforia.com/case-studies/anatomy-4d |title=Anatomy 4D – Qualcomm |work=Qualcomm |accessdate=2 July 2015 |deadurl=yes |archiveurl=https://web.archive.org/web/20160311085744/http://vuforia.com/case-studies/anatomy-4d |archivedate=11 March 2016 |df=dmy }}</ref>

== Remote collaboration ==
Primary school children learn easily from interactive experiences. Astronomical constellations and the movements of objects in the solar system were oriented in 3D and overlaid in the direction the device was held, and expanded with supplemental video information. Paper-based science book illustrations could seem to come alive as video without requiring the child to navigate to web-based materials.

In 2013, a project was launched on Kickstarter to teach about electronics with an educational toy that allowed children to scan their circuit with an iPad and see the electric current flowing around.<ref>{{Cite web|url=https://circuits.lightup.io/|title=LightUp - An award-winning toy that teaches kids about circuits and coding|website=LightUp|language=en-US|access-date=2018-08-29}}</ref> While some educational apps were available for AR by 2016, it was not broadly used. Apps that leverage augmented reality to aid learning included SkyView for studying astronomy,<ref>{{Cite web|title = Terminal Eleven: SkyView – Explore the Universe|url = http://www.terminaleleven.com/skyview/iphone/|website = www.terminaleleven.com|access-date = 2016-02-15}}</ref> AR Circuits for building simple electric circuits,<ref>{{Cite web|title = AR Circuits – Augmented Reality Electronics Kit|url = http://arcircuits.com|website = arcircuits.com|access-date = 2016-02-15}}</ref> and SketchAr for drawing.<ref>{{Cite web|url=http://sketchar.tech|title=SketchAR - start drawing easily&nbsp;using augmented reality|website=SketchAR - start drawing easily&nbsp;using augmented reality|access-date=2018-05-20}}</ref>

AR would also be a way for parents and teachers to achieve their goals for modern education, which might include providing a more individualized and flexible learning, making closer connections between what is taught at school and the real world, and helping students to become more engaged in their own learning.

A recent research compared the functionalities of augmented reality tools with potential for education <ref>Herpich, F.; Guarese, R. L. M.; Tarouco, L. R.[https://www.researchgate.net/publication/318707271_A_Comparative_Analysis_of_Augmented_Reality_Frameworks_Aimed_at_the_Development_of_Educational_Applications A Comparative Analysis of Augmented Reality Frameworks Aimed at the Development of Educational Applications], Creative Education, 08(09):1433-1451</ref>

=== Emergency management/search and rescue ===

Augmented reality systems are used in public safety situations, from super storms to suspects at large.

As early as 2009, two articles from ''Emergency Management'' magazine discussed the power of this technology for emergency management. The first was "Augmented Reality--Emerging Technology for Emergency Management" by Gerald Baron.<ref name="BARO13">"Augmented Reality--Emerging Technology for Emergency Management", ''Emergency Management Magazine'', September 24, 2009</ref> Per Adam Crowe: "Technologies like augmented reality (ex: Google Glass) and the growing expectation of the public will continue to force professional emergency managers to radically shift when, where, and how technology is deployed before, during, and after disasters."<ref name="CROW13">"What Does the Future Hold for Emergency Management?", Emergency Management Magazine, November 8, 2013</ref> Moreover, a 2018 article in the ''Journal of Agromedicine'' describes lessons learned from the development of an augmented reality prototype app developed to assist emergency responders in rural and agricultural environments.<ref>{{Cite journal|last=Weichelt|first=Bryan|last2=Yoder|first2=Aaron|last3=Bendixsen|first3=Casper|last4=Pilz|first4=Matthew|last5=Minor|first5=Gerald|last6=Keifer|first6=Matthew|date=2018-07-03|title=Augmented Reality Farm MAPPER Development: Lessons Learned from an App Designed to Improve Rural Emergency Response|journal=Journal of Agromedicine|language=en|volume=23|issue=3|pages=284–296|doi=10.1080/1059924x.2018.1470051|pmid=30047852|issn=1059-924X|url=http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1121&context=veterans}}</ref> The article also describes this application's utility and current use as a training tool with rural firefighters, part of a [[National Farm Medicine Center]] research project on [[Agricultural safety and health|agricultural safety]] throughout [[Wisconsin]] and [[Minnesota]].

Another early example was a search aircraft looking for a lost hiker in rugged mountain terrain. Augmented reality systems provided aerial camera operators with a geographic awareness of forest road names and locations blended with the camera video. The camera operator was better able to search for the hiker knowing the geographic context of the camera image. Once located, the operator could more efficiently direct rescuers to the hiker's location because the geographic position and reference landmarks were clearly labeled.<ref name="COOP07">{{cite web|last = Cooper|first = Joseph L.|title =Supporting Flight Control for UAV-Assisted Wilderness Search and Rescue Through Human Centered Interface Design|format= Thesis|publisher= Brigham Young University|date= December 2007|url = https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=2216&context=etd}}</ref>

=== Social interaction ===
AR can be used to facilitate social interaction. An augmented reality social network framework called Talk2Me enables people to disseminate information and view others’ advertised information in an augmented reality way. The timely and dynamic information sharing and viewing functionalities of Talk2Me help initiate conversations and make friends for users with people in physical proximity.<ref>Talk2Me: A Framework for Device-to-Device Augmented Reality Social Network. Jiayu Shu, Sokol Kosta, Rui Zheng, Pan Hui. In Proceedings of IEEE International Conference on Pervasive Computing and Communications (PerCom 2018), Athens, Greece, March 2018.</ref>

Augmented reality also Gives users the ability to practice different forms of social interactions with other people in a safe, risk-free environment. Hannes Kauffman, Associate Professor for Virtual Reality at TU Vienna, says “In collaborative Augmented Reality multiple users may access a shared space populated by virtual objects, while remaining grounded in the real world. This technique is particularly powerful for educational purposes when users are collocated and can use natural means of communication (speech, gestures etc.), but can also be mixed successfully with immersive VR or remote collaboration.” (Hannes)Hannes cites a specific use for this technology, [[education]].

=== Video games ===
{{See also|List of augmented reality software#Games|l1=List of augmented reality software § Games}}
[[File:Desjardins AR Augmented Reality Game, March 2013.png|thumb| [[Merchlar]]'s mobile game ''Get On Target'' uses a trigger image as [[fiducial marker]].]]

The gaming industry embraced AR technology. A number of games were developed for prepared indoor environments, such as AR air hockey, ''Titans of Space'', collaborative combat against virtual enemies, and AR-enhanced pool table games.<ref>Hawkins, Mathew. [http://www.gamesetwatch.com/2011/10/augmented_reality_used_to_enhance_both_pool_and_air_hockey.php Augmented Reality Used To Enhance Both Pool And Air Hockey] ''Game Set Watch''October 15, 2011.</ref><ref>[http://combathelo.blogspot.com/2012/07/one-week-only-augmented-reality-project.html One Week Only – Augmented Reality Project] {{webarchive |url=https://web.archive.org/web/20131106180740/http://combathelo.blogspot.com/2012/07/one-week-only-augmented-reality-project.html |date=6 November 2013 }} ''Combat-HELO Dev Blog'' July 31, 2012.</ref><ref>[http://getandroidstuff.com/best-augmented-reality-apps-vr-games-android/ Best VR, Augmented Reality apps & games on Android]</ref>

Augmented reality allowed video game players to experience digital game play in a real-world environment. Companies and platforms like [[Niantic, Inc.|Niantic]] and [[Proxy42]] emerged as major augmented reality gaming creators.<ref name="YOUR THOUGHTS ABOUT AUGMENTED REALITY IN VIDEO GAMES">{{cite web |url=http://day9.tv/d/Lineste/your-thoughts-about-augmented-reality-in-video-games/ |title=YOUR THOUGHTS ABOUT AUGMENTED REALITY IN VIDEO GAMES |date=2013-05-01|accessdate=2013-05-07}}</ref><ref>{{Cite web|title =  Father.io - AR FPS |url = http://www.father.io/|language = en-US}}</ref> Niantic is notable for releasing the record-breaking game ''[[Pokémon Go]]''.<ref>{{cite web|last1=Swatman|first1=Rachel|title=Pokémon Go catches five new world records|url=http://www.guinnessworldrecords.com/news/2016/8/pokemon-go-catches-five-world-records-439327|publisher=[[Guinness World Records]]|accessdate=28 August 2016|date=2016-08-10}}</ref>
[[Disney]] has partnered with [[Lenovo]] to create the augmented reality game ''[[Star Wars]]: Jedi Challenges'' that works with a Lenovo Mirage AR headset, a tracking sensor and a [[Lightsaber]] controller, scheduled to launch in December 2017.<ref>{{Cite web | url=https://www.cnbc.com/2017/08/31/star-wars-jedi-challenges-augmented-reality-game-launches-with-lenovo-mirage-headset.html | title='Star Wars' augmented reality game that lets you be a Jedi launched| date=2017-08-31}}</ref>

=== Industrial design ===

{{Main|Industrial Augmented Reality}}

AR allows industrial designers to experience a product's design and operation before completion. Volkswagen has used AR for comparing calculated and actual crash test imagery.<ref>{{cite book |last1=Noelle |first1=S. |year=2002 |title=Stereo augmentation of simulation results on a projection wall |journal=Mixed and Augmented Reality, 2002. ISMAR 2002. Proceedings. |pages=271–322 |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1115108&tag=1 |accessdate=2012-10-07|doi=10.1109/ISMAR.2002.1115108 |isbn=978-0-7695-1781-0 |citeseerx=10.1.1.121.1268 }}</ref> AR has been used to visualize and modify car body structure and engine layout. It has also been used to compare digital mock-ups with physical mock-ups for finding discrepancies between them.<ref>{{cite journal|last1=Verlinden |first1=Jouke |last2=Horvath |first2=Imre |title=Augmented Prototyping as Design Means in Industrial Design Engineering |publisher=Delft University of Technology |url=http://www.io.tudelft.nl/index.php?id=24954&L=1 |accessdate=2012-10-07 |deadurl=yes |archiveurl=https://web.archive.org/web/20130616010611/http://www.io.tudelft.nl/index.php?id=24954&L=1 |archivedate=16 June 2013 |df=dmy }}</ref><ref>{{cite journal |last1=Pang |first1=Y |last2=Nee |first2=A |last3=Youcef-Toumie |first3=Kamal |last4=Ong |first4=S.K |last5=Yuan |first5=M.L |date=November 18, 2004 |title=Assembly Design and Evaluation in an Augmented Reality Environment |publisher=National University of Singapore, M.I.T. |url=http://dspace.mit.edu/bitstream/handle/1721.1/7441/IMST?sequence=1 |accessdate=2012-10-07}}</ref>

=== Medical ===

Since 2005, a device called a [[near-infrared vein finder]] that films subcutaneous veins, processes and projects the image of the veins onto the skin has been used to locate veins.<ref>{{cite journal|title=Vein imaging: a new method of near infrared imaging, where a processed image is projected onto the skin for the enhancement of vein treatment |vauthors=Miyake RK, etal |pmid=16918565 | doi=10.1111/j.1524-4725.2006.32226.x |volume=32 |issue=8 |journal=Dermatol Surg |pages=1031–8|year=2006 }}</ref><ref>{{cite news| url=http://www.economist.com/node/10202623 | work=The Economist | title=Reality_Only_Better | date=8 December 2007}}</ref>

AR provides surgeons with patient monitoring data in the style of a fighter pilot's heads-up display, and allows patient imaging records, including functional videos, to be accessed and overlaid. Examples include a virtual [[X-ray]] view based on prior [[tomography]] or on real-time images from [[ultrasound]] and [[confocal microscopy]] probes,<ref>{{cite journal |vauthors=Mountney P, Giannarou S, Elson D, Yang GZ |title=Optical biopsy mapping for minimally invasive cancer screening |journal=Medical Image Computing and Computer-assisted Intervention |volume=12 |issue=Pt 1 |pages=483–90 |year=2009 |pmid=20426023}}</ref> visualizing the position of a tumor in the video of an [[endoscope]],<ref>{{youtube|4emmCcBb4s|Scopis Augmented Reality: Path guidance to craniopharyngioma}}</ref> or radiation exposure risks from X-ray imaging devices.<ref>N. Loy Rodas, N. Padoy. "3D Global Estimation and Augmented Reality Visualization of Intra-operative X-ray Dose". Proceedings of Medical Image Computing and Computer-Assisted Intervention (MICCAI), Oral, 2014</ref><ref>{{youtube|pINE2gaOVOY|3D Global Estimation and Augmented Reality Visualization of Intra-operative X-ray Dose}}</ref> AR can enhance viewing a [[fetus]] inside a mother's [[womb]].<ref>{{cite web |url=http://www.cs.unc.edu/Research/us/ |title=UNC Ultrasound/Medical Augmented Reality Research |accessdate=2010-01-06 |archiveurl=https://web.archive.org/web/20100212231230/http://www.cs.unc.edu/Research/us/ |archivedate=12 February 2010 <!-- DASHBot -->|deadurl=no}}</ref> Siemens, Karl Storz and IRCAD have developed a system for laparoscopic liver surgery that uses AR to view sub-surface tumors and vessels.<ref>{{Cite book|last=Mountney|first=Peter|last2=Fallert|first2=Johannes|last3=Nicolau|first3=Stephane|last4=Soler|first4=Luc|last5=Mewes|first5=Philip W.|date=2014-01-01|title=An augmented reality framework for soft tissue surgery|journal=International Conference on Medical Image Computing and Computer-Assisted Intervention|volume=8673|pages=423–431|doi=10.1007/978-3-319-10404-1_53|series=Lecture Notes in Computer Science|isbn=978-3-319-10403-4}}</ref>  
AR has been used for cockroach phobia treatment.<ref>Botella, C., Bretón-López, J., Quero, S., Baños, R., & García-Palacios, A. (2010). Treating Cockroach Phobia With Augmented Reality.</ref>
Patients wearing augmented reality glasses can be reminded to take medications.<ref name="healthtechevent">{{cite web | url = http://www.healthtechevent.com/technology/augmented-reality-revolutionizing-medicine-healthcare/ | title = Augmented Reality Revolutionizing Medicine | publisher = Health Tech Event | accessdate = 9 October 2014| date = 2014-06-06 }}</ref> Virtual reality has been seen promising in the medical field since the 90's.<ref>{{Cite journal|url=https://www.researchgate.net/publication/289532420|title=The New Dawn of Virtual Reality in Health Care: Medical Simulation and Experiential Interface|journal=Annual Review of Cybertherapy and Telemedicine|last=Riva|first=Giuseppe|last2=Wiederhold|first2=Brenda|date=2015-12-28|volume=13|pages=3–6|doi=10.3233/978-1-61499-595-1-3}}</ref> Augmented reality can be very helpful in the medical field.<ref>{{Cite journal|last=Thomas|first=Daniel J.|date=December 2016|title=Augmented reality in surgery: The Computer-Aided Medicine revolution|journal=International Journal of Surgery |volume=36|issue=Pt A|pages=25|doi=10.1016/j.ijsu.2016.10.003|issn=1743-9159|pmid=27741424}}</ref> It could be used to provide crucial information to a doctor or surgeon with having them take their eyes off the patient. On the 30th of April, 2015 Microsoft announced the [[Microsoft HoloLens]], their first shot at augmented reality. The [[Microsoft HoloLens|HoloLens]] has advanced through the years and it has gotten so advanced that it has been used to project holograms for near infrared fluorescence based image guided surgery.<ref>{{Cite book|last=Cui|first=Nan|last2=Kharel|first2=Pradosh|last3=Gruev|first3=Viktor|date=2017-02-08|title=Augmented reality with Microsoft HoloLens holograms for near infrared fluorescence based image guided surgery|publisher=International Society for Optics and Photonics|volume=10049|pages=100490I|doi=10.1117/12.2251625|series=Molecular-Guided Surgery: Molecules, Devices, and Applications III}}</ref> As augment reality advances, the more it is implemented into medical use. Augmented reality and other computer based-utility is being used today to help train medical professionals.<ref>{{Cite journal|last=Barsom|first=E. Z.|last2=Graafland|first2=M.|last3=Schijven|first3=M. P.|date=2016-10-01|title=Systematic review on the effectiveness of augmented reality applications in medical training|journal=Surgical Endoscopy|language=en|volume=30|issue=10|pages=4174–4183|doi=10.1007/s00464-016-4800-6|pmid=26905573|issn=0930-2794|pmc=5009168}}</ref> With the creation of [[Google Glass]] and [[Microsoft HoloLens]], has helped pushed Augmented Reality into medical education.

=== Spatial immersion and interaction ===

Augmented reality applications, running on handheld devices utilized as virtual reality headsets, can also digitalize human presence in space and provide a computer generated model of them, in a virtual space where they can interact and perform various actions. Such capabilities are demonstrated by "Project Anywhere", developed by a postgraduate student at ETH Zurich, which was dubbed as an "out-of-body experience".<ref>{{cite news | url=https://www.theguardian.com/technology/2015/jan/07/project-anywhere-digital-route-to-an-out-of-body-experience | title=Project Anywhere: digital route to an out-of-body experience | newspaper=The Guardian | date=January 7, 2015 | accessdate=September 21, 2016 | author=Davis, Nicola}}</ref><ref>{{cite web | url=http://www.euronews.com/2015/02/25/project-anywhere-an-out-of-body-experience-of-a-new-kind | title=Project Anywhere: an out-of-body experience of a new kind | work=Euronews | date=2015-02-25 | accessdate=September 21, 2016}}</ref><ref>[http://www.studioany.com/#!projectanywhere/c1g1s Project Anywhere] at studioany.com</ref>

=== Flight training ===

Building on decades of perceptual-motor research in experimental psychology, researchers at the Aviation Research Laboratory of the University of Illinois at Urbana-Champaign used augmented reality in the form of a flight path in the sky to teach flight students how to land a flight simulator. An adaptive augmented schedule in which students were shown the augmentation only when they departed from the flight path proved to be a more effective training intervention than a constant schedule.<ref name=":0" /><ref>{{Cite journal|last=Lintern|first=Gavan|last2=Roscoe, Stanley N|last3=Sivier, Jonathon|date=1990|title=Display principles, control dynamics, and environmental factors in pilot training and transfer|url=|journal=Human Factors|volume=32|pages=299–317|via=}}</ref> Flight students taught to land in the simulator with the adaptive augmentation learned to land a light aircraft more quickly than students with the same amount of landing training in the simulator but with constant augmentation or without any augmentation.<ref name=":0">{{cite journal|last1=Lintern|first1=Gavan|title=Transfer of landing skill after training with supplementary visual cues|journal=Human Factors|date=1980|volume=22|pages=81–88}}</ref>

=== Military ===
[[File:ARC4_AR_System.jpg|thumb|Augmented Reality System for Soldier ARC4(USA)]]
An interesting early application of AR occurred when Rockwell International created video map overlays of satellite and orbital debris tracks to aid in space observations at Air Force Maui Optical System.  In their 1993 paper "Debris Correlation Using the Rockwell WorldView System" the authors describe the use of map overlays applied to video from space surveillance telescopes.  The map overlays indicated the trajectories of various objects in geographic coordinates.  This allowed telescope operators to identify satellites, and also to identify and catalog potentially dangerous space debris.<ref name="ABER93">Abernathy, M., Houchard, J., Puccetti, M., and Lambert, J,"Debris Correlation Using the Rockwell WorldView System", Proceedings of 1993 Space Surveillance Workshop 30 March to 1 April 1993, pages 189-195</ref>

Starting in 2003 the US Army integrated the SmartCam3D augmented reality system into the Shadow Unmanned Aerial System to aid sensor operators using telescopic cameras to locate people or points of interest. The system combined both fixed geographic information including street names, points of interest, airports, and railroads with live video from the camera system. The system offered a "picture in picture" mode that allows the system to show a synthetic view of the area surrounding the camera's field of view. This helps solve a problem in which the field of view is so narrow that it excludes important context, as if "looking through a soda straw". The system displays real-time friend/foe/neutral location markers blended with live video, providing the operator with improved situational awareness.

As of 2010, Korean researchers are looking to implement mine-detecting robots into the military. The proposed design for such a robot includes a mobile platform that is like a track which would be able to cover uneven distances including stairs. The robot's mine detection sensor would include a combination of metal detectors and ground penetration radars to locate mines or IEDs. This unique design would be immeasurably helpful in saving lives of Korean soldiers.<ref name="ieeexplore-ieee-org.mutex.gmu.edu">Kang, Seong Pal; Choi, Junho; Suh, Seung-Beum; Kang, Sungchul. [https://ieeexplore-ieee-org.mutex.gmu.edu/document/5679622] Ret. November 30, 2018.</ref>

Researchers at USAF Research Lab (Calhoun, Draper et al.) found an approximately two-fold increase in the speed at which UAV sensor operators found points of interest using this technology.<ref name="CALH05">Calhoun, G. L., Draper, M. H., Abernathy, M. F., Delgado, F., and Patzek, M. "Synthetic Vision System for Improving Unmanned Aerial Vehicle Operator Situation Awareness,"  2005 Proceedings of SPIE Enhanced and Synthetic Vision, Vol. 5802, pp. 219–230.</ref> This ability to maintain geographic awareness quantitatively enhances mission efficiency. The system is in use on the US Army RQ-7 Shadow and the MQ-1C Gray Eagle Unmanned Aerial Systems.

In combat, AR can serve as a networked communication system that renders useful battlefield data onto a soldier's goggles in real time. From the soldier's viewpoint, people and various objects can be marked with special indicators to warn of potential dangers. Virtual maps and 360° view camera imaging can also be rendered to aid a soldier's navigation and battlefield perspective, and this can be transmitted to military leaders at a remote command center.<ref>Cameron, Chris. [http://www.readwriteweb.com/archives/military_grade_augmented_reality_could_redefine_modern_warfare.php Military-Grade Augmented Reality Could Redefine Modern Warfare] ''ReadWriteWeb'' June 11, 2010.</ref>

=== Navigation ===

{{See also|Automotive navigation system}}
[[File:LandForm displays landmarks and other indicators during helicopter flight at Yuma Proving Ground..JPG|thumb|LandForm video map overlay marking runways, road, and buildings during 1999 helicopter flight test]]

The NASA X-38 was flown using a Hybrid Synthetic Vision system that overlaid map data on video to provide enhanced navigation for the spacecraft during flight tests from 1998 to 2002. It used the LandForm software and was useful for times of limited visibility, including an instance when the video camera window frosted over leaving astronauts to rely on the map overlays.<ref name="DELG99">Delgado, F., Abernathy, M., White J., and Lowrey, B. ''[http://adsabs.harvard.edu/abs/1999SPIE.3691..149D Real-Time 3-D Flight Guidance with Terrain for the X-38]'', SPIE Enhanced and Synthetic Vision 1999, Orlando Florida, April 1999, Proceedings of the SPIE Vol. 3691, pages 149–156</ref>  The LandForm software was also test flown at the Army Yuma Proving Ground in 1999.  In the photo at right one can see the map markers indicating runways, air traffic control tower, taxiways, and hangars overlaid on the video.<ref name="DELG00">Delgado, F., Altman, S., Abernathy, M., White, J. ''[http://adsabs.harvard.edu/abs/2000SPIE.4023...63D Virtual Cockpit Window for the X-38]'', SPIE Enhanced and Synthetic Vision 2000, Orlando Florida, Proceedings of the SPIE Vol. 4023, pages 63–70</ref>

AR can augment the effectiveness of navigation devices. Information can be displayed on an automobile's windshield indicating destination directions and meter, weather, terrain, road conditions and traffic information as well as alerts to potential hazards in their path.<ref>[https://techcrunch.com/2010/03/17/gms-enhanced-vision-system-brings-augmented-reality-to-vehicle-huds/ GM's Enhanced Vision System]. Techcrunch.com (17 March 2010). Retrieved 9 June 2012.</ref><ref>Couts, Andrew. [http://www.digitaltrends.com/cars/new-augmented-reality-system-shows-3d-gps-navigation-through-your-windshield/ New augmented reality system shows 3D GPS navigation through your windshield] ''Digital Trens'',27 October 2011.</ref><ref>Griggs, Brandon. [http://www.cnn.com/2012/01/13/tech/innovation/ces-future-driving/index.html Augmented-reality' windshields and the future of driving] ''CNN Tech'', 13 January 2012.</ref> Since 2012, a Swiss-based company [[WayRay]] has been developing holographic AR navigation systems that use holographic optical elements for projecting all route-related information including directions, important notifications, and points of interest right into the drivers’ line of sight and far ahead of the vehicle.<ref>{{Cite news|url=https://techcrunch.com/2018/01/09/wayrays-ar-in-car-hud-convinced-me-huds-can-be-better/|title=WayRay’s AR in-car HUD convinced me HUDs can be better|work=TechCrunch|access-date=2018-10-03|language=en-US}}</ref><ref>{{Cite web|url=http://www.futurecar.com/1013/WayRay-Creates-Holographic-Navigation-Alibaba-Invests-$18-Million|title=WayRay Creates Holographic Navigation: Alibaba Invests $18 Million|last=Walz|first=Eric|date=May 22, 2017|website=FutureCar|access-date=2018-10-17}}</ref> Aboard maritime vessels, AR can allow bridge watch-standers to continuously monitor important information such as a ship's heading and speed while moving throughout the bridge or performing other tasks.<ref>{{cite web |url=http://cimsec.org/bridgegoggles/ |title=CIMSEC: Google's AR Goggles|author=Cheney-Peters, Scott|date=12 April 2012 |accessdate=2012-04-20}}</ref>

=== Workplace ===

Augmented reality may have a good impact on work collaboration as people may be inclined to interact more actively with their learning environment. It may also encourage tacit knowledge renewal which makes firms more competitive. AR was used to facilitate collaboration among distributed team members via conferences with local and virtual participants. AR tasks included brainstorming and discussion meetings utilizing common visualization via touch screen tables, interactive digital whiteboards, shared design spaces and distributed control rooms.<ref>{{cite web |url=http://www.hog3d.net/ |title=Hand of God |author1=Stafford, Aaron |author2=Piekarski, Wayne |author3=Thomas, Bruce H. |accessdate=2009-12-18 |archiveurl=https://web.archive.org/web/20091207022651/http://www.hog3d.net/ |archivedate=7 December 2009 |deadurl=yes |df=dmy-all }}</ref><ref>Benford, S, Greenhalgh, C, Reynard, G, Brown, C and Koleva, B. Understanding and constructing shared spaces with mixed-reality boundaries. ACM Trans. Computer-Human Interaction, 5(3):185–223, Sep. 1998.</ref><ref>[http://mi-lab.org/projects/office-of-tomorrow/ Office of Tomorrow] ''Media Interaction Lab''.</ref>

In industrial environments, augmented reality is proving to have a substantial impact with more and more use cases emerging across all aspect of the product lifecycle, starting from product design and new product introduction (NPI) to manufacturing to service and maintenance, to material handling and distribution. For example, labels were displayed on parts of a system to clarify operating instructions for a mechanic performing maintenance on a system.<ref>[http://ngm.nationalgeographic.com/big-idea/14/augmented-reality-pg1 The big idea:Augmented Reality]. Ngm.nationalgeographic.com (15 May 2012). Retrieved 2012-06-09.</ref><ref>{{cite web |url=http://graphics.cs.columbia.edu/projects/armar/ |title=Augmented Reality for Maintenance and Repair (ARMAR) |author1=Henderson, Steve |author2=Feiner, Steven |accessdate=2010-01-06}}</ref> Assembly lines benefited from the usage of AR. In addition to Boeing, BMW and Volkswagen were known for incorporating this technology into assembly lines for monitoring process improvements.<ref>Sandgren, Jeffrey. [http://brandtechnews.net/tag/augmented-reality/ The Augmented Eye of the Beholder], ''BrandTech News'' January 8, 2011.</ref><ref>Cameron, Chris. [http://www.slideshare.net/readwriteweb/augmented-reality-for-marketers-and-developers-analysis-of-the-leaders-the-challenges-and-the-future Augmented Reality for Marketers and Developers], ''ReadWriteWeb''.</ref><ref>Dillow, Clay [http://www.popsci.com/scitech/article/2009-09/bmw-developing-augmented-reality-help-mechanics BMW Augmented Reality Glasses Help Average Joes Make Repairs], ''Popular Science'' September 2009.</ref> Big machines are difficult to maintain because of their multiple layers or structures. AR permits people to look through the machine as if with an x-ray, pointing them to the problem right away.<ref>King, Rachael. [http://www.businessweek.com/stories/2009-11-03/augmented-reality-goes-mobilebusinessweek-business-news-stock-market-and-financial-advice Augmented Reality Goes Mobile], ''Bloomberg Business Week Technology'' November 3, 2009.</ref>

As AR technology has evolved and second and third generation AR devices come to market, the impact of AR in enterprise continues to flourish. In a Harvard Business Review, Magid Abraham and Marco Annunziata discuss how AR devices are now being used to "boost workers’ productivity on an array of tasks the first time they're used, even without prior training."<ref name=":6">{{Cite web|url=https://hbr.org/2017/03/augmented-reality-is-already-improving-worker-performance|title=Augmented Reality Is Already Improving Worker Performance|last=Abraham|first=Magid|last2=Annunziata|first2=Marco|date=2017-03-13|website=Harvard Business Review|access-date=2019-01-13}}</ref> They go on to contend that "these technologies increase productivity by making workers more skilled and efficient, and thus have the potential to yield both more economic growth and better jobs."<ref name=":6" />

=== Broadcast and live events===

Weather visualizations were the first application of augmented reality to television. It has now become common in weathercasting to display full motion video of images captured in real-time from multiple cameras and other imaging devices. Coupled with 3D graphics symbols and mapped to a common virtual geospace model, these animated visualizations constitute the first true application of AR to TV.

AR has become common in sports telecasting. Sports and entertainment venues are provided with see-through and overlay augmentation through tracked camera feeds for enhanced viewing by the audience. Examples include the yellow "[[first down]]" line seen in television broadcasts of [[American football]] games showing the line the offensive team must cross to receive a first down. AR is also used in association with football and other sporting events to show commercial advertisements overlaid onto the view of the playing area. Sections of [[rugby football|rugby]] fields and [[cricket]] pitches also display sponsored images. Swimming telecasts often add a line across the lanes to indicate the position of the current record holder as a race proceeds to allow viewers to compare the current race to the best performance. Other examples include hockey puck tracking and annotations of racing car performance and snooker ball trajectories.<ref name="recentadvances">Azuma, Ronald; Balliot, Yohan; Behringer, Reinhold; Feiner, Steven; Julier, Simon; MacIntyre, Blair. [http://www.cc.gatech.edu/~blair/papers/ARsurveyCGA.pdf Recent Advances in Augmented Reality] ''Computers & Graphics'', November 2001.</ref><ref>Marlow, Chris. [http://www.dmwmedia.com/news/2012/04/27/hey-hockey-puck-nhl-preplay-adds-a-second-screen-experience-to-live-games Hey, hockey puck! NHL PrePlay adds a second-screen experience to live games], ''digitalmediawire'' April 27, 2012.</ref>

Augmented reality for Next Generation TV allows viewers to interact with the programs they were watching. They can place objects into an existing program and interact with them, such as moving them around. Objects include avatars of real persons in real time who are also watching the same program.

AR has been used to enhance concert and theater performances. For example, artists allow listeners to augment their listening experience by adding their performance to that of other bands/groups of users.<ref>Pair, J.; Wilson, J.; Chastine, J.; Gandy, M. "[http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?tp=&arnumber=1107010 The Duran Duran Project: The Augmented Reality Toolkit in Live Performance]". ''The First IEEE International Augmented Reality Toolkit Workshop'', 2002.</ref><ref>Broughall, Nick. [http://www.gizmodo.com.au/2009/10/sydney-band-uses-augmented-reality-for-video-clip/ Sydney Band Uses Augmented Reality For Video Clip.] ''Gizmodo'', 19 October 2009.</ref><ref>Pendlebury, Ty. [http://www.cnet.com.au/augmented-reality-in-aussie-film-clip-339299097.htm Augmented reality in Aussie film clip]. ''c|net'' 19 October 2009.</ref>

=== Tourism and sightseeing ===

Travelers may use AR to access real-time informational displays regarding a location, its features, and comments or content provided by previous visitors. Advanced AR applications include simulations of historical events, places, and objects rendered into the landscape.<ref>Saenz, Aaron [http://singularityhub.com/2009/11/19/augmented-reality-does-time-travel-tourism/ Augmented Reality Does Time Travel Tourism] ''SingularityHUB'' November 19, 2009.</ref><ref>Sung, Dan [http://www.pocket-lint.com/news/38806/augmented-reality-travel-tourism-apps Augmented reality in action – travel and tourism] ''Pocket-lint'' March 2, 2011.</ref><ref>Dawson, Jim [http://www.livescience.com/5644-augmented-reality-reveals-history-tourists.html Augmented Reality Reveals History to Tourists] ''Life Science'' August 16, 2009.</ref>

AR applications linked to geographic locations present location information by audio, announcing features of interest at a particular site as they become visible to the user.<ref>Bartie, P and Mackaness, W.[http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9671.2006.00244.x/abstract Development of a speech-based augmented reality system to support exploration of the cityscape.] Trans. GIS, 10(1):63–86, 2006.</ref><ref>Benderson, Benjamin B. [http://www.cs.umd.edu/~bederson/papers/chi-95-aar/ Audio Augmented Reality: A Prototype Automated Tour Guide] {{webarchive |url=https://web.archive.org/web/20020701071038/http://www.cs.umd.edu/~bederson/papers/chi-95-aar/ |date=1 July 2002 }} Bell Communications Research, ACM Human Computer in Computing Systems Conference, pp. 210–211.</ref><ref>Jain, Puneet and Manweiler, Justin and Roy Choudhury, Romit. [http://synrg.csl.illinois.edu/papers/overlay.pdf OverLay: Practical Mobile Augmented Reality] 
ACM MobiSys, May 2015.</ref>

Companies can use AR to attract tourists to particular areas that they may not be familiar with by name. Tourists will be able to experience beautiful landscapes in first person with the use of AR devices. Companies like Phocuswright plan to use such technology in order to expose the lesser known but beautiful areas of the planet, and in turn, increase tourism. Other companies such as Matoke Tours have already developed an application where the user can see 360 degrees from several different places in Uganda. Matoke Tours and Phocuswright have the ability to display their apps on virtual reality headsets like the Samsung VR and Oculus Rift.<ref>{{Cite news|url=https://www.cnbc.com/2016/01/08/virtual-reality-devices-could-transform-the-tourism-experience.html|title=VR devices could transform tourism|last=CNBC.com|first=Luke Graham, special to|date=2016-01-08|work=CNBC|access-date=2018-03-08}}</ref>

=== Translation ===

AR systems such as [[Word Lens]] can interpret the foreign text on signs and menus and, in a user's augmented view, re-display the text in the user's language. Spoken words of a foreign language can be translated and displayed in a user's view as printed subtitles.<ref>Tsotsis, Alexia. [https://techcrunch.com/2010/12/16/world-lens-translates-words-inside-of-images-yes-really Word Lens Translates Words Inside of Images. Yes Really.] ''TechCrunch'' (16 December 2010).</ref><ref>N.B. [https://www.economist.com/blogs/gulliver/2010/12/instant_translation Word Lens: This changes everything]  ''The Economist: Gulliver blog'' 18 December 2010.</ref><ref>Borghino, Dario [http://www.gizmag.com/language-translating-glasses/23494/ Augmented reality glasses perform real-time language translation]. ''gizmag'', 29 July 2012.</ref>

=== Music ===

It has been suggested that augmented reality may be used in new methods of [[music production]], [[music mixing|mixing]], [[Media controls|control]] and [[music visualization|visualization]].<ref>{{cite web|title=Music Production in the Era of Augmented Reality|url=https://medium.com/@Soundspringstudio/music-production-in-the-era-of-augmented-reality-2e79f4926275|website=Medium|accessdate=5 January 2017|date=14 October 2016}}</ref><ref>{{cite web|title=Augmented Reality music making with Oak on Kickstarter – gearnews.com|url=https://www.gearnews.com/augmented-reality-music-making-oak-kickstarter/|website=gearnews.com|accessdate=5 January 2017|date=3 November 2016}}</ref><ref>{{cite web|last1=Clouth|first1=Robert|title=Mobile Augmented Reality as a Control Mode for Real-time Music Systems|url=http://mtg.upf.edu/node/2846|accessdate=5 January 2017|date=1 January 2013}}</ref><ref>{{Cite book|last1=Farbiz|first1=Farzam|title=2007 6th International Conference on Information, Communications & Signal Processing|pages=1–5|last2=Tang|first2=Ka Yin|last3=Manders|first3=Corey|last4=Herng|first4=Chong Jyh|last5=Tan|first5=Yeow Kee|last6=Wang|first6=Kejian|last7=Ahmad|first7=Waqas|chapter-url=https://www.researchgate.net/publication/4318144|website=ResearchGate|accessdate=5 January 2017|doi=10.1109/ICICS.2007.4449564|date=10 January 2008|chapter=A multimodal augmented reality DJ music system|isbn=978-1-4244-0982-2}}</ref>

A tool for 3D music creation in clubs that, in addition to regular sound mixing features, allows the [[DJ]] to play dozens of [[sound sample]]s, placed anywhere in 3D space, has been conceptualized.<ref>{{cite journal|last1=Stampfl|first1=Philipp|title=Augmented Reality Disk Jockey: AR/DJ|journal=ACM SIGGRAPH 2003 Sketches & Applications|date=1 January 2003|pages=1|doi=10.1145/965400.965556}}</ref>

[[Leeds College of Music]] teams have developed an AR app that can be used with [[Audient]] desks and allow students to use their smartphone or tablet to put layers of information or interactivity on top of an Audient mixing desk.<ref>{{cite web|title=GROUND-BREAKING AUGMENTED REALITY PROJECT Supporting music production through new technology|url=http://www.lcm.ac.uk/News/Ground-breaking-AR-project-for-Production|accessdate=5 January 2017|archive-url=https://web.archive.org/web/20170106102945/http://www.lcm.ac.uk/News/Ground-breaking-AR-project-for-Production|archive-date=6 January 2017|dead-url=yes|df=dmy-all}}</ref>

ARmony is a software package that makes use of augmented reality to help people to learn an instrument.<ref>{{cite web|title=ARmony – Using Augmented Reality to learn music|url=https://www.youtube.com/watch?v=wolO1lbKzAw|website=YouTube|accessdate=5 January 2017|date=24 August 2014}}</ref>

In a proof-of-concept project Ian Sterling, interaction design student at [[California College of the Arts]], and software engineer Swaroop Pal demonstrated a HoloLens app whose primary purpose is to provide a 3D spatial UI for cross-platform devices — the Android Music Player app and Arduino-controlled Fan and Light — and also allow interaction using gaze and gesture control.<ref>{{cite web|title=HoloLens concept lets you control your smart home via augmented reality|url=http://www.digitaltrends.com/cool-tech/hololens-hackathon-smart-home/|publisher=Digital Trends|accessdate=5 January 2017|date=26 July 2016}}</ref><ref>{{cite web|title=Hololens: Entwickler zeigt räumliches Interface für Elektrogeräte|url=https://vrodo.de/hololens-entwickler-zeigt-raeumliches-interface-fuer-elektrogeraete/|publisher=VRODO|accessdate=5 January 2017|language=de-DE|date=22 July 2016}}</ref><ref>{{cite web|title=Control Your IoT Smart Devices Using Microsoft HoloLen (video) – Geeky Gadgets|url=http://www.geeky-gadgets.com/control-your-iot-smart-devices-using-microsoft-hololen-27-07-2016/|publisher=Geeky Gadgets|accessdate=5 January 2017|date=27 July 2016}}</ref><ref>{{cite web|title=Experimental app brings smart home controls into augmented reality with HoloLens|url=http://www.windowscentral.com/experimental-app-brings-smart-home-controls-augmented-reality-hololens|publisher=Windows Central|accessdate=5 January 2017|date=2016-07-22}}</ref>

AR Mixer is an app that allows one to select and mix between songs by manipulating objects – such as changing the orientation of a bottle or can.<ref>{{cite web|title=This app can mix music while you mix drinks, and proves augmented reality can be fun|url=http://www.digitaltrends.com/mobile/augmented-reality-mixer-app/|publisher=Digital Trends|accessdate=5 January 2017|date=20 November 2013}}</ref>

In a video, Uriel Yehezkel demonstrates using the [[Leap Motion]] controller and GECO MIDI to control [[Ableton Live]] with [[gesture recognition|hand gesture]]s and states that by this method he was able to control more than 10 parameters simultaneously with both hands and take full control over the construction of the song, emotion and energy.<ref>{{cite journal|last1=Sterling|first1=Bruce|title=Augmented Reality: Controlling music with Leapmotion Geco and Ableton (Hands Control)|journal=Wired|url=https://www.wired.com/2013/11/augmented-reality-controlling-music-with-leapmotion-geco-and-ableton-hands-control/|accessdate=5 January 2017|date=2013-11-06}}</ref><ref>{{cite web|title=Controlling Music With Leap Motion Geco & Ableton|url=http://www.synthtopia.com/content/2013/11/04/controlling-music-with-leap-motion-geco-ableton/|publisher=Synthtopia|accessdate=5 January 2017|date=4 November 2013}}</ref>{{Better source|reason=|date=January 2017}}

A novel musical instrument that allows novices to play electronic musical compositions, interactively remixing and modulating their elements, by manipulating simple physical objects has been proposed.<ref>{{cite journal|title=Augmented Reality Interface for Electronic Music Performance|url=https://pdfs.semanticscholar.org/4dcc/f17d5a68206a872d887ceec84fa0a085c21d.pdf|accessdate=5 January 2017}}</ref>

A system using explicit gestures and implicit dance moves to control the visual augmentations of a live music performance that enable more dynamic and spontaneous performances and—in combination with indirect augmented reality—leading to a more intense interaction between artist and audience has been suggested.<ref>{{cite journal|title=Expressive Control of Indirect Augmented Reality During Live Music Performances|url=http://nime.org/proceedings/2013/nime2013_32.pdf|accessdate=5 January 2017}}</ref>

Research by members of the CRIStAL at the [[University of Lille]] makes use of augmented reality in order to enrich musical performance. The ControllAR project allows musicians to augment their [[MIDI]] control surfaces with the remixed [[graphical user interface]]s of [[music software]].<ref>{{cite book|title=ControllAR : Appropriation of Visual Feedback on Control Surfaces|pages=271–277|chapter-url=https://hal.archives-ouvertes.fr/hal-01356239|doi=10.1145/2992154.2992170|chapter=ControllAR|year=2016|last1=Berthaut|first1=Florent|last2=Jones|first2=Alex|isbn=9781450342483}}</ref> The Rouages project proposes to augment [[Electronic musical instrument|digital musical instruments]] in order to reveal their mechanisms to the audience and thus improve the perceived liveness.<ref>{{cite journal|title=Rouages: Revealing the Mechanisms of Digital Musical Instruments to the Audience|pages=6 pages|url=https://hal.archives-ouvertes.fr/hal-00807049|date=May 2013}}</ref> Reflets is a novel augmented reality display dedicated to musical performances where the audience acts as a 3D display by revealing virtual content on stage, which can also be used for 3D musical interaction and collaboration.<ref>{{cite journal|title=Reflets: Combining and Revealing Spaces for Musical Performances|url=https://hal.archives-ouvertes.fr/hal-01136857|date=May 2015}}</ref>

=== Retail ===

Augmented reality is becoming more frequently used for online advertising. Retailers offer the ability to upload a picture on their website and "try on" various clothes which is overlaid on the picture. Even further, companies such as Bodymetrics install dressing booths in department stores that offer [[full-body scanning]]. These booths render a 3-D model of the user, allowing the consumers to view different outfits on themselves without the need of physically changing clothes.<ref>Pavlik, John V., and Shawn McIntosh. “Augmented Reality.” Converging Media: a New Introduction to Mass Communication, 5th ed., Oxford University Press, 2017, pp. 184–185.</ref> For example, [[J. C. Penney|JC Penney]] and [[Bloomingdale's]] use "[[virtual dressing room]]s" that allow customers to see themselves in clothes without trying them on.<ref name=":02">{{Cite journal|date=2017-11-01|title=Enabling smart retail settings via mobile augmented reality shopping apps|url=https://www.sciencedirect.com/science/article/pii/S0040162516304243|journal=Technological Forecasting and Social Change|language=en|volume=124|pages=243–256|doi=10.1016/j.techfore.2016.09.032|issn=0040-1625|last1=Dacko|first1=Scott G.}}</ref> Another store that uses AR to market clothing to its customers is [[Neiman Marcus]].<ref name=":12">{{Cite news|url=https://www.retaildive.com/news/how-neiman-marcus-is-turning-technology-innovation-into-a-core-value/436590/|title=How Neiman Marcus is turning technology innovation into a 'core value'|work=Retail Dive|access-date=2018-09-23|language=en-US}}</ref>  Neiman Marcus offers consumers the ability to see their outfits in a 360 degree view with their "memory mirror".<ref name=":12" /> Makeup stores like [[L'Oréal|L'Oreal]], [[Sephora]], [[Charlotte Tilbury]], and [[Rimmel]] also have apps that utilize AR.<ref name=":22" />  These apps allow consumers to see how the makeup will look on them.<ref name=":22" />  According to Greg Jones, director of AR and VR at Google, augmented reality is going to "reconnect physical and digital retail."<ref name=":22" />

AR technology is also used by furniture retailers such as [[IKEA]], [[Houzz]], and [[Wayfair]].<ref name=":22">{{Cite news|url=https://www.forbes.com/sites/rachelarthur/2017/10/31/augmented-reality-is-set-to-transform-fashion-and-retail/#364c701b3151|title=Augmented Reality Is Set To Transform Fashion And Retail|last=Arthur|first=Rachel|work=Forbes|access-date=2018-09-23|language=en}}</ref><ref name=":02" />  These retailers offer apps that allow consumers to view their products in their home prior to purchasing anything.<ref name=":22" />  IKEA launched their IKEA Place at the end of 2017 and made it possible to have 3D and true to scale models of furniture in their living space, through using the app and their camera. IKEA realized that their customers are not shopping in stores as often or directly buy things anymore. So they created IKEA Place to tackle these problems and have people try out the furniture with Augmented Reality and then decide if they want to buy it.<ref>IKEA Highlights 2017 https://www.ikea.com/ms/en_CH/this-is-ikea/ikea-highlights/2017/ikea-place-app/index.html
</ref><ref>Fact & Figures, IKEA, 2017, https://highlights.ikea.com/2017/facts-and-figures/</ref>

=== Snapchat ===

Snapchat users have access to augmented reality in the company's instant messaging app through use of camera filters. In September 2017, Snapchat updated its app to include a camera filter that allowed users to render an animated, cartoon version of themselves called "Bitmoji". These animated avatars would be projected in the real world through the camera, and can be photographed or video recorded.<ref>Wagner, Kurt. “Snapchat's New Augmented Reality Feature Brings Your Cartoon Bitmoji into the Real World.” Recode, Recode, 14 Sept. 2017, www.recode.net/2017/9/14/16305890/snapchat-bitmoji-ar-facebook.</ref> In the same month, Snapchat also announced a new feature called "Sky Filters" that will be available on its app. This new feature makes use of augmented reality to alter the look of a picture taken of the sky, much like how users can apply the app's filters to other pictures. Users can choose from sky filters such as starry night, stormy clouds, beautiful sunsets, and rainbow.<ref>Miller, Chance. “Snapchat’s Latest Augmented Reality Feature Lets You Paint the Sky with New Filters.” 9to5Mac, 9to5Mac, 25 Sept. 2017, 9to5mac.com/2017/09/25/how-to-use-snapchat-sky-filters/.</ref>

== The Dangers of AR ==

=== Reality modifications ===
There is a danger that will make individuals overconfident and put their life at risk because of it. Pokémon GO with a couple of deaths and many injuries is the perfect example of it. "[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3073723 Death by Pokémon GO]”, by a pair of researchers from Purdue University's Krannert School of Management, says the game caused “a disproportionate increase in vehicular crashes and associated vehicular damage, personal injuries, and fatalities in the vicinity of locations, called PokéStops, where users can play the game while driving.”.<ref>{{Cite journal |ssrn=3073723|doi=10.2139/ssrn.3073723|title = Death by Pokémon GO: The Economic and Human Cost of Using Apps While Driving|date = 2018-02-02|last1 = Faccio|first1 = Mara|last2=McConnell|first2=John J.}}</ref> The paper extrapolated what that might mean nationwide and concluded “the increase in crashes attributable to the introduction of Pokémon GO is 145,632 with an associated increase in the number of injuries of 29,370 and an associated increase in the number of fatalities of 256 over the period of July 6, 2016, through November 30, 2016.” The authors valued those crashes and fatalities at between $2bn and $7.3 billion for the same period.

Furthermore, more than one in three surveyed advanced internet users would like to edit out disturbing elements around them, such as garbage or graffiti.<ref>Peddie, J., 2017, Agumented Reality, Springer</ref> They would like to even modify their surroundings by erasing street signs, billboard ads, and uninteresting shopping windows. So it seems that AR is a threat to companies as it is an opportunity. Although this could be a nightmare to numerous brands that do not manage to capture consumer imaginations it also creates the risk that the wearers of augmented reality glasses may become unaware of surrounding dangers. Consumers want to use augmented reality glasses to change their surroundings into something that reflects their own personal opinions. Around two in five want to change the way their surroundings look and even how people appear to them.

Next, to the possible privacy issues that are described below, overload and over-reliance issues is the biggest danger of AR. For the development of new AR related products, this implies that the user-interface should follow certain guidelines as not to overload the user with information while also preventing the user to overly rely on the AR system such that important cues from the environment are missed.<ref name="Azuma, R. T. 1997">Azuma, R. T. (1997). A survey of augmented reality. Presence-Teleoperators and Virtual Environments, 6(4), 355–385.</ref>  This is called the virtually-augmented key.<ref name="Azuma, R. T. 1997"/> Once the key is not taken into account people might not need the real world anymore.

=== Privacy concerns ===
The concept of modern augmented reality depends on the ability of the device to record and analyze the environment in real time. Because of this, there are potential legal concerns over privacy. While the [[First Amendment to the United States Constitution]] allows for such recording in the name of public interest, the constant recording of an AR device makes it difficult to do so without also recording outside of the public domain. Legal complications would be found in areas where a right to a certain amount of privacy is expected or where copyrighted media are displayed.

In terms of individual privacy, there exists the ease of access to information that one should not readily possess about a given person. This is accomplished through facial recognition technology. Assuming that AR automatically passes information about persons that the user sees, there could be anything seen from social media, criminal record, and marital status.<ref>TRoesner, Franziska, Tadayoshi Kohno, Tamara Denning, Ryan Calo, and Bryce Clayton Newell. "Augmented Reality." Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing Adjunct Publication – UbiComp '14 Adjunct (2014). The university of Utah. Ubicomp. Web. 18 Aug. 2015.</ref>

Privacy-compliant image capture solutions can be deployed to temper the impact of constant filming on individual privacy.<ref>Jiayu Shu, Rui Zheng, Pan Hui [http://www.cse.ust.hk/~panhui/papers/mar.privacy.2017.pdf Your Privacy Is in Your Hand: Interactive Visual Privacy Control with Tags and Gestures].</ref>

== Notable researchers ==

* [[Ivan Sutherland]] invented the [[The Sword of Damocles (virtual reality)|first VR head-mounted display]] at [[Harvard University]].
* [[Steve Mann]] formulated an earlier concept of [[mediated reality]] in the 1970s and 1980s, using cameras, processors, and display systems to modify visual reality to help people see better (dynamic range management), building computerized welding helmets, as well as "augmediated reality" vision systems for use in everyday life. He is also an adviser to [[Meta (company)|Meta]].<ref>"Wearable Computing: A first step towards personal imaging", IEEE Computer, pp. 25–32, Vol. 30, Issue 2, Feb. 1997 [http://www.eyetap.org/papers/docs/first_step.pdf link].</ref>
* [[Louis Rosenberg (writer)|Louis Rosenberg]] developed one of the first known AR systems, called [[Virtual Fixtures]], while working at the U.S. Air Force Armstrong Labs in 1991, and published the first study of how an AR system can enhance human performance.<ref name="B. Rosenberg 1992">L. B. Rosenberg. The Use of Virtual Fixtures As Perceptual Overlays to Enhance Operator Performance in Remote Environments. Technical Report AL-TR-0089, USAF Armstrong Laboratory, Wright-Patterson AFB OH, 1992.</ref> Rosenberg's subsequent work at Stanford University in the early 90's, was the first proof that virtual overlays when registered and presented over a user's direct view of the real physical world, could significantly enhance human performance.<ref>Rosenberg, L., "[https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2057/0000/Virtual-fixtures-as-tools-to-enhance-operator-performance-in-telepresence/10.1117/12.164901.short Virtual fixtures as tools to enhance operator performance in telepresence environments]," SPIE Manipulator Technology, 1993.</ref><ref>Rosenberg, "[https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2351/0000/Virtual-haptic-overlays-enhance-performance-in-telepresence-tasks/10.1117/12.197302.short Virtual Haptic Overlays Enhance Performance in Telepresence Tasks]," Dept. of Mech. Eng., Stanford Univ., 1994.</ref><ref name="autogenerated1">Rosenberg, "[https://dl.acm.org/citation.cfm?id=221788 Virtual Fixtures: Perceptual Overlays Enhance Operator Performance in Telepresence Tasks]," Ph.D. Dissertation, Stanford University.</ref>
* [[Mike Abernathy]] pioneered one of the first successful augmented video overlays (also called hybrid syntheric vision) using map data for space debris in 1993,<ref name="ABER93"/> while at Rockwell International.  He co-founded Rapid Imaging Software, Inc. and was the primary author of the LandForm system in 1995, and the SmartCam3D system.<ref name="DELG99" /><ref name = "DELG00" />   LandForm augmented reality was successfully flight tested in 1999 aboard a helicopter and SmartCam3D was used to fly the NASA X-38 from 1999–2002.  He and NASA colleague Francisco Delgado received the National Defense Industries Association Top5 awards in 2004.<ref name="ReferenceA">C. Segura E. George F. Doherty J. H. Lindley M. W. Evans "[http://www.crosstalkonline.org/storage/issue-archives/2005/200509/200509-Delgado.pdf SmartCam3D Provides New Levels of Situation Awareness]", CrossTalk: The Journal of Defense Software Engineering. Volume 18, Number 9, pages 10–11.</ref>
* [[Steven Feiner]], Professor at [[Columbia University]], is the author of a 1993 paper on an AR system prototype, KARMA (the Knowledge-based Augmented Reality Maintenance Assistant), along with [[Blair MacIntyre]] and [[Doree Seligmann]]. He is also an advisor to [[Meta (company)|Meta]].<ref>{{cite journal |url=http://portal.acm.org/citation.cfm?id=159587 |title=Knowledge-based augmented reality |journal=Communications of the ACM |volume=36 |issue=7 |pages=53–62 |date=July 1993 |doi=10.1145/159544.159587 |last1=Feiner |first1=Steven |last2=MacIntyre |first2=Blair |last3=Seligmann |first3=Dorée }}</ref>
*[[Tracy McSheery]], of Phasespace, developer in 2009 of wide field of view AR lenses as used in Meta 2 and others.<ref>{{cite web|title=SBIR STTR Development of Low-Cost Augmented Reality Head Mounted Display|url=https://www.sbir.gov/sbirsearch/detail/269401}}</ref>
*S. Ravela, B. Draper, J. Lim and A. Hanson developed a marker/fixture-less augmented reality system with computer vision in 1994. They augmented an engine block observed from a single video camera with annotations for repair. They use model-based pose estimation, aspect graphs and visual feature tracking to dynamically register model with the observed video.<ref>{{Cite book | doi=10.1109/IROS.1995.525793|chapter = Adaptive tracking and model registration across distinct aspects|title = Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots| volume=1| pages=174–180|year = 1995|last1 = Ravela|first1 = S.| last2=Draper| first2=B.| last3=Lim| first3=J.| last4=Weiss| first4=R.| isbn=978-0-8186-7108-1| chapter-url=http://scholarworks.umass.edu/cs_faculty_pubs/219}}</ref>
* [[Francisco Delgado (researcher)|Francisco Delgado]] is a [[NASA]] engineer and project manager specializing in human interface research and development.  Starting 1998 he conducted research into displays that combined video with synthetic vision systems (called hybrid synthetic vision at the time) that we recognize today as augmented reality systems for the control of aircraft and spacecraft.  In 1999 he and colleague Mike Abernathy flight-tested the LandForm system aboard a US Army helicopter.  Delgado oversaw integration of the LandForm and SmartCam3D systems into the X-38 Crew Return Vehicle.<ref name="DELG99" /><ref name = "DELG00" /><ref name="huffingtonpost.com"/>  In 2001, Aviation Week reported NASA astronaut's successful use of hybrid synthetic vision (augmented reality) to fly the X-38 during a flight test at Dryden Flight Research Center.  The technology was used in all subsequent flights of the X-38.  Delgado was co-recipient of the National Defense Industries Association 2004 Top 5 software of the year award for SmartCam3D.<ref name="ReferenceA"/>
* [[Bruce H. Thomas]] and [[Wayne Piekarski]] develop the Tinmith system in 1998.<ref>Piekarski, William; Thomas, Bruce. [http://www.computer.org/portal/web/csdl/doi/10.1109/ISWC.2001.962093 Tinmith-Metro: New Outdoor Techniques for Creating City Models with an Augmented Reality Wearable Computer] Fifth International Symposium on Wearable Computers (ISWC'01), 2001, pp. 31.</ref> They along with [[Steve Feiner]] with his MARS system pioneer outdoor augmented reality.
*Mark Billinghurst is Director of the HIT Lab New Zealand (HIT Lab NZ) at the [[University of Canterbury]] in New Zealand and a notable AR researcher. He has produced over 250 technical publications and presented demonstrations and courses at a wide variety of conferences.
*[[Reinhold Behringer]] performed important early work (1998) in image registration for augmented reality, and prototype wearable testbeds for augmented reality. He also co-organized the First IEEE International Symposium on Augmented Reality in 1998 (IWAR'98), and co-edited one of the first books on augmented reality.<ref>Behringer, R.;[http://reference.kfupm.edu.sa/content/i/m/improving_the_registration_precision_by__1670204.pdf Improving the Registration Precision by Visual Horizon Silhouette Matching.]{{dead link|date=August 2017|bot=medic}}{{cbignore|bot=medic}} Rockwell Science Center.</ref><ref>Behringer, R.;Tam, C; McGee, J.; Sundareswaran, V.; Vassiliou, Marius. [http://www.computer.org/portal/web/csdl/doi/10.1109/ISWC.2000.888495 Two Wearable Testbeds for Augmented Reality: itWARNS and WIMMIS.] ISWC 2000, Atlanta, 16–17 October 2000.</ref><ref>R. Behringer, G. Klinker,. D. Mizell. [http://www.crcpress.com/product/isbn/9781568810980 Augmented Reality – Placing Artificial Objects in Real Scenes]. Proceedings of IWAR '98. A.K. Peters, Natick, 1999. {{ISBN|1-56881-098-9}}.</ref>
*[[Felix G. Hamza-Lup]], [[Larry Davis (researcher)|Larry Davis]] and [[Jannick Rolland]] developed the 3D ARC display with optical see-through head-warned display for AR visualization in 2002.<ref>{{cite journal|title=The ARC Display: An Augmented Reality Visualization Center |author=Felix, Hamza-Lup |date=30 September 2002 |publisher=CiteSeer|citeseerx = 10.1.1.89.5595}}</ref>  
* [[Dieter Schmalstieg]] and [[Daniel Wagner (researcher)|Daniel Wagner]] developed a marker tracking systems for mobile phones and PDAs in 2009.<ref>{{cite book |url=http://portal.acm.org/citation.cfm?id=946910 |title=First Steps Towards Handheld Augmented Reality |author=Wagner, Daniel |date=29 September 2009 |publisher=ACM |accessdate=2009-09-29|isbn=9780769520346 }}</ref>

== History ==
* 1901: [[L. Frank Baum]], an author, first mentions the idea of an electronic display/spectacles that overlays data onto real life (in this case 'people'). It is named a 'character marker'.<ref>Johnson, Joel. [https://web.archive.org/web/20130522153011/http://moteandbeam.net/the-master-key-l-frank-baum-envisions-ar-glasses-in-1901 "The Master Key": L. Frank Baum envisions augmented reality glasses in 1901] ''Mote & Beam'' 10 September 2012.</ref>
* 1957–62: [[Morton Heilig]], a cinematographer, creates and patents a simulator called [[Sensorama]] with visuals, sound, vibration, and smell.<ref>{{cite web|url=http://www.google.com/patents?q=3050870|title=3050870 – Google Search|work=google.com|accessdate=2 July 2015}}</ref>
* 1968: [[Ivan Sutherland]] invents the [[head-mounted display]] and positions it as a window into a virtual world.<ref>{{cite web|url=http://90.146.8.18/en/archiv_files/19902/E1990b_123.pdf |title=Archived copy |accessdate=2014-02-19 |deadurl=yes |archiveurl=https://web.archive.org/web/20140123204209/http://90.146.8.18/en/archiv_files/19902/E1990b_123.pdf |archivedate=23 January 2014 |df=dmy }}</ref>
* 1975: [[Myron Krueger]] creates [[Videoplace]] to allow users to interact with virtual objects.
* 1980: The research by Gavan Lintern of the University of Illinois is the first published work to show the value of a [[Head-up display|heads up display]] for teaching real-world flight skills.<ref name=":0"/>
* 1980: [[Steve Mann]] creates the first wearable computer, a computer vision system with text and graphical overlays on a photographically mediated scene.<ref>{{cite news|last=Mann |first=Steve |url=http://techland.time.com/2012/11/02/eye-am-a-camera-surveillance-and-sousveillance-in-the-glassage |title=Eye Am a Camera: Surveillance and Sousveillance in the Glassage |publisher=Techland.time.com |date=2012-11-02 |accessdate=2013-10-14}}</ref>  See [[EyeTap]].  See [[Head-up display|Heads Up Display]].
* 1981: Dan Reitan geospatially maps multiple weather radar images and space-based and studio cameras to earth maps and abstract symbols for television weather broadcasts, bringing a precursor concept to augmented reality (mixed real/graphical images) to TV.<ref>{{cite web|url=http://www.etceter.com/c-news/p-google-glasses-project/ |title=Archived copy |accessdate=2014-02-21 |deadurl=yes |archiveurl=https://web.archive.org/web/20131003224001/http://www.etceter.com/c-news/p-google-glasses-project/ |archivedate=3 October 2013 |df=dmy }}</ref>
* 1987: Douglas George and Robert Morris create a working prototype of an astronomical telescope-based "[[Head-up display|heads-up display]]" system (a precursor concept to augmented reality) which superimposed in the telescope eyepiece, over the actual sky images, multi-intensity star, and celestial body images, and other relevant information.<ref>George, D.B., "A COMPUTER-DRIVEN ASTRONOMICAL TELESCOPE GUIDANCE AND CONTROL SYSTEM WITH SUPERIMPOSED STARFIELD AND CELESTIAL COORDINATE GRAPHICS DISPLAY", M.Eng. Thesis, Carleton University, Ottawa, Oct. 1987.</ref><ref>George, Douglas; Morris, Robert. "A Computer-driven Astronomical Telescope Guidance and Control System with Superimposed Star Field and Celestial Coordinate Graphics Display" pp. 32–41, J. Roy. Astron. Soc. Can., Vol. 83, No. 1, 1989.</ref>
* 1990: The term 'Augmented Reality' is attributed to Thomas P. Caudell, a former [[Boeing]] researcher.<ref>{{cite journal |last=Lee |first=Kangdon |title=Augmented Reality in Education and Training |journal=Techtrends: Linking Research & Practice to Improve Learning |date=March 2012 |volume=56 |issue=2 |accessdate=2014-05-15|url = http://www2.potsdam.edu/betrusak/566/Augmented%20Reality%20in%20Education.pdf}}</ref>
* 1992: [[Louis Rosenberg (entrepreneur)|Louis Rosenberg]] developed one of the first functioning AR systems, called [[Virtual fixture|Virtual Fixtures]], at the United States Air Force Research Laboratory—Armstrong, that demonstrated benefit to human perception.<ref>{{Cite journal|last=Rosenberg|first=R.|last2=Rosenberg|first2=S.|last3=Rosenberg|first3=R.|last4=Fenton|first4=D.|date=2009-04-07|title=Bernard Cecil Rosenberg|journal=BMJ|volume=338|issue=apr07 2|pages=b1450|doi=10.1136/bmj.b1450|issn=0959-8138}}</ref>
* 1993: [[Steven Feiner]], [[Blair MacIntyre]] and [[Doree Seligmann]] present an early paper on an AR system prototype, KARMA, at the Graphics Interface conference.
* 1993: Mike Abernathy, et al., report the first use of augmented reality in identifying space debris using [[Rockwell Collins|Rockwell]] WorldView by overlaying satellite geographic trajectories on live telescope video.<ref name = "ABER93"/>
* 1993 A widely cited version of the paper above is published in [[Communications of the ACM]] – Special issue on computer augmented environments, edited by Pierre Wellner, Wendy Mackay, and Rich Gold.<ref>{{cite book|last=Wellner|first=Pierre|title=Computer Augmented Environments: back to the real world|volume=36|url=http://dl.acm.org/citation.cfm?id=159544|publisher=ACM|accessdate=2012-07-28|year=1993}}</ref>
* 1993: [[Loral Corporation|Loral WDL]], with sponsorship from [[United States Army Simulation and Training Technology Center|STRICOM]], performed the first demonstration combining live AR-equipped vehicles and manned simulators. Unpublished paper, J. Barrilleaux, "Experiences and Observations in Applying Augmented Reality to Live Training", 1999.<ref>Barrilleaux, Jon. [[:File:Experiences and Observations in Applying Augmented Reality to Live Training.pdf|Experiences and Observations in Applying Augmented Reality to Live Training]].</ref>
* 1994: Julie Martin creates first 'Augmented Reality Theater production', Dancing In Cyberspace, funded by the [[Australia Council for the Arts]], features dancers and [[acrobatics|acrobats]] manipulating body–sized virtual object in real time, projected into the same physical space and performance plane. The acrobats appeared immersed within the virtual object and environments. The installation used [[Silicon Graphics]] computers and Polhemus sensing system.
* 1995: S. Ravela et al. at [[University of Massachusetts]] introduce a vision-based system using monocular cameras to track objects (engine blocks) across views for augmented reality.
* 1998: Spatial Augmented Reality introduced at [[University of North Carolina]] at Chapel Hill by [[Ramesh Raskar]], Welch, [[Henry Fuchs]].<ref name="raskarSAR" />
* 1999: Frank Delgado, Mike Abernathy et al. report successful flight test of LandForm software video map overlay from a helicopter at Army Yuma Proving Ground overlaying video with runways, taxiways, roads and road names.<ref name="DELG99" /><ref name = "DELG00" />
* 1999: The [[United States Naval Research Laboratory|US Naval Research Laboratory]] engages on a decade-long research program called the Battlefield Augmented Reality System (BARS) to prototype some of the early wearable systems for dismounted soldier operating in urban environment for situation awareness and training.<ref>[http://www.nrl.navy.mil/itd/imda/research/5581/augmented-reality NRL BARS Web page]</ref>
* 2001: NASA X-38 flown using LandForm software video map overlays at [[Dryden Flight Research Center]].<ref name="AN2001">AviationNow.com Staff, "X-38 Test Features Use Of Hybrid Synthetic Vision" AviationNow.com, December 11, 2001</ref>
* 2004: Outdoor helmet-mounted AR system demonstrated by [[Trimble Navigation]] and the Human Interface Technology Laboratory (HIT lab).<ref name="Outdoor AR"/>
* 2008: Wikitude AR Travel Guide launches on 20 Oct 2008 with the [[HTC Dream|G1 Android phone]].<ref>[https://www.youtube.com/watch?v=8EA8xlicmT8 Wikitude AR Travel Guide]. Youtube.com. Retrieved 2012-06-09.</ref>
* 2009: ARToolkit was ported to [[Adobe Flash]] (FLARToolkit) by Saqoosha, bringing augmented reality to the web browser.<ref>Cameron, Chris. [http://www.readwriteweb.com/archives/flash-based_ar_gets_high-quality_markerless_upgrade.php Flash-based AR Gets High-Quality Markerless Upgrade], ''ReadWriteWeb'' 9 July 2010.</ref>
* 2010: Design of mine detection robot for Korean mine field.<ref name="ieeexplore-ieee-org.mutex.gmu.edu" />
* 2012: Launch of [[LyteShot|Lyteshot]], an interactive AR gaming platform that utilizes smart glasses for game data
* 2013: Meta announces the Meta 1 developer kit.<ref>{{Cite news|url=https://www.slashgear.com/meta-plans-true-augmented-reality-with-epson-powered-wearable-28266900/|title=Meta plans true augmented reality with Epson-powered wearable|date=2013-01-28|work=SlashGear|access-date=2018-08-31|language=en-US}}</ref><ref>{{Cite news|url=https://www.roadtovr.com/meta-01-augmented-reality-glasses-pre-order-price/|title=Meta 01 Augmented Reality Glasses Available for Pre-order for $667|last=Lang|first=Ben|date=2013-08-13|work=Road to VR|access-date=2018-08-31|language=en-US}}</ref>
* 2013: [[Google]] announces an open beta test of its [[Google Glass]] augmented reality glasses. The glasses reach the Internet through Bluetooth, which connects to the wireless service on a user's cellphone. The glasses respond when a user speaks, touches the frame or moves the head.<ref>Miller, Claire. [https://www.nytimes.com/2013/02/21/technology/google-looks-to-make-its-computer-glasses-stylish.html?pagewanted=all&_r=0], ''New York Times'' 20 February 2013.</ref><ref>{{Cite web|url=http://images.huffingtonpost.com/2016-05-13-1463155843-8474094-AR_history_timeline.jpg|title=Timeline of Augmented Reality (Huffington Post)|last=|first=|date=|website=huffingtonpost.com|access-date=}}</ref>
* 2015: [[Microsoft]] announces [[Windows Holographic]] and the [[HoloLens]] augmented reality headset. The headset utilizes various sensors and a processing unit to blend high definition "holograms" with the real world.<ref>Microsoft Channel, YouTube [https://www.youtube.com/watch?v=aThCr0PsyuA], 23 January 2015.</ref>
* 2016: [[Niantic, Inc.|Niantic]] released ''[[Pokémon Go]]'' for [[iOS]] and [[Android (operating system)|Android]] in July 2016. The game quickly became one of the most popular smartphone applications and in turn spikes the popularity of augmented reality games.<ref>{{cite news|last1=Bond|first1=Sarah|title=After the Success Of Pokémon Go, How Will Augmented Reality Impact Archaeological Sites?|url=https://www.forbes.com/sites/drsarahbond/2016/07/17/after-the-success-of-pokemon-go-how-will-augmented-reality-impact-archaeological-sites/|accessdate=July 17, 2016|date=July 17, 2016}}</ref>
* 2017: [[Magic Leap]] announces the use of [[Digital Lightfield]] technology embedded into the [[Magic Leap One]] headset. The creators edition headset includes the glasses and a computing pack worn on your belt.<ref>C|NET [https://www.cnet.com/products/magic-leap-one/preview/], 20 December 2017.</ref>

==See also==
{{div col|colwidth=22em}}

* [[Alternate reality game]]
* [[ARTag]]
* [[Augmented browsing]]
* [[Augmented reality-based testing]]
* [[Augmented web]]
* [[Automotive head-up display]]
* [[Bionic contact lens]]
* [[Brain in a vat]]
* [[Computer-mediated reality]]
* [[Cyborg]]
* [[EyeTap]]
* [[Head-mounted display]]
* [[Holography]]
* [[Lifelike experience]]
* [[List of augmented reality software]]
* [[Magic Leap]]
* [[Mixed reality]]
* [[Optical head-mounted display]]
* [[Simulated reality]]
* [[Smartglasses]]
* [[Transreality gaming]]
* [[Video mapping]]
* [[Viractualism]]
* [[Virtual reality]]
* [[Visuo-haptic mixed reality]]
* [[Wearable computing]]
{{div col end}}

== References ==
{{Reflist|30em}}

== External links ==
{{Commons}}

{{Authority control}}

{{DEFAULTSORT:Augmented reality}}
[[Category:Applications of computer vision]]
[[Category:Augmented reality]]
[[Category:Advertising techniques]]
[[Category:Marketing techniques]]
[[Category:Promotion and marketing communications]]
[[Category:User interface techniques]]